[{"path":"https://ngreifer.github.io/cobalt/articles/cobalt.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Covariate Balance Tables and Plots: A Guide to the cobalt Package","text":"Preprocessing data matching, weighting, subclassification can effective way reduce model dependence improve efficiency estimating causal effect treatment (Ho et al. 2007). Propensity scores related methods (e.g., coarsened exact matching, Mahalanobis distance matching, genetic matching) become popular social health sciences tools purpose. Two excellent introductions propensity scores preprocessing methods Stuart (2010) Austin (2011), describe simply clearly point sources knowledge. logic theory behind preprocessing discussed , reader’s knowledge causal assumption strong ignorability assumed. Several packages R exist perform preprocessing causal effect estimation, reviewed Keller Tipton (2016). include MatchIt (Ho et al. 2011), twang (Ridgeway et al. 2016), Matching (Sekhon 2011), optmatch (Hansen Klopfer 2006), CBPS (Fong et al. 2019), ebal (Hainmueller 2014), sbw (Zubizarreta, Li, Kim 2021), designmatch (Zubizarreta, Kilcioglu, Vielma 2018), WeightIt (Greifer 2021), MatchThem (Pishgar et al. 2021), cem (Iacus, King, Porro 2009); together provide near complete set preprocessing tools R date. following basic steps performing causal analysis using data preprocessing (Stuart 2010): Decide covariates balance must achieved Estimate distance measure (e.g., propensity score) Condition distance measure (e.g., using matching, weighting, subclassification) Assess balance covariates interest; poor, repeat steps 2-4 Estimate treatment effect conditioned sample Steps 2, 3, 4 accomplished packages mentioned . However, Step 4, assessing balance, often overlooked propensity score applications, researchers failing report degree covariate balance achieved conditioning (Thoemmes Kim 2011). Achieving balance purpose preprocessing covariate balance justifies ignorability observed covariates, allowing potential valid causal inference effect estimation (Ho et al. 2007). addition simply achieving balance, researchers must also report balance convince readers analysis performed adequately causal conclusions valid (Thoemmes Kim 2011). Covariate balance typically assessed reported using statistical measures, including standardized mean differences, variance ratios, t-test Kolmogorov-Smirnov-test p-values. Balance can reported article means balance tables plots displaying balance measures conditioning. defensible measure balance used presented, readers empowered judge whether causal claim made valid based methods used covariates chosen. cobalt meant supplement replace balance assessment tools packages allow researchers assess report balance covariates simply, clearly, flexibly conditioning. integrates seamlessly packages users can employ conditioning package choice cobalt conjunction assess report balance. important note cobalt replace highly sophisticated conditioning tools packages, conditioning estimation . rest guide explains use cobalt packages others, well choices instituted functions customizable user. vignettes describe use cobalt packages mentioned , multiply imputed clustered data, longitudinal treatments.","code":""},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt.html","id":"citing-cobalt","dir":"Articles","previous_headings":"Introduction","what":"Citing cobalt","title":"Covariate Balance Tables and Plots: A Guide to the cobalt Package","text":"using cobalt, please cite use along conditioning package used. full APA reference cobalt following: Greifer, N. (2022). cobalt: Covariate Balance Tables Plots. R package version 4.4.1. example, use Matching propensity score estimation matching cobalt balance assessment /reporting, possible citation might go follows: Matching performed using Matching package (Sekhon, 2011), covariate balance assessed using cobalt (Greifer, 2022), R (R Core Team, 2022).","code":""},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt.html","id":"why-cobalt","dir":"Articles","previous_headings":"","what":"Why cobalt?","title":"Covariate Balance Tables and Plots: A Guide to the cobalt Package","text":"major conditioning packages contain functions assess balance, use cobalt ? cobalt arose several desiderata using packages: standardized measures consistent across conditioning packages, allow flexibility calculation display balance measures, incorporate recent methodological recommendations assessment balance. However, users packages may completely satisfied capabilities comfortable output; , cobalt still value unique plotting capabilities make use ggplot2 R. following reasons cobalt may attractive users MatchIt, twang, Matching, optmatch, CBPS, ebal, sbw, designmatch, WeightIt, conditioning packages:","code":""},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt.html","id":"visual-clarity","dir":"Articles","previous_headings":"Why cobalt?","what":"Visual clarity","title":"Covariate Balance Tables and Plots: A Guide to the cobalt Package","text":"cobalt presents one table balance output, contains information required assess balance. twang CBPS present two tables, MatchIt presents three tables, Matching presents many tables covariates. Although tables contains valuable information, bal.tab() function cobalt allows quick easy search information desired, often single column containing balance statistic (standardized mean difference) adjusted sample.","code":""},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt.html","id":"useful-summaries","dir":"Articles","previous_headings":"Why cobalt?","what":"Useful summaries","title":"Covariate Balance Tables and Plots: A Guide to the cobalt Package","text":"Although thorough balance assessment requires examining balance covariate individually, cobalt’s bal.tab() function can also produce quick balance summaries can aid model selection many covariates higher order terms examine. summaries include proportion covariates met user-specified threshold balance covariate highest degree imbalance, two values shown effective diagnosing imbalance potential bias (Stuart, Lee, Leacy 2013).","code":""},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt.html","id":"one-tool-to-rule-them-all","dir":"Articles","previous_headings":"Why cobalt?","what":"One tool to rule them all","title":"Covariate Balance Tables and Plots: A Guide to the cobalt Package","text":"priori way know conditioning method work best given sample, users try several methods, methods spread across various packages; example, full matching available MatchIt optmatch, generalized boosted modeling twang, covariate balancing propensity score weighting CBPS, genetic matching MatchIt Matching, entropy balancing ebal2. user wants compare methods ability generate balance sample, metrics output. package computes balance statistics differently (), relevant balance measures different places package. using cobalt assess balance across packages, users can sure using single, equivalent balance metric across methods, relevant balance statistics place computed way regardless conditioning package used.","code":""},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt.html","id":"flexibility","dir":"Articles","previous_headings":"Why cobalt?","what":"Flexibility","title":"Covariate Balance Tables and Plots: A Guide to the cobalt Package","text":"cobalt gives users choice statistics presented calculated, intelligently uses defaults line goals unified balance assessment data available. Rather displaying values calculated, bal.tab() displays user wants; bare minimum, standardized mean difference covariate displayed, traditionally considered sufficient model selection justification preprocessing analysis binary treatments. Even user doesn’t want values displayed, still calculated, thus available use programming (though can disabled increased speed).","code":""},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt.html","id":"pretty-plots","dir":"Articles","previous_headings":"Why cobalt?","what":"Pretty plots","title":"Covariate Balance Tables and Plots: A Guide to the cobalt Package","text":"main conditioning packages produce plots can useful assessing balance, summarizing balance, understanding intricacies conditioning method simple text insufficient. Many plots unique package, cobalt attempted replace replicate . plots, though, cobalt uses ggplot2 present clean, clear, customizable, high-quality displays balance assessment presentation. two included plotting functions bal.plot(), generates plots distributions covariates treatment levels complete distributional balance can assessed beyond numerical summaries, love.plot(), generates plot summarizing covariate balance conditioning, popularized Dr. Thomas E. Love. plots use ggplot2 base, users familiar ggplot2 can customize various elements plots use publications presentations.","code":""},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt.html","id":"unique-features","dir":"Articles","previous_headings":"Why cobalt?","what":"Unique features","title":"Covariate Balance Tables and Plots: A Guide to the cobalt Package","text":"unique features cobalt exist package. include handling clustered grouped data handling data generated multiple imputation. advanced uses cobalt described detail accompanying Appendix 2. addition, cobalt includes tools handling data sets continuous multi-category treatments. Data sets longitudinal treatments, time-varying confounding may issue, can handled well; uses described accompanying Appendix 3.","code":""},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt.html","id":"how-to-use-cobalt","dir":"Articles","previous_headings":"","what":"How To Use cobalt","title":"Covariate Balance Tables and Plots: A Guide to the cobalt Package","text":"three main functions use cobalt: bal.tab(), bal.plot(), love.plot(). also several utility functions can used ease use cobalt packages. next sections describe use , complete example code output. start, install load cobalt following code:","code":"install.packages(\"cobalt\") library(\"cobalt\")"},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt.html","id":"utilities","dir":"Articles","previous_headings":"How To Use cobalt","what":"Utilities","title":"Covariate Balance Tables and Plots: A Guide to the cobalt Package","text":"addition main functions, cobalt contains several utility functions, include f.build(), splitfactor() unsplitfactor(), get.w(). meant reduce typing programming burden often accompany use R diverse set packages. simplify vignette, descriptions functions Appendix 1. understand code vignette, aware f.build(), creates formula inputs, get.w() extracts weights input.","code":""},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt.html","id":"bal-tab","dir":"Articles","previous_headings":"How To Use cobalt","what":"bal.tab()","title":"Covariate Balance Tables and Plots: A Guide to the cobalt Package","text":"bal.tab() primary function cobalt. produces balance tables objects given inputs. balance tables can customized variety inputs, affect calculation presentation values. performs similar functions summary() MatchIt; bal.table(), summary(), dx.wts() twang; MatchBalance() summary() Matching; balance() CBPS; summarize() sbw. can seen replacement supplement functions. help using bal.tab(), see ?bal.tab R, contains information certain values calculated links help files bal.tab() methods integrate packages. simplicity, description use bal.tab() complete use without package. demonstration display bal.tab()’s many options, several differ based package, , bal.tab() used. demonstrations minimal, highlighting use bal.tab() effectively MatchIt WeightIt, detailing possible options packages, avoid redundancy. use bal.tab() packages described accompanying Appendix 1, “Using cobalt Preprocessing Packages”.","code":""},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt.html","id":"using-bal-tab-on-its-own","dir":"Articles","previous_headings":"How To Use cobalt > bal.tab()","what":"Using bal.tab() on its own","title":"Covariate Balance Tables and Plots: A Guide to the cobalt Package","text":"bal.tab() can take data set set weights, subclasses, matching strata evaluate balance . can useful propensity score weights, subclasses, matching strata generated outside supported packages, balance assessment desired prior adjustment, package output adjusted way make unusable one bal.tab()’s methods (e.g., cases manually removed weights manually changed). twang, function dx.wts() performs similar action allowing balance assessment groups weighted using twang functions, though limited types data conditioning strategies allowed. example use bal.tab() ATT weights generating using logistic regression weighting---odds analysis: Displayed first balance table, last summary sample size information. weighting specified method used, effective sample sizes given, done twang. See twang documentation, ?bal.tab, “Details Calculations” details calculation. several ways specify input bal.tab() using data outside conditioning package. first, shown , use data frame covariates vectors treatment status weights subclasses. user can additionally specify vector distance measures (e.g., propensity scores) balance assessed well. weights left empty, balance unadjusted sample reported. user can also optionally specify data set data argument; makes arguments treat, weights, distance, subclass, others can specified either vector name variable argument data contains respective values. Another way specify input bal.tab() use formula interface. example use: use formula interface, user must specify formula relating treatment covariates balance assessed. variables exist data set, must supplied data. , covs data frame used simplicity, using f.build() traditional formula input treat ~ v1 + v2 + v3 + ... also acceptable. , arguments weights, distance, subclass, others can specified either vectors data frames containing values names variables argument data containing values. example, argument distance specified, balance measures propensity score now appear balance table. default, bal.tab() outputs standardized mean differences continuous variables raw differences proportion binary variables. details values computed determined, see ?bal.tab “Details Calculations” . see raw standardized mean differences binary continuous variables, can manually set binary /continuous \"raw\" \"std\". can also set global options using, example, set.cobalt.options(binary = \"std\"), allows user type non-default option every time call bal.tab. Users can specify additional variables display balance using argument addl, can supplied data.frame, formula containing variables, string names variables. Users can also add two-way interactions covariates, including addl, specifying int = TRUE, can add polynomials (e.g., squares) covariates specifying numeric argument poly. Interactions computed distance measure (.e., propensity score), squared terms computed binary variables. details interactions, see “Details Calculations”, . request desired interaction terms, can entered addl using formula, addl = ~ V1 * V2. , balance requested variables stored covs, additional variables nodegree married, interactions squares. Standardized mean differences can computed several ways, user can decide bal.tab() using argument s.d.denom, controls whether measure spread denominator standard deviation treated group (\"treated\"), appropriate computing ATT; standard deviation control group (\"control\"), appropriate computing ATC; pooled standard deviation (\"pooled\"), computed Austin (2009), appropriate computing ATE; another value (see ?col_w_smd options). bal.tab() can generally determine ATT ATC estimated supply s.d.denom accordingly. Otherwise, default \"pooled\". next options affect display, calculation statistics. First disp, controls whether sample statistics covariate group displayed. Options include \"means\" \"sds\", request group means standard deviations, respectively3. Next stats, controls balance statistics displayed. binary multi-category treatments, options include \"mean.diffs\" (standardized) mean differences, \"variance.ratios\" variance ratios, \"ks.statistics\" Kolmogorov-Smirnov (KS) statistics, \"ovl.coefficient\" complement overlapping coefficient (abbreviations allowed). See ?balance.stats details. default, standardized mean differences displayed. Variance ratios another important tool assessing balance beyond mean differences pertain shape covariate distributions beyond centers. Variance ratios close 1 (.e., equal variances groups) indicative group balance (Austin 2009). KS statistics measure greatest distance empirical cumulative distribution functions (eCDFs) variable two groups. statistic bounded 0 1, 0 indicting perfectly identical distributions 1 indicating perfect separation distributions (.e., overlap ); values close 0 thus indicative balance. use KS statistic formally assess balance debated. Austin Stuart (2015) recommend use, variant appears default balance statistic MatchIt, twang, Matching. hand, Belitser et al. (2011), Stuart, Lee, Leacy (2013), Ali et al. (2014) found global balance assessments using KS statistic performed uniformly worse standardized mean differences, especially sample sizes less 1000 simulations. overlapping coefficient measures amount overlap covariate distributions two groups. Franklin et al. (2014), complement used 0 indicates perfectly overlapping distributions 1 indicates perfectly non-overlapping distributions. functions similarly KS statistic. Next un, controls whether statistics displayed displayed unadjusted group well. can useful first time balance assessed see initial group imbalance. Setting un = FALSE, default, can declutter output maintain spotlight group balance adjustment. See ?display_options full list display options. can also set global options using set.cobalt.options(). Finally, user can specify threshold balance statistics using threshold argument. Thresholds can useful determining whether satisfactory balance achieved. standardized mean differences, thresholds .1 .25 proposed, Stuart, Lee, Leacy (2013) found threshold .1 effective assessing imbalance lead biased effect estimation. general, standardized mean differences close 0 possible, conservative upper limit .1 can valuable heuristic selecting models defending conditioning choice. Works Clearinghouse Standards Handbook recommends standardized mean differences less .05 (Works Clearinghouse, 2020). thresholds requested, components added balance output: extra column balance table stating whether covariate balanced according threshold, extra table balance table tally many covariates balanced according threshold, notice covariate greatest imbalance conditioning whether exceeded threshold. , thresholds requested mean differences (m) variance ratios (v). simplify output many covariates included int = TRUE specified, imbalanced.can set TRUE, reveal imbalanced covariates output. covariates failed meet balance thresholds set. addition, disp.bal.tab can set FALSE, hide balance table (revealing balance summaries accompanying threshold). sampling weights used applied adjusted unadjusted groups, can specified argument s.weights, can specified either providing vector sampling weights unit providing name variable data containing sampling weights. adjusted unadjusted samples weighted sampling weights multiplying adjustment weights () sampling weights. possible view balance one set weights time. input weights either names variables data containing desired weights named data frame containing set weights. arguments s.d.denom estimand must length number sets weights, else length 1, applying sole input sets weights. example comparing weights estimated new set weights. Another example can found section “Comparing Balancing Methods”. subclassification used conditioning, argument subclass must specified; can vector subclass membership name variable data containing subclass membership. bal.tab() produces different type output matching weighting used, though features. default output balance table displaying balance aggregated across subclasses; can controlled subclass.summary options. cell contains average statistic across subclasses. Using arguments discussed change output matching weighting used. examine balance within subclass, user can specify .subclass = ., produce output subclasses aggregate. Within subclasses, information , including requested statistics, presented, except statistics unadjusted groups (since adjustment occurs creating subclasses), specified user. See ?bal.tab.subclass details. using bal.tab() continuous treatments, default balance statistic presented (weighted) Pearson correlation covariate treatment. Zhu, Coffman, Ghosh (2015) recommend absolute correlations greater 0.1, correlations ideally close zero possible. Spearman correlations can also requested. See section “Using cobalt continuous treatments” ?balance.stats details. next two sections describe use bal.tab() MatchIt WeightIt. stated , arguments controlling calculations display largely across inputs types, described except use differs described present section.","code":"data(\"lalonde\", package = \"cobalt\") #If not yet loaded covs <- subset(lalonde, select = -c(treat, re78, nodegree, married))  # Generating ATT weights as specified in Austin (2011) lalonde$p.score <- glm(treat ~ age + educ + race + re74 + re75,                        data = lalonde,                        family = \"binomial\")$fitted.values lalonde$att.weights <- with(lalonde, treat + (1-treat)*p.score/(1-p.score))  bal.tab(covs, treat = lalonde$treat, weights = lalonde$att.weights) ## Balance Measures ##                Type Diff.Adj ## age         Contin.   0.1112 ## educ        Contin.  -0.0641 ## race_black   Binary  -0.0044 ## race_hispan  Binary   0.0016 ## race_white   Binary   0.0028 ## re74        Contin.  -0.0039 ## re75        Contin.  -0.0428 ##  ## Effective sample sizes ##            Control Treated ## Unadjusted   429.      185 ## Adjusted     108.2     185 bal.tab(treat ~ covs, data = lalonde,         weights = \"att.weights\",         distance = \"p.score\") ## Balance Measures ##                 Type Diff.Adj ## p.score     Distance  -0.0397 ## age          Contin.   0.1112 ## educ         Contin.  -0.0641 ## race_black    Binary  -0.0044 ## race_hispan   Binary   0.0016 ## race_white    Binary   0.0028 ## re74         Contin.  -0.0039 ## re75         Contin.  -0.0428 ##  ## Effective sample sizes ##            Control Treated ## Unadjusted   429.      185 ## Adjusted     108.2     185 bal.tab(treat ~ covs, data = lalonde,         weights = \"att.weights\",         binary = \"std\", continuous = \"std\") ## Balance Measures ##                Type Diff.Adj ## age         Contin.   0.1112 ## educ        Contin.  -0.0641 ## race_black   Binary  -0.0120 ## race_hispan  Binary   0.0068 ## race_white   Binary   0.0093 ## re74        Contin.  -0.0039 ## re75        Contin.  -0.0428 ##  ## Effective sample sizes ##            Control Treated ## Unadjusted   429.      185 ## Adjusted     108.2     185 # Balance on all covariates in data set, including interactions and squares bal.tab(treat ~ covs, data = lalonde,         weights = \"att.weights\",         addl = ~ nodegree + married,         int = TRUE, poly = 2) ## Balance Measures ##                             Type Diff.Adj ## age                      Contin.   0.1112 ## educ                     Contin.  -0.0641 ## race_black                Binary  -0.0044 ## race_hispan               Binary   0.0016 ## race_white                Binary   0.0028 ## re74                     Contin.  -0.0039 ## re75                     Contin.  -0.0428 ## nodegree                  Binary   0.1151 ## married                   Binary  -0.0938 ## age²                     Contin.  -0.0194 ## educ²                    Contin.  -0.1353 ## re74²                    Contin.   0.0675 ## re75²                    Contin.   0.0196 ## age * educ               Contin.   0.0950 ## age * race_black         Contin.   0.0741 ## age * race_hispan        Contin.  -0.0096 ## age * race_white         Contin.  -0.0013 ## age * re74               Contin.  -0.0498 ## age * re75               Contin.  -0.0144 ## age * nodegree_0         Contin.  -0.1950 ## age * nodegree_1         Contin.   0.2507 ## age * married_0          Contin.   0.3612 ## age * married_1          Contin.  -0.2843 ## educ * race_black        Contin.  -0.0441 ## educ * race_hispan       Contin.   0.0122 ## educ * race_white        Contin.   0.0085 ## educ * re74              Contin.  -0.0149 ## educ * re75              Contin.  -0.0834 ## educ * nodegree_0        Contin.  -0.2655 ## educ * nodegree_1        Contin.   0.3051 ## educ * married_0         Contin.   0.2016 ## educ * married_1         Contin.  -0.2453 ## race_black * re74        Contin.   0.0477 ## race_black * re75        Contin.  -0.0297 ## race_black * nodegree_0   Binary  -0.1110 ## race_black * nodegree_1   Binary   0.1067 ## race_black * married_0    Binary   0.0535 ## race_black * married_1    Binary  -0.0579 ## race_hispan * re74       Contin.  -0.0129 ## race_hispan * re75       Contin.   0.0258 ## race_hispan * nodegree_0  Binary  -0.0068 ## race_hispan * nodegree_1  Binary   0.0084 ## race_hispan * married_0   Binary   0.0076 ## race_hispan * married_1   Binary  -0.0060 ## race_white * re74        Contin.  -0.2488 ## race_white * re75        Contin.  -0.0926 ## race_white * nodegree_0   Binary   0.0027 ## race_white * nodegree_1   Binary   0.0001 ## race_white * married_0    Binary   0.0327 ## race_white * married_1    Binary  -0.0300 ## re74 * re75              Contin.   0.0636 ## re74 * nodegree_0        Contin.  -0.0464 ## re74 * nodegree_1        Contin.   0.0467 ## re74 * married_0         Contin.   0.1108 ## re74 * married_1         Contin.  -0.1122 ## re75 * nodegree_0        Contin.  -0.3656 ## re75 * nodegree_1        Contin.   0.1487 ## re75 * married_0         Contin.   0.1093 ## re75 * married_1         Contin.  -0.1177 ## nodegree_0 * married_0    Binary  -0.0134 ## nodegree_0 * married_1    Binary  -0.1017 ## nodegree_1 * married_0    Binary   0.1072 ## nodegree_1 * married_1    Binary   0.0079 ##  ## Effective sample sizes ##            Control Treated ## Unadjusted   429.      185 ## Adjusted     108.2     185 # Balance tables with mean differences, variance ratios, and  #  statistics for the unadjusted sample bal.tab(treat ~ covs, data = lalonde,         weights = \"att.weights\",         disp = c(\"means\", \"sds\"), un = TRUE,          stats = c(\"mean.diffs\", \"variance.ratios\")) ## Balance Measures ##                Type    M.0.Un   SD.0.Un    M.1.Un   SD.1.Un Diff.Un V.Ratio.Un ## age         Contin.   28.0303   10.7867   25.8162    7.1550 -0.3094     0.4400 ## educ        Contin.   10.2354    2.8552   10.3459    2.0107  0.0550     0.4959 ## race_black   Binary    0.2028         .    0.8432         .  0.6404          . ## race_hispan  Binary    0.1422         .    0.0595         . -0.0827          . ## race_white   Binary    0.6550         .    0.0973         . -0.5577          . ## re74        Contin. 5619.2365 6788.7508 2095.5737 4886.6204 -0.7211     0.5181 ## re75        Contin. 2466.4844 3291.9962 1532.0553 3219.2509 -0.2903     0.9563 ##               M.0.Adj  SD.0.Adj   M.1.Adj  SD.1.Adj Diff.Adj V.Ratio.Adj ## age           25.0205   10.0330   25.8162    7.1550   0.1112      0.5086 ## educ          10.4748    2.5918   10.3459    2.0107  -0.0641      0.6018 ## race_black     0.8476         .    0.8432         .  -0.0044           . ## race_hispan    0.0578         .    0.0595         .   0.0016           . ## race_white     0.0945         .    0.0973         .   0.0028           . ## re74        2114.5263 4013.9557 2095.5737 4886.6204  -0.0039      1.4821 ## re75        1669.9618 2974.6678 1532.0553 3219.2509  -0.0428      1.1712 ##  ## Effective sample sizes ##            Control Treated ## Unadjusted   429.      185 ## Adjusted     108.2     185 # Balance tables with thresholds for mean differences and variance ratios bal.tab(treat ~ covs, data = lalonde,         weights = \"att.weights\",         thresholds = c(m = .1, v = 2)) ## Balance Measures ##                Type Diff.Adj        M.Threshold V.Ratio.Adj  V.Threshold ## age         Contin.   0.1112 Not Balanced, >0.1      0.5086 Balanced, <2 ## educ        Contin.  -0.0641     Balanced, <0.1      0.6018 Balanced, <2 ## race_black   Binary  -0.0044     Balanced, <0.1           .              ## race_hispan  Binary   0.0016     Balanced, <0.1           .              ## race_white   Binary   0.0028     Balanced, <0.1           .              ## re74        Contin.  -0.0039     Balanced, <0.1      1.4821 Balanced, <2 ## re75        Contin.  -0.0428     Balanced, <0.1      1.1712 Balanced, <2 ##  ## Balance tally for mean differences ##                    count ## Balanced, <0.1         6 ## Not Balanced, >0.1     1 ##  ## Variable with the greatest mean difference ##  Variable Diff.Adj        M.Threshold ##       age   0.1112 Not Balanced, >0.1 ##  ## Balance tally for variance ratios ##                  count ## Balanced, <2         4 ## Not Balanced, >2     0 ##  ## Variable with the greatest variance ratio ##  Variable V.Ratio.Adj  V.Threshold ##       age      0.5086 Balanced, <2 ##  ## Effective sample sizes ##            Control Treated ## Unadjusted   429.      185 ## Adjusted     108.2     185 # Generating ATT weights with different covariates lalonde$p.score2 <- glm(treat ~ age + I(age^2) + race + educ + re74,                          data = lalonde,                         family = \"binomial\")$fitted.values lalonde$att.weights2 <- with(lalonde, treat + (1-treat)*p.score2/(1-p.score2))  bal.tab(treat ~ covs, data = lalonde,         weights = c(\"att.weights\", \"att.weights2\"),         estimand = \"ATT\") ## Balance Measures ##                Type Diff.att.weights Diff.att.weights2 ## age         Contin.           0.1112           -0.0400 ## educ        Contin.          -0.0641           -0.0227 ## race_black   Binary          -0.0044           -0.0005 ## race_hispan  Binary           0.0016           -0.0010 ## race_white   Binary           0.0028            0.0015 ## re74        Contin.          -0.0039            0.0037 ## re75        Contin.          -0.0428           -0.0083 ##  ## Effective sample sizes ##              Control Treated ## All           429.       185 ## att.weights   108.2      185 ## att.weights2   72.04     185 # Subclassification for ATT with 5 subclasses lalonde$p.score <- glm(treat ~ age + educ + race + re74 + re75,                        data = lalonde,                         family = \"binomial\")$fitted.values nsub <- 5 #number of subclasses lalonde$subclass <- with(lalonde,                          findInterval(p.score,                                        quantile(p.score[treat == 1],                                                 seq(0, 1, length.out = nsub + 1)),                                        all.inside = TRUE))                           bal.tab(treat ~ covs, data = lalonde,         subclass = \"subclass\",          which.subclass = .all,         subclass.summary = TRUE) ## Balance by subclass ##  - - - Subclass 1 - - -  ##                Type Diff.Adj ## age         Contin.  -0.4889 ## educ        Contin.   0.1324 ## race_black   Binary   0.1934 ## race_hispan  Binary   0.1230 ## race_white   Binary  -0.3164 ## re74        Contin.  -0.2334 ## re75        Contin.  -0.0435 ##  ##  - - - Subclass 2 - - -  ##                Type Diff.Adj ## age         Contin.  -0.4423 ## educ        Contin.   0.3102 ## race_black   Binary   0.0000 ## race_hispan  Binary   0.0000 ## race_white   Binary   0.0000 ## re74        Contin.   0.0584 ## re75        Contin.   0.3445 ##  ##  - - - Subclass 3 - - -  ##                Type Diff.Adj ## age         Contin.   0.4968 ## educ        Contin.  -0.1031 ## race_black   Binary   0.0000 ## race_hispan  Binary   0.0000 ## race_white   Binary   0.0000 ## re74        Contin.  -0.1250 ## re75        Contin.  -0.1912 ##  ##  - - - Subclass 4 - - -  ##                Type Diff.Adj ## age         Contin.   0.2665 ## educ        Contin.  -0.1616 ## race_black   Binary   0.0000 ## race_hispan  Binary   0.0000 ## race_white   Binary   0.0000 ## re74        Contin.  -0.1082 ## re75        Contin.  -0.0307 ##  ##  - - - Subclass 5 - - -  ##                Type Diff.Adj ## age         Contin.   0.2946 ## educ        Contin.  -0.0757 ## race_black   Binary   0.0000 ## race_hispan  Binary   0.0000 ## race_white   Binary   0.0000 ## re74        Contin.  -0.0546 ## re75        Contin.  -0.1770 ##  ## Balance measures across subclasses ##                Type Diff.Adj ## age         Contin.   0.0216 ## educ        Contin.   0.0195 ## race_black   Binary   0.0387 ## race_hispan  Binary   0.0246 ## race_white   Binary  -0.0633 ## re74        Contin.  -0.0923 ## re75        Contin.  -0.0170 ##  ## Sample sizes by subclass ##           1  2  3  4  5 All ## Control 350 25 21 14 19 429 ## Treated  37 37 34 40 37 185 ## Total   387 62 55 54 56 614"},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt.html","id":"using-bal-tab-with-matchit","dir":"Articles","previous_headings":"How To Use cobalt > bal.tab()","what":"Using bal.tab() with MatchIt","title":"Covariate Balance Tables and Plots: A Guide to the cobalt Package","text":"using bal.tab() MatchIt, fewer arguments need specified information stored matchit object, output call matchit(). bal.tab() used similarly summary() MatchIt: takes matchit object input, prints balance table requested information. simple example use: output looks similar MatchIt’s summary() function: first balance table, second summary sample size adjustment. Setting binary = \"std\" bal.tab() produce identical calculations MatchIt’s summary(m., standardize = TRUE), produces standardized differences binary variables well continuous variables. arguments bal.tab() using MatchIt form function given using without conditioning package. output using MatchIt subclassification displayed previously.","code":"data(\"lalonde\", package = \"cobalt\")  # Nearest neighbor 2:1 matching with replacement m.out <- MatchIt::matchit(treat ~ age + educ + race + re74 + re75,                            data = lalonde, method = \"nearest\",                            ratio = 1,  replace = TRUE)  bal.tab(m.out) ## Balance Measures ##                 Type Diff.Adj ## distance    Distance  -0.0010 ## age          Contin.   0.1964 ## educ         Contin.  -0.0726 ## race_black    Binary   0.0108 ## race_hispan   Binary  -0.0054 ## race_white    Binary  -0.0054 ## re74         Contin.   0.0667 ## re75         Contin.   0.0936 ##  ## Sample sizes ##                      Control Treated ## All                   429.       185 ## Matched (ESS)          36.45     185 ## Matched (Unweighted)   77.       185 ## Unmatched             352.         0"},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt.html","id":"using-bal-tab-with-weightit","dir":"Articles","previous_headings":"How To Use cobalt > bal.tab()","what":"Using bal.tab() with WeightIt","title":"Covariate Balance Tables and Plots: A Guide to the cobalt Package","text":"WeightIt package convenient wrapper weighting functions several packages, including twang, CBPS, ebal, sbw, ATE, allows estimation weights binary, multi-category, categorical treatments point longitudinal treatments. designed work seamlessly cobalt, using cobalt straightforward. simple example using bal.tab() WeightIt:","code":"data(\"lalonde\", package = \"cobalt\") #If not yet loaded  #Generating propensity score weights for the ATT W.out <- WeightIt::weightit(treat ~ age + educ + race + re74 + re75,                             data = lalonde,                             method = \"ps\",                             estimand = \"ATT\")  bal.tab(W.out) ## Balance Measures ##                 Type Diff.Adj ## prop.score  Distance  -0.0397 ## age          Contin.   0.1112 ## educ         Contin.  -0.0641 ## race_black    Binary  -0.0044 ## race_hispan   Binary   0.0016 ## race_white    Binary   0.0028 ## re74         Contin.  -0.0039 ## re75         Contin.  -0.0428 ##  ## Effective sample sizes ##            Control Treated ## Unadjusted   429.      185 ## Adjusted     108.2     185"},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt.html","id":"bal-plot","dir":"Articles","previous_headings":"How To Use cobalt","what":"bal.plot()","title":"Covariate Balance Tables and Plots: A Guide to the cobalt Package","text":"gold standard covariate balance multidimensional independence treatment covariates. hard visualize assess large numbers covariates typical causal effect analysis, univariate balance typically assessed proxy. conditioning packages, well cobalt, provide numerical summaries balance, typically comparing moments treated control groups. even univariate balance complicated simple numerical summaries can address; examining distributional balance thorough method assess balance groups. Although statistics Kolmogorov-Smirnov statistics overlapping coefficient attempt summarize distributional balance beyond first moments (Austin Stuart 2015; Ali et al. 2015), complimenting statistics visual examination distributional densities can effective way assessing distributional similarity groups (Ho et al. 2007). bal.plot() allows users displaying density plots, histograms, empirical CDF plots, bar graphs, scatterplots users can visually assess independence treatment covariates conditioning. example use bal.plot() using propensity score weighting ATT using output WeightIt generated .:  first argument (set arguments) sufficient set arguments simple call bal.tab(), defining data object (e.g., output conditioning function), treatment indicators, weights subclasses. See examples. next argument name covariate distributional balance assessed. subclassification used (.e., subclasses present input data object arguments), additional argument .sub can specified, number corresponding subclass number balance assessed specified covariate; specified, plots subclasses displayed. user can also specify whether distributional balance shown adjusting using argument . = \"unadjusted\", balance displayed unadjusted sample . = \"\", balance displayed unadjusted sample adjusted sample. default display balance adjusted sample. output bal.plot() density plot, histogram, empirical CDF plot two groups given covariate, depending argument type. categorical binary variables, bar graph displayed instead. multi-category categorical variables given, bars created level, unlike bal.tab(), splits variable several binary variables. degree densities two groups overlap good measure group balance given covariate; significant differences shape can indicative poor balance, even mean differences variance ratios well within thresholds. Strong distributional similarity especially important variables strongly related outcome interest. Distributional balance can also assessed distance measure, can form alternative common support checks, like MatchIt’s plot(..., type = \"hist\") twang’s plot(..., plots = \"boxplot\"). examine distributions distance measure, input var.name must name distance variable. data input object doesn’t already contain distance measure (e.g., using one conditioning packages), distance measure must manually added input bal.plot() distance, addition called var.name. example using bal.plot() display distributions propensity scores weighting adjustment:  Setting type = \"histogram\" produces histogram rather density plot, setting mirror = TRUE creates mirrored plot rather overlapping histograms. Mirroring works binary treatments. generally useful assessment balance examine overlap distance measure distributions adjustment, conditioning methods yield good distributional overlap distance measure whether balance achieved covariates (Stuart, Lee, Leacy 2013). However, may useful see new range distance measure calipers common support pruning used. output plot made using ggplot2, means users familiar ggplot2 can adjust plot ggplot2 commands. treatment variable continuous, users can use bal.plot() examine assess dependence covariate treatment. arguments given bal.plot() binary treatment case, resulting plots different. covariate continuous, scatterplot covariate treatment variable displayed, along linear fit line, Loess curve, reference line indicating linear independence. Used together, lines can help diagnose departures independence beyond simple correlation coefficient. Proximity fit lines reference line suggestive independence covariate treatment variable. covariate categorical (including binary), density plots treatment variable category displayed. Densities overlap completely indicative independence covariate treatment. See section “Using cobalt continuous treatments” details example.","code":"bal.plot(W.out, var.name = \"age\") bal.plot(W.out, var.name = \"race\") #Before and after weighting; which = \"both\" bal.plot(W.out, var.name = \"prop.score\",          which = \"both\",          type = \"histogram\",          mirror = TRUE)"},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt.html","id":"love-plot","dir":"Articles","previous_headings":"How To Use cobalt","what":"love.plot()","title":"Covariate Balance Tables and Plots: A Guide to the cobalt Package","text":"Love plot summary plot covariate balance conditioning popularized Dr. Thomas E. Love. visually appealing clear way, balance can presented demonstrate readers balance met within threshold, balance improved conditioning [always case; cf. King Nielsen (2019)]. love.plot() just , providing user several options customize plot presentation. example use:  love.plot() takes arguments ones go call bal.tab(). addition, can take first argument output call bal.tab(); can accomplished simply inserting bal.tab() call first argument saving result call bal.tab() object inserting object argument. several arguments, control display, described . output plot balance statistic X-axis covariates output bal.tab() Y-axis. point represents balance statistic covariate, colored based whether calculated adjustment. dotted lines represent threshold set threshold argument; points adjustment within threshold, good evidence balance achieved. default present absolute mean differences calculated call bal.tab(); specifying stats = \"variance.ratios\" stats = \"ks.statistics\" (abbreviations allowed), user can request variance ratios KS statistics instead addition. binary variables don’t variance ratios calculated, rows variables, rows can added (empty entries) alignment mean differences setting drop.missing = FALSE. thresholds argument works similarly bal.tab(); specifying optional, provide additional point reference evaluate displayed balance measures. mean difference requested, love.plot() use mean differences calculated bal.tab() presented mean differences columns balance table. See section using bal.tab() see default calculations values. abs = TRUE love.plot(), plot display absolute mean differences, can aid display clarity since magnitude generally important aspect statistic. order covariates displayed can adjusted using argument var.order. left empty NULL, covariates listed order original dataset. \"adjusted\", covariates ordered requested balance statistic adjusted sample. \"unadjusted\", covariates ordered requested balance statistic unadjusted sample, tends visually appealing. Abbreviations allowed. distance variable(s), , always displayed top. can omitted setting drop.distance = TRUE. plot uses original variable names given data set, may names desired display publication. using argument var.names, users can specify variable names used instead. specify new variable names var.names, user must enter object containing new variable names , optionally, old variable names replace. options , see help file love.plot() ?love.plot. example, creating publication-ready plot arguments customize output:  plot shows balance improved almost variables adjustment, bringing two threshold .1 absolute mean differences. helper function, var.names() can used easily create new variable names many variables present. See ?var.names details. treatment variable continuous, love.plot() display Pearson correlations covariate treatment. arguments apply except stats ignored threshold corresponds r.threshold, threshold correlations. Like output bal.plot(), output love.plot() ggplot2 object, means ggplot2 users can modify plot extent presentation publication. Several aspects appearance plot can customized using love.plot() syntax, including size, shape, color points, title plot, whether display grid lines, whether display lines connecting points. See ?love.plot details. may challenging make adjustments aspects using ggplot2 syntax, arguments allow simple adjustments. See Appendix 4: Using love.plot Generate Love Plots information love.plot()’s features.","code":"data(\"lalonde\", package = \"cobalt\")  # Nearest neighbor 1:1 matching with replacement m.out <- MatchIt::matchit(treat ~ age + educ + married + race +                               nodegree + re74 + re75,                           data = lalonde,                            method = \"nearest\",                           replace = TRUE)  love.plot(m.out, binary = \"std\", thresholds = c(m = .1)) v <- data.frame(old = c(\"age\", \"educ\", \"race_black\", \"race_hispan\",                          \"race_white\", \"married\", \"nodegree\", \"re74\", \"re75\", \"distance\"),                 new = c(\"Age\", \"Years of Education\", \"Black\",                          \"Hispanic\", \"White\", \"Married\", \"No Degree Earned\",                          \"Earnings 1974\", \"Earnings 1975\", \"Propensity Score\"))  love.plot(m.out, stats = c(\"mean.diffs\", \"ks.statistics\"),            threshold = c(m = .1, ks = .05),            binary = \"std\",           abs = TRUE,           var.order = \"unadjusted\",           var.names = v,           limits = c(0, 1),           grid = FALSE,           wrap = 20,           sample.names = c(\"Unmatched\", \"Matched\"),           position = \"top\",           shapes = c(\"circle\", \"triangle\"),           colors = c(\"red\", \"blue\"))"},{"path":[]},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt.html","id":"using-cobalt-with-continuous-treatments","dir":"Articles","previous_headings":"Additional Features","what":"Using cobalt with continuous treatments","title":"Covariate Balance Tables and Plots: A Guide to the cobalt Package","text":"Although common use propensity scores context binary treatments, also possible use propensity scores continuous treatment estimate dose-response functions controlling background variables (Hirano Imbens 2005). binary case, goal propensity score adjustment continuous case arrive scenario , conditional propensity score, treatment independent background covariates. true (unmeasured confounders), treatment also independent potential outcomes, thereby meeting strong ignorability requirement causal inference. Bia Mattei (2008) describe use gpscore function Stata, appears effective estimating assessing dose-response functions continuous treatments. R, many ways estimate condition propensity score contexts. possible, using formulas described Hirano Imbens (2005), generate propensity scores manually perform weighting, subclassification, covariate adjustment . WeightIt package supports continuous treatments variety options, including CBPS method implemented CBPS package described Fong, Hazlett, Imai (2018), GBM described Zhu, Coffman, Ghosh (2015), entropy balancing described Vegetabile et al. (2021), among others. cobalt, users can assess present balance continuous treatments using bal.tab(), bal.plot(), love.plot(), just binary treatments. syntax almost identical cases regardless type treatment variable considered, differences specifics worth noting. approach cobalt takes assessing balance display correlations covariate treatment variable, approach used CBPS described Zhu, Coffman, Ghosh (2015) Austin (2019), described Hirano Imbens (2005) implemented gpscore (Bia Mattei 2008), involves stratifying treatment variable propensity score calculating mean differences. Note weighted correlations use unweighted standard deviations treatment variable covariate denominator, correlations 1 may observed rare cases. addition assessing treatment-covariate correlations, important assess degree adjusted sample representative original target population. weighted sample differs greatly original sample, estimated effect may biased target population interest, even covariates independent treatment. cobalt offers methods compare weighted sample unweighted sample context continuous treatments, computing standardized mean difference KS statistic weighted unweighted sample covariate. example workflow using propensity scores continuous treatments WeightIt package. demonstrate, use lalonde package included cobalt, using arbitrary continuous variable treatment, though substantively analysis makes little sense. First, can assess balance numerically using bal.tab(). main balance statistic used Pearson correlation covariate treatment variable. threshold balance correlations can specified using thresholds; Zhu, Coffman, Ghosh (2015) recommend using .1 indicating balance, general lower better. goal complete independence treatment covariates, simply absence linear correlation treatment covariates, including interactions polynomial terms use arguments int poly recommended (just display use poly brevity). addition treatment-covariate correlations, request standardized mean difference weighted unweighted samples include \"m\" (\"mean.diffs.target\") argument stats along \"c\" (\"correlations\"). can also visually assess balance using bal.plot(). continuous covariates, bal.plot() displays scatterplot treatment covariate, includes linear fit line (red), smoothed fit curve (blue), horizontal reference line (black) unweighted mean treatment variable, vertical line unweighted mean covariate. lines can used diagnose dependence. either fit line close flat lying top reference line, may remaining dependence treatment covariate. points weighted plot shaded according size corresponding weight. linear fit line (red) cross intersection black reference lines, target population weighted estimate differs original population. categorical covariates, including binary, bal.plot() displays density plot treatment variable category. treatment covariate independent, densities category overlap . distinct lack overlap indicative remaining dependence treatment covariate.   balance achieved satisfactory level, users can present balance improvements Love plot using love.plot() command, just binary treatments.","code":"data(\"lalonde\", package = \"cobalt\")  #Generating weights with re75 as the continuous treatment W.out.c <- WeightIt::weightit(re75 ~ age + educ + race + married +                                   nodegree + re74 + I(re74^2),                                data = lalonde,                               method = \"ps\") #Assessing balance numerically bal.tab(W.out.c, stats = c(\"c\", \"m\"), un = TRUE,          thresholds = c(cor = .1), poly = 3) ## Balance Measures ##                Type Corr.Un Corr.Adj        R.Threshold Diff.Adj ## age         Contin.  0.1400   0.0165     Balanced, <0.1  -0.1552 ## educ        Contin.  0.0183   0.0573     Balanced, <0.1  -0.0392 ## race_black   Binary -0.1405   0.0499     Balanced, <0.1   0.1139 ## race_hispan  Binary  0.0616   0.0637     Balanced, <0.1  -0.1379 ## race_white   Binary  0.0978  -0.0899     Balanced, <0.1  -0.0227 ## married      Binary  0.3541   0.0249     Balanced, <0.1  -0.2152 ## nodegree     Binary -0.0705  -0.0409     Balanced, <0.1  -0.0159 ## re74        Contin.  0.5520  -0.0904     Balanced, <0.1  -0.3843 ## age²        Contin.  0.0998  -0.0160     Balanced, <0.1  -0.1426 ## educ²       Contin.  0.0312   0.0849     Balanced, <0.1  -0.0328 ## re74²       Contin.  0.4607  -0.1631 Not Balanced, >0.1  -0.3904 ## I(re74^2)²  Contin.  0.3142  -0.1591 Not Balanced, >0.1  -0.2725 ## age³        Contin.  0.0627  -0.0436     Balanced, <0.1  -0.1293 ## educ³       Contin.  0.0361   0.0911     Balanced, <0.1  -0.0257 ## re74³       Contin.  0.3790  -0.1755 Not Balanced, >0.1  -0.3418 ## I(re74^2)³  Contin.  0.2230  -0.0989     Balanced, <0.1  -0.1385 ##  ## Balance tally for treatment correlations ##                    count ## Balanced, <0.1        13 ## Not Balanced, >0.1     3 ##  ## Variable with the greatest treatment correlation ##  Variable Corr.Adj        R.Threshold ##     re74³  -0.1755 Not Balanced, >0.1 ##  ## Effective sample sizes ##             Total ## Unadjusted 614.   ## Adjusted   181.28 #Assessing balance graphically bal.plot(W.out.c, \"re74\", which = \"both\") bal.plot(W.out.c, \"married\", which = \"both\") #Summarizing balance in a Love plot love.plot(W.out.c, stats = c(\"c\", \"ks\"),           thresholds = c(cor = .1),            abs = TRUE, wrap = 20,           var.order = \"unadjusted\", line = TRUE)"},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt.html","id":"using-cobalt-with-multi-category-treatments","dir":"Articles","previous_headings":"Additional Features","what":"Using cobalt with multi-category treatments","title":"Covariate Balance Tables and Plots: A Guide to the cobalt Package","text":"multiple categorical treatment groups compared , possible create balance across treatment groups using preprocessing methods. Lopez Gutman (2017) compare methods used create balance multi-category treatments briefly describe balance assessment scenarios. important note choice estimand examined. ATE represents causal effect moving one treatment group another units population; ATT represents causal effect moving one treatment group another “focal” treatment group just units focal treatment group. way balance assessed scenarios differs. ATE, possible treatment pairs must assessed balance possible comparisons potentially meaningful, ATT, treatment pairs include focal treatment group can meaningfully compared, balance needs assessed pairs. cobalt, users can assess present balance multi-category treatments using bal.tab(), bal.plot(), love.plot(), just binary treatments. output slightly different, though, similar output generated using functions clusters. bal.tab() computes balance statistics pairwise comparisons treatment groups table containing worst balance covariate across pairwise comparisons. mean differences, described Lopez Gutman (2017) “Max2SB,” maximum pairwise standardized bias. cobalt, extended variance ratios KS statistics well. worst imbalance great, imbalance pairwise comparisons great either. ATT desired, focal group must specified (unless done automatically methods), treatment group comparisons involve focal group computed displayed. love.plot() allows display pairwise treatment range balance across treatment pairs covariate. bal.plot() displays distributional balance requested covariate across treatment groups. Currently, multi-category treatments supported clustered multiply imputed data. example using cobalt multi-category treatments. example, race “treatment”; type analysis meant causal, rather represents method examine disparities among groups accounting covariates might otherwise explain differences among groups. use WeightIt generate balanced groups estimating propensity score weights multinomial logistic regression. First, can examine balance numerically using bal.tab(). three possible pairwise comparisons, can requested .treat = .. See ?bal.tab.multi details. can also assess balance graphically. guidelines apply multi-category treatments binary treatments. Ideally, covariate distributions look similar across treatment groups.   Finally, can use love.plot() display balance across treatments. default, love.plot() displays values summary across pairwise comparisons. request individual treatment comparisons, use .treat = .love.plot().","code":"data(\"lalonde\", package = \"cobalt\")  #Using WeightIt to generate weights with multinomial #logistic regression W.out.mn <- WeightIt::weightit(race ~ age + educ + married +                                    nodegree + re74 + re75,                                data = lalonde,                                method = \"ps\",                                use.mlogit = FALSE) #Balance summary across treatment pairs bal.tab(W.out.mn, un = TRUE) ## Balance summary across all treatment pairs ##             Type Max.Diff.Un Max.Diff.Adj ## age      Contin.      0.3065       0.0504 ## educ     Contin.      0.5861       0.1046 ## married   Binary      0.3430       0.0355 ## nodegree  Binary      0.2187       0.0438 ## re74     Contin.      0.6196       0.1445 ## re75     Contin.      0.3442       0.1462 ##  ## Effective sample sizes ##            black hispan  white ## Unadjusted 243.   72.   299.   ## Adjusted   140.5  54.32 259.28 #Assessing balance for each pair of treatments bal.tab(W.out.mn, un = TRUE,         disp.means = TRUE,         which.treat = .all) ## Balance by treatment pair ##  ##  - - - black (0) vs. hispan (1) - - -  ## Balance Measures ##             Type    M.0.Un    M.1.Un Diff.Un   M.0.Adj   M.1.Adj Diff.Adj ## age      Contin.   26.0123   25.9167 -0.0101   26.6302   27.0937   0.0491 ## educ     Contin.   10.2346    9.0139 -0.4515   10.4977   10.2149  -0.1046 ## married   Binary    0.2222    0.4444  0.2222    0.4124    0.3781  -0.0343 ## nodegree  Binary    0.6955    0.7639  0.0684    0.5998    0.6436   0.0438 ## re74     Contin. 2499.4492 4431.6260  0.3183 5447.2370 4836.5681  -0.1006 ## re75     Contin. 1613.7752 2741.3920  0.3442 2654.8185 2196.7393  -0.1398 ##  ## Effective sample sizes ##            black hispan ## Unadjusted 243.   72.   ## Adjusted   140.5  54.32 ##  ##  - - - black (0) vs. white (1) - - -  ## Balance Measures ##             Type    M.0.Un    M.1.Un Diff.Un   M.0.Adj   M.1.Adj Diff.Adj ## age      Contin.   26.0123   28.8094  0.2963   26.6302   27.1058   0.0504 ## educ     Contin.   10.2346   10.5987  0.1347   10.4977   10.2982  -0.0738 ## married   Binary    0.2222    0.5652  0.3430    0.4124    0.4136   0.0011 ## nodegree  Binary    0.6955    0.5452 -0.1503    0.5998    0.6265   0.0267 ## re74     Contin. 2499.4492 6260.5029  0.6196 5447.2370 4570.1106  -0.1445 ## re75     Contin. 1613.7752 2515.1320  0.2752 2654.8185 2175.8306  -0.1462 ##  ## Effective sample sizes ##            black  white ## Unadjusted 243.  299.   ## Adjusted   140.5 259.28 ##  ##  - - - hispan (0) vs. white (1) - - -  ## Balance Measures ##             Type    M.0.Un    M.1.Un Diff.Un   M.0.Adj   M.1.Adj Diff.Adj ## age      Contin.   25.9167   28.8094  0.3065   27.0937   27.1058   0.0013 ## educ     Contin.    9.0139   10.5987  0.5861   10.2149   10.2982   0.0308 ## married   Binary    0.4444    0.5652  0.1208    0.3781    0.4136   0.0355 ## nodegree  Binary    0.7639    0.5452 -0.2187    0.6436    0.6265  -0.0171 ## re74     Contin. 4431.6260 6260.5029  0.3013 4836.5681 4570.1106  -0.0439 ## re75     Contin. 2741.3920 2515.1320 -0.0691 2196.7393 2175.8306  -0.0064 ##  ## Effective sample sizes ##            hispan  white ## Unadjusted  72.   299.   ## Adjusted    54.32 259.28 ##  - - - - - - - - - - - - - - - - - - - - - - - - #Assessing balance graphically bal.plot(W.out.mn, \"age\", which = \"both\") bal.plot(W.out.mn, \"married\", which = \"both\") #Summarizing balance in a Love plot love.plot(W.out.mn, thresholds = c(m = .1), binary = \"std\",           which.treat = .all, abs = FALSE)"},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt.html","id":"comparing-balancing-methods","dir":"Articles","previous_headings":"Additional Features","what":"Comparing balancing methods","title":"Covariate Balance Tables and Plots: A Guide to the cobalt Package","text":"possible display balance multiple balancing methods time bal.tab(), bal.plot(), love.plot(). , weights generated balancing method need supplied together call. can done supplying weights output objects . example, can compare matching inverse probability weighting ATT using following code output generated . use bal.plot(), syntax can used:  love.plot(), var.order can \"unadjusted\", \"alphabetical\", one names weights order variables. Also, colors shapes length number weights length 1.  Another way compare weights multiple objects call bal.tab() one object usual supply (s) weights argument; see example:","code":"bal.tab(treat ~ age + educ + married + race +             nodegree + re74 + re75, data = lalonde,          weights = list(Matched = m.out,                        IPW = W.out),         disp.v.ratio = TRUE) ## Balance Measures ##                Type Diff.Matched V.Ratio.Matched Diff.IPW V.Ratio.IPW ## age         Contin.       0.2395          0.5557   0.1112      0.5086 ## educ        Contin.      -0.0161          0.5765  -0.0641      0.6018 ## married      Binary       0.0595               .  -0.0938           . ## race_black   Binary       0.0054               .  -0.0044           . ## race_hispan  Binary      -0.0054               .   0.0016           . ## race_white   Binary       0.0000               .   0.0028           . ## nodegree     Binary       0.0054               .   0.1151           . ## re74        Contin.      -0.0493          1.0349  -0.0039      1.4821 ## re75        Contin.       0.0087          2.1264  -0.0428      1.1712 ##  ## Effective sample sizes ##         Control Treated ## All      429.       185 ## Matched   43.49     185 ## IPW      108.2      185 bal.plot(treat ~ age, data = lalonde,           weights = list(Matched = m.out,                         IPW = W.out),          var.name = \"age\", which = \"both\") love.plot(treat ~ age + educ + married + race +               nodegree + re74 + re75,           data = lalonde,            weights = list(Matched = m.out,                          IPW = W.out),           var.order = \"unadjusted\", binary = \"std\",           abs = TRUE, colors = c(\"red\", \"blue\", \"darkgreen\"),            shapes = c(\"circle\", \"square\", \"triangle\"),           line = TRUE) bal.tab(m.out, weights = list(IPW = W.out))"},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt.html","id":"using-the-prognostic-score-for-balance-assessment","dir":"Articles","previous_headings":"Additional Features","what":"Using the prognostic score for balance assessment","title":"Covariate Balance Tables and Plots: A Guide to the cobalt Package","text":"prognostic score model-predicted outcome individual, excluding treatment variable model (Hansen 2008). Stuart, Lee, Leacy (2013) found prognostic scores can extremely effective tool assessing balance, greatly outperforming mean differences covariates significance tests. true even prognostic score model slightly misspecified. Although use prognostic scores appears violate spirit preprocessing users observe outcome variable prior treatment effect estimation, typically prognostic score model estimated just control group, outcome treated group (may contain treatment effect information) excluded analysis. Assessing balance prognostic score simple cobalt, highly recommended available. steps : Estimate outcome model control group Generate model-predicted outcome values treated control groups Assess balance prognostic scores comparing standardized mean differences use prognostic scores cobalt, simply add prognostic score variable argument distance. example call matchit(): Although prognostic score sensitive outcome estimation model used, defensible prognostic score model can yield valid prognostic scores, can used balance assessment. example, balance estimated prognostic score good, can confidence effect estimate relatively unbiased, even though “age” variable remains imbalanced. logic age highly prognostic variable, demonstrated examining standardized regression output prognostic score model, even though imbalance remains, imbalance unlikely affect effect estimate. variables “re74” “re75”, though, highly prognostic outcome, quite balanced, thereby supporting unbiased treatment effect estimate.","code":"ctrl.data <- lalonde[lalonde$treat == 0,] ctrl.fit <- glm(re78 ~ age + educ + race +                      married + nodegree + re74 + re75,                 data = ctrl.data) lalonde$prog.score <- predict(ctrl.fit, lalonde)  bal.tab(m.out, distance = lalonde[\"prog.score\"]) ## Balance Measures ##                 Type Diff.Adj ## prog.score  Distance  -0.0485 ## distance    Distance   0.0044 ## age          Contin.   0.2395 ## educ         Contin.  -0.0161 ## married       Binary   0.0595 ## race_black    Binary   0.0054 ## race_hispan   Binary  -0.0054 ## race_white    Binary   0.0000 ## nodegree      Binary   0.0054 ## re74         Contin.  -0.0493 ## re75         Contin.   0.0087 ##  ## Sample sizes ##                      Control Treated ## All                   429.       185 ## Matched (ESS)          43.49     185 ## Matched (Unweighted)   80.       185 ## Unmatched             349.         0"},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt.html","id":"details-on-calculations","dir":"Articles","previous_headings":"","what":"Details on Calculations","title":"Covariate Balance Tables and Plots: A Guide to the cobalt Package","text":"calculations cobalt may opaque users; section explains .","code":""},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt.html","id":"variance-in-standardized-mean-differences-and-correlations","dir":"Articles","previous_headings":"Details on Calculations","what":"Variance in Standardized Mean Differences and Correlations","title":"Covariate Balance Tables and Plots: A Guide to the cobalt Package","text":"computing standardized mean difference, raw mean difference divided standard deviation, yielding d-type effect size statistic. bal.tab(), user can control whether standard deviation treated group control group pooled estimate, calculated square root average group variances. applications, standard deviation corresponding default method appropriate. key detail standard deviation, matter computed, always computed using unadjusted sample4. line MatchIt computes standardized mean differences, recommended Stuart [-Stuart (2008); -Stuart (2010)]5. One reason favor use standard deviation unadjusted sample prevents paradoxical situation occurs adjustment decreases mean difference spread sample, yielding larger standardized mean difference prior adjustment, even though adjusted groups now similar. using standard deviation adjusting, change balance isolated change mean difference, rather conflated accompanying change spread. logic applies computing standard deviations appear denominator treatment-covariate correlations used assess balance continuous treatments. Given covariance relevant quality assessed correlation just standardization used simplify interpretation, standardization factor remain adjustment. Thus, standard deviations unadjusted sample used denominator treatment-covariate correlation, even correlation question adjusted sample. Note sampling weights used, values unadjusted sample computed incorporating sampling weights; sense, “adjusted” sampling weights.","code":""},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt.html","id":"weighted-variance","dir":"Articles","previous_headings":"Details on Calculations","what":"Weighted Variance","title":"Covariate Balance Tables and Plots: A Guide to the cobalt Package","text":"using weighting matching, summary values adjustment calculated using weights generated matching weighting process. example, group means computed using standard formula weighted mean, incorporating weighting matching weights calculation. estimate weighted sample variance use variance ratios, sample standard deviations, statistics presence sampling weights, two formulas proposed: \\(\\frac{\\sum_{=1}^{n} w_{}(x_{} - \\bar{x}_{w})^2}{(\\sum_{=1}^{n} w_{}) - 1}\\) \\(\\frac{\\sum_{=1}^{n} w_{}}{(\\sum_{=1}^{n} w_{})^2 - \\sum_{=1}^{n} w^2_{}} \\sum_{=1}^{n} w_{}(x_{} - \\bar{x}_{w})^2\\) weights used first formula often called “frequency weights”, weights second formula often called normalized “reliability weights”. MatchIt, twang, Matching use first formula calculating weighted variance (CBPS compute weighted variance). However, Austin (2008b) Austin Stuart (2015) recommend second formula considering matching weights k:1 matching weights propensity score weighting. cobalt, version 2.0.0, second formula used remain line recommended practice. applications (e.g., weights either 0 1, 1:1 matching), two formulas yield variance estimate. cases, estimates nearly . binary variables, weighted variance computed \\(\\bar{x}_{w}(1-\\bar{x}_{w})\\) \\(\\bar{x}_{w}\\) weighted proportion 1s sample.","code":""},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt.html","id":"effective-sample-size-for-weighting","dir":"Articles","previous_headings":"Details on Calculations","what":"Effective Sample Size for Weighting","title":"Covariate Balance Tables and Plots: A Guide to the cobalt Package","text":"Knowledge sample size adjustment important just outcome analysis also assessing adequacy conditioning specification. example, pruning many units common support cutoffs, caliper matching, matching replacement can yield small sample sizes hurt precision outcome estimate external validity conclusion. matching weighting, adjusted sample size straightforward purpose weighting - -weight observations create two similar samples. “effective sample size” (ESS) measure sample size non-weighted sample achieve level precision weighted sample (Ridgeway 2006). measure implemented twang using following formula: \\[ESS = \\frac{(\\sum_{=1}^{n} w_{})^2}{\\sum_{=1}^{n} w_{}^2}\\]Shook-Sa Hudgens (2020) derived specific relationship ESS standard error propensity score-weighted mean.","code":""},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt.html","id":"whats-missing-in-cobalt","dir":"Articles","previous_headings":"","what":"What’s Missing in cobalt","title":"Covariate Balance Tables and Plots: A Guide to the cobalt Package","text":"fair amount missing cobalt present packages. Though value many aspects cobalt lacks, many purposefully excluded based methodological recommendations conflict current use packages. aspects intentionally missing cobalt users may used packages. reasons exclusion included, hope users cobalt satisfied available confident using methodologically sound tools balance assessment.","code":""},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt.html","id":"test-statistics-and-p-values","dir":"Articles","previous_headings":"What’s Missing in cobalt","what":"Test Statistics and P-values","title":"Covariate Balance Tables and Plots: A Guide to the cobalt Package","text":"early literature propensity score matching included measures balance assessment relied hypothesis tests independence treatment assignment covariates adjustment (e.g., Hansen 2004; Rosenbaum Rubin 1985). review propensity score applications social sciences, Thoemmes Kim (2011) found 66% studies used significance tests assess balance. Likewise, Austin (2008a) found 70% studies using propensity scores medical literature used significance tests assess balance, finding replicated Ali et al. (2015). hypothesis tests can come many forms: t-tests difference means groups, chi-square tests difference proportion groups, Kolmogorov-Smirnov tests difference cumulative density groups, F-tests difference means groups across subclasses. use hypothesis tests appears natural : balance achieved, expect extreme values test statistics, can quantify probability observing imbalance extreme one observed imbalance present way assess whether balance, can standard hypothesis testing. view shared methodological community: many contemporary propensity score methodologists recommend using hypothesis tests balance assessment (e.g., Ho et al. 2007; Imai, King, Stuart 2008; Austin 2011, 2009; Stuart 2010; Thoemmes Kim 2011; Ali et al. 2015). logical reasons preference hypothesis tests, noted clearly Ali et al. (2015) Linden (2014): influenced sample size, fluctuates adjustment, theory behind inappropriate balance quality solely sample question, relation population. relevant information hypothesis test group differences standardized magnitude group difference, measure preferred. hypothesis tests can misleading use discouraged leading methodologists, completely excluded cobalt favor summary statistics. stands contrast twang, Matching, RItools, report hypothesis test p-values balance output.","code":""},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt.html","id":"q-q-plots-and-summaries","dir":"Articles","previous_headings":"What’s Missing in cobalt","what":"Q-Q Plots and Summaries","title":"Covariate Balance Tables and Plots: A Guide to the cobalt Package","text":"Q-Q plots recommended tools assess distributional balance covariates groups (Ho et al. 2007), implemented MatchIt Matching (twang implements different purpose). Statistics summarizing degree imbalance Q-Q plots also reported MatchIt Matching. MatchIt’s summary() command reports “eQQ Mean” “eQQ Max” covariate adjustment. mean maximum distance treated control group empirical Q-Q plots scale covariate. Values close 0 indicate good balance groups given covariate. weakness empirical Q-Q plots don’t reveal much differences shapes distributions groups, key aspect distributional balance. density plot essentially contains information, clearer intuitive. Although assessment balance using empirical Q-Q plot straightforward (.e., deviations 45-degree line indicate imbalances), density plots present information way line actual goals conditioning, particular, distributions treated control units similar (Ho et al. 2007). Empirical Q-Q plot summary statistics may useful quantifying imbalance, currently recommendations use.","code":""},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt.html","id":"whats-added-in-cobalt","dir":"Articles","previous_headings":"","what":"What’s Added in cobalt","title":"Covariate Balance Tables and Plots: A Guide to the cobalt Package","text":"several features cobalt present , , balance assessment tools major packages. come methodological recommendations requests members methodological community.","code":""},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt.html","id":"density-plots","dir":"Articles","previous_headings":"What’s Added in cobalt","what":"Density Plots","title":"Covariate Balance Tables and Plots: A Guide to the cobalt Package","text":"mentioned , cobalt displays density plots bar charts rather empirical Q-Q plots assessment distributional similarity. charts standard conditioning packages, can intuitive helpful tool deciding whether adjustment yielded similar distributions groups given covariates. Though obvious heuristics deciding much dissimilarity much dissimilarity, density plots avoid sometimes confusing logic empirical Q-Q plots favor simplicity interpretability. Austin (2009) Linden (2014) consider density plots compliment empirical Q-Q plots finely examine balance adjusting.","code":""},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt.html","id":"variance-ratios","dir":"Articles","previous_headings":"What’s Added in cobalt","what":"Variance Ratios","title":"Covariate Balance Tables and Plots: A Guide to the cobalt Package","text":"Although mean differences (including t-tests chi-square tests) reported balance statistic (Thoemmes Kim 2011), variance ratios recommended literature means examine balance groups (Austin 2009; Ho et al. 2007; Imai, King, Stuart 2008). group variances similar, variance ratio close 1. Common thresholds variance ratio balanced groups .5 2 (Stuart 2010; Rubin 2001), though ratios closer 1 preferred. Although bal.tab() cobalt display variance ratios default, can easily requested thresholds set.","code":""},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt.html","id":"distinguishing-continuous-and-binary-covariates","dir":"Articles","previous_headings":"What’s Added in cobalt","what":"Distinguishing Continuous and Binary Covariates","title":"Covariate Balance Tables and Plots: A Guide to the cobalt Package","text":"Continuous binary covariates treated differently default bal.tab() bal.plot(). continuous covariates, standard summaries apply: standardized mean differences, variance ratios, density plots. binary covariates, raw differences proportion bar charts preferable, variance ratios useless. value standardized mean differences continuous variables scale can compared across variables, allow simple interpretation even details variable’s original scale unclear analyst. None advantages passed binary variables binary variables already scale (.e., proportion), scale easily interpretable. addition, details standardizing proportion difference binary variable involve dividing proportion difference variance, variance binary variable function proportion (Austin 2009). Standardizing proportion difference binary variable can yield following counterintuitive result: \\(X_{T} = .2\\) \\(X_{C} = .3\\), standardized difference proportion different \\(X_{T} = .5\\) \\(X_{C} = .6\\), even though expectation balance statistic scenarios yield degree bias effect estimate. addition, Ali et al. (2014) found raw difference proportion better predictor bias standardized mean difference binary variables6. MatchIt allows users view either standardized mean differences covariates raw differences covariates, twang Matching display standardized differences variables calculate test statistics depending whether covariate continuous binary (CBPS calculate mean differences, presents standardized unstandardized means covariates). cobalt allows user select differences calculated separately continuous binary variables, uses intuitive default mean differences continuous variables standardized proportion differences binary variables . variance binary variable function proportion, variance ratio binary variable two groups function proportions, thereby containing information simple difference proportion. Therefore, binary variables, cobalt compute variance ratios, can misleading.","code":""},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt.html","id":"interactions-and-polynomials","dir":"Articles","previous_headings":"What’s Added in cobalt","what":"Interactions and Polynomials","title":"Covariate Balance Tables and Plots: A Guide to the cobalt Package","text":"goal balancing procedure achieve independence treatment joint distribution covariates, evaluating univariate distributional similarity may sufficient assessing balance completely. writers recommended evaluation distributional similarity interaction polynomial terms account . Rather requiring user create interaction variables hand, bal.tab() can produce balance statistics interactions specifying int = TRUE, similar MatchIt’s summary(), polynomials specifying numeric argument poly (e.g., 2 squared terms). including categorical variables balance assessment, bal.tab() makes adjustments hood deserve explanation. First, variable binary entered factor variable, balance statistics displayed one level variable (since redundant), balance interaction terms displayed values variables. example, consider binary variable “Sex” values “Male” “Female”. Many functions, including bal.tab(), lm(), matchit(), split variable two numeric dummy variables, “Male” “Female”, take values 0 1. One new variables completely redundant: relevant information stored just “Female”, “Male” can eliminated. Consider now variable “Age”: desired balance assessment interaction Age Sex; distributional similarity interaction treated untreated groups evidence multivariate balance. Computing interaction “Female” “Age” yields variable “Age” unit female 0 otherwise. average value variable average age females sample, weighted proportion females. two treatment groups similar average values variable, taken evidence balance interaction sex age, though entirely possible average age men differs greatly two groups. Thus, additional variable computed product “Male” “Age” necessary fully assess balance interaction sex age. bal.tab() produces interaction term, otherwise unobserved analyst7. interactions among levels single factor, always equal 0, excluded bal.tab(). Interactions distance measure variables excluded bal.tab(), noting balance distance measure neither necessary sufficient covariate balance. number computations increases sample size number variables, computing interactions can slow. addition taking product variables two time, bal.tab() checks variables ensure variables created contain single value (e.g., interactions mutually exclusive covariates) redundant respect variables (e.g., manually created interactions manually split factors). results cleaner, useful output, also requires computing time. advisable store results call bal.tab() variable accessed later rather call bal.tab() several times using interactions.","code":""},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt.html","id":"clusters","dir":"Articles","previous_headings":"What’s Added in cobalt","what":"Clusters","title":"Covariate Balance Tables and Plots: A Guide to the cobalt Package","text":"use preprocessing techniques context multilevel data (e.g., students within schools, patients within hospitals) increasing. Currently package allows balance assessment respect clusters, except manually examining balance clusters specified manually. can useful examine balance within cluster, , especially many clusters, may also useful examine summary balance across clusters. functions, cobalt provides options displaying balance clustered data sets. can occur either within specified clusters across clusters. Details using cobalt clustered data can found accompanying Appendix 2.","code":""},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt.html","id":"missing-data","dir":"Articles","previous_headings":"What’s Added in cobalt","what":"Missing Data","title":"Covariate Balance Tables and Plots: A Guide to the cobalt Package","text":"Missing data frequent research involving human subjects, especially large survey data sets often used answer causal questions social sciences. cobalt functions can assess balance observed covariates also proportion missing values covariate. Additionally, cobalt features designed especially assessing balance preprocessed data sets multiply imputed address covariate missingness. Although guidelines assessing balance multiply imputed data sets scarce, valuable assess balance within across imputed data sets ensure preprocessing solution applicable imputations. Details using cobalt multiply imputed data can found accompanying Appendix 2.","code":""},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt.html","id":"for-programmers-integrating-cobalt-with-your-package","dir":"Articles","previous_headings":"","what":"For Programmers: Integrating cobalt with Your Package","title":"Covariate Balance Tables and Plots: A Guide to the cobalt Package","text":"designing new R package preprocessing performs similar functions MatchIt, twang, Matching, optmatch, CBPS, ebal, designmatch, cem, WeightIt, might consider integrating cobalt package avoid programming balance assessment tool. simplest way output preprocessing function contain sufficient elements use default method bal.tab() bal.plot(). See ?bal.tab.default information might work. cobalt updated remain line methodological recommendations, balance assessment capabilities function’s output also improve cobalt balance assessment tool package. way, users package can use --date balance assessment tools programmed cobalt without update package. develop new balance assessment tool, may also able integrated cobalt, especially applicable balance assessment generally matching, weighting, subclassification. Incorporating new tool cobalt may good way broaden use. cobalt includes small suite functions compute balance statistics matrices covariates without weights. include col_w_smd computing (standardized) mean differences, col_w_vr computing variance ratios, col_w_ks computing KS statistics, col_w_ovl computing complement overlap statistics (Franklin et al. 2014), col_w_corr computing treatment-covariate correlations. run fairly quickly still quite flexible, can used quickly simply compute balance statistics packages. used internally bal.tab, might able used internally functions (e.g., choose tuning parameter based measure balance).","code":""},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt.html","id":"acknowledgments","dir":"Articles","previous_headings":"","what":"Acknowledgments","title":"Covariate Balance Tables and Plots: A Guide to the cobalt Package","text":"thank Kirsten Kainz Elizabeth Stuart support advice cobalt’s creation. thank Zachary Fisher Brian Barkley advice developing R package.","code":""},{"path":[]},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt_A1_other_packages.html","id":"utilities","dir":"Articles","previous_headings":"","what":"Utilities","title":"Appendix 1: Using cobalt with Other Preprocessing Packages","text":"addition main balance assessment functions, cobalt contains several utility functions. meant reduce typing programming burden often accompany use R diverse set packages.","code":""},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt_A1_other_packages.html","id":"splitfactor-and-unsplitfactor","dir":"Articles","previous_headings":"Utilities","what":"splitfactor() and unsplitfactor()","title":"Appendix 1: Using cobalt with Other Preprocessing Packages","text":"functions (outside cobalt) friendly factor character variables, require numeric variables operate correctly. example, regression-style functions, ebalance() ebal, can take non-singular numeric matrices. functions process factor variables, return output terms dummy coded version factors. example, lm() create dummy variables factor drop reference category create regression coefficients. prepare data sets use functions allow factors mimic output functions split factor variables, users can use splitfactor(), takes data set names variables split, outputs new data set newly created dummy variables. example splitting race variable Lalonde data set dummies, eliminating reference category (\"black\"): possible undo action splitfactor() unsplitfactor(), takes data set dummy variables formed splitfactor() otherwise recreates original factor variable. reference category dropped, value needs supplied. Notice original data set unsplit data set look identical. input unsplitfactor() output call splitfactor() (), don’t need tell unsplitfactor() name split variable value dropped level. done illustration purposes.","code":"head(lalonde) ##   treat age educ   race married nodegree re74 re75       re78 ## 1     1  37   11  black       1        1    0    0  9930.0460 ## 2     1  22    9 hispan       0        1    0    0  3595.8940 ## 3     1  30   12  black       0        0    0    0 24909.4500 ## 4     1  27   11  black       0        1    0    0  7506.1460 ## 5     1  33    8  black       0        1    0    0   289.7899 ## 6     1  22    9  black       0        1    0    0  4056.4940 lalonde.split <- splitfactor(lalonde, \"race\") head(lalonde.split) ##   treat age educ race_hispan race_white married nodegree re74 re75       re78 ## 1     1  37   11           0          0       1        1    0    0  9930.0460 ## 2     1  22    9           1          0       0        1    0    0  3595.8940 ## 3     1  30   12           0          0       0        0    0    0 24909.4500 ## 4     1  27   11           0          0       0        1    0    0  7506.1460 ## 5     1  33    8           0          0       0        1    0    0   289.7899 ## 6     1  22    9           0          0       0        1    0    0  4056.4940 lalonde.unsplit <- unsplitfactor(lalonde.split, \"race\",                                   dropped.level = \"black\") head(lalonde.unsplit) ##   treat age educ   race married nodegree re74 re75       re78 ## 1     1  37   11  black       1        1    0    0  9930.0460 ## 2     1  22    9 hispan       0        1    0    0  3595.8940 ## 3     1  30   12  black       0        0    0    0 24909.4500 ## 4     1  27   11  black       0        1    0    0  7506.1460 ## 5     1  33    8  black       0        1    0    0   289.7899 ## 6     1  22    9  black       0        1    0    0  4056.4940"},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt_A1_other_packages.html","id":"get-w","dir":"Articles","previous_headings":"Utilities","what":"get.w()","title":"Appendix 1: Using cobalt with Other Preprocessing Packages","text":"get.w() allows users extract weights output call preprocessing function one supported packages. package stores weights different ways, can helpful single function applies equally outputs. twang function called get.weights() performs functions slightly finer control output call ps().","code":""},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt_A1_other_packages.html","id":"bal-tab","dir":"Articles","previous_headings":"","what":"bal.tab()","title":"Appendix 1: Using cobalt with Other Preprocessing Packages","text":"next sections describe use bal.tab() packages described main vignette. Even using bal.tab() one packages, may useful read main vignette understand bal.tab()’s main options, detailed .","code":""},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt_A1_other_packages.html","id":"using-bal-tab-with-twang","dir":"Articles","previous_headings":"bal.tab()","what":"Using bal.tab() with twang","title":"Appendix 1: Using cobalt with Other Preprocessing Packages","text":"Generalized boosted modeling (GBM), implemented twang, can effective way generate propensity scores weights use propensity score weighting. bal.tab() functions similarly functions bal.table() summary() used GBM twang. simple example use: output looks bit different twang’s bal.table() output. First original call ps(). Next balance table containing mean differences covariates included input ps(). Last table displaying sample size information, similar generated using twang’s summary() function. “effective” sample size displayed weighting used; calculated done twang. See twang documentation, ?bal.tab, “Details Calculations” main vignette details calculation. using bal.tab() twang, user must specify ps object, output call ps(), first argument. second argument, stop.method, name stop method(s) balance assessed, since ps object may contain one specified. bal.tab() can display balance one stop method time specifying vector stop method names. argument left empty argument stop.method correspond stop methods ps object, bal.tab() default displaying balance stop methods available. Abbreviations allowed stop method, case sensitive. arguments bal.tab() using twang form function given using without conditioning package, except s.d.denom. estimand stop method used ATT, s.d.denom default \"treated\" specified, estimand ATE, s.d.denom default \"pooled\", mimicking behavior twang. user can specify argument s.d.denom, using defaults advised. sampling weights used call ps(), automatically incorporated bal.tab() calculations adjusted unadjusted samples, just twang . mnps objects resulting fitting models twang multi-category treatments also compatible cobalt. See section “Using cobalt multi-category treatments” main vignette. iptw objects resulting fitting models twang longitudinal treatments also compatible cobalt. See Appendix 3 vignette. ps.cont objects resulting using ps.cont() WeightIt, implements GBM continuous treatments, also compatible. See section “Using cobalt continuous treatments” main vignette.","code":"#GBM PS weighting for the ATT data(\"lalonde\", package = \"cobalt\") ##If not yet loaded covs0 <- subset(lalonde, select = -c(treat, re78)) f <- reformulate(names(covs0), \"treat\")  ps.out <- twang::ps(f, data = lalonde,                      stop.method = c(\"es.mean\", \"es.max\"),                      estimand = \"ATT\", n.trees = 1000,                     verbose = FALSE) bal.tab(ps.out, stop.method = \"es.mean\") ## Balance Measures ##                 Type Diff.Adj ## prop.score  Distance   0.5189 ## age          Contin.   0.0400 ## educ         Contin.  -0.0819 ## race_black    Binary   0.0250 ## race_hispan   Binary  -0.0008 ## race_white    Binary  -0.0242 ## married       Binary  -0.0116 ## nodegree      Binary   0.0864 ## re74         Contin.   0.0691 ## re75         Contin.   0.0953 ##  ## Effective sample sizes ##            Control Treated ## Unadjusted  429.       185 ## Adjusted     33.03     185"},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt_A1_other_packages.html","id":"using-bal-tab-with-matching","dir":"Articles","previous_headings":"bal.tab()","what":"Using bal.tab() with Matching","title":"Appendix 1: Using cobalt with Other Preprocessing Packages","text":"Matching package used propensity score matching, also first package implement genetic matching. MatchIt calls Matching use genetic matching can accomplish many matching methods Matching can, Matching still widely used package strengths. bal.tab() functions similarly Matching’s MatchBalance() command, yields thorough presentation balance. simple example use bal.tab() Matching: output looks quite different Matching’s MatchBalance() output. Rather stacked vertically, balance statistics arranged horizontally table format, allowing quick balance checking. balance table summary sample size matching, similar Matching’s summary() command display. sample size can include “ESS” “unweighted” value; “ESS” value effective sample size resulting matching weights, “unweighted” count units nonzero matching weights. input bal.tab() similar given MatchBalance(): Match object resulting call Match(), formula relating treatment covariates balance assessed, original data set. way call bal.tab(): instead formula data set, one can also input data frame covariates vector treatment status indicators, just using bal.tab() without conditioning package. example, code yield results call bal.tab() : arguments bal.tab() using Matching form function given using without conditioning package, except s.d.denom. estimand original call Match() ATT, s.d.denom default \"treated\" specified; estimand ATE, s.d.denom default \"pooled\"; estimand ATC, s.d.denom default \"control\". user can specify argument s.d.denom, using defaults advisable. addition, use addl argument unnecessary covariates entered manually arguments, covariates balance assessed can entered formula covs argument. covariates stored two separate data frames, may useful include one formula covs addl.","code":"#1:1 NN PS matching w/ replacement data(\"lalonde\", package = \"cobalt\") #If not yet loaded covs0 <- subset(lalonde, select = -c(treat, re78)) f <- reformulate(names(covs0), \"treat\")  fit <- glm(f, data = lalonde, family = binomial) p.score <- fit$fitted.values match.out <- Matching::Match(Tr = lalonde$treat, X = p.score,                              estimand = \"ATT\")  bal.tab(match.out, formula = f, data = lalonde,         distance = ~ p.score) ## Balance Measures ##                 Type Diff.Adj ## p.score     Distance   0.0043 ## age          Contin.   0.2106 ## educ         Contin.   0.0201 ## race_black    Binary   0.0054 ## race_hispan   Binary  -0.0051 ## race_white    Binary  -0.0003 ## married       Binary   0.0661 ## nodegree      Binary  -0.0079 ## re74         Contin.  -0.0772 ## re75         Contin.  -0.0127 ##  ## Sample sizes ##                      Control Treated ## All                   429.       185 ## Matched (ESS)          49.17     185 ## Matched (Unweighted)  136.       185 ## Unmatched             293.         0 bal.tab(match.out, treat = lalonde$treat, covs = covs0,         distance = ~ p.score)"},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt_A1_other_packages.html","id":"using-bal-tab-with-optmatch","dir":"Articles","previous_headings":"bal.tab()","what":"Using bal.tab() with optmatch","title":"Appendix 1: Using cobalt with Other Preprocessing Packages","text":"optmatch package useful performing optimal pairwise full matching. functions optmatch subsumed MatchIt, optmatch sees use want finer control matching process MatchIt allows. output calls functions optmatch optmatch object, contains matching stratum membership unit given data set. Units matched assigned matching stratum. user guide optmatch recommends using RItools package balance assessment, example use bal.tab() purpose. Note results differ cobalt RItools differences balance calculated . details use bal.tab() optmatch similar using bal.tab() Matching. Users can enter either formula data set vector treatment status set covariates. Unlike Matching, entering treatment variable optional already stored optmatch object. bal.tab() compatible pairmatch() fullmatch() output.","code":"#Optimal full matching on the propensity score data(\"lalonde\", package = \"cobalt\") #If not yet loaded covs0 <- subset(lalonde, select = -c(treat, re78)) f <- reformulate(names(covs0), \"treat\")  fit <- glm(f, data = lalonde, family = binomial) p.score <- fit$fitted.values #get the propensity score fm <- optmatch::fullmatch(treat ~ p.score, data = lalonde)  bal.tab(fm, covs = covs0, distance = ~ p.score) ## Balance Measures ##                 Type Diff.Adj ## p.score     Distance   0.0058 ## age          Contin.   0.1522 ## educ         Contin.  -0.0314 ## race_black    Binary   0.0086 ## race_hispan   Binary  -0.0014 ## race_white    Binary  -0.0071 ## married       Binary   0.0573 ## nodegree      Binary   0.0072 ## re74         Contin.  -0.0631 ## re75         Contin.  -0.0138 ##  ## Sample sizes ##                      Control Treated ## All                   429.       185 ## Matched (ESS)          51.42     185 ## Matched (Unweighted)  429.       185"},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt_A1_other_packages.html","id":"using-bal-tab-with-cbps","dir":"Articles","previous_headings":"bal.tab()","what":"Using bal.tab() with CBPS","title":"Appendix 1: Using cobalt with Other Preprocessing Packages","text":"CBPS (Covariate Balancing Propensity Score) package great tool generating covariate balancing propensity scores, class propensity scores quite effective balancing covariates among groups. CBPS includes functions estimating propensity scores binary, multi-category, continuous treatments. bal.tab() functions similarly CBPS’s balance() command. simple example use binary treatment: First original call CBPS(). Next balance table containing mean differences covariates included input CBPS(). Last table displaying sample size information. “effective” sample size displayed weighting (rather matching subclassification) used; calculated done twang. See twang documentation, ?bal.tab, “Details Calculations” main vignette details calculation. arguments bal.tab() using CBPS form function given using without conditioning package, except s.d.denom. estimand original call CBPS() ATT, s.d.denom default \"treated\" specified, estimand ATE, s.d.denom default \"pooled\". user can specify argument s.d.denom, using defaults advisable. CBPSContinuous objects resulting fitting models CBPS continuous treatments also compatible cobalt. See section “Using cobalt continuous treatments” main vignette. CBPS objects resulting fitting models CBPS multi-category treatments also compatible cobalt. See section “Using cobalt multi-category treatments” main vignette. CBMSM objects resulting fitting models CBPS longitudinal treatments also compatible cobalt. See Appendix 3 vignette.","code":"#CBPS weighting data(\"lalonde\", package = \"cobalt\") #If not yet loaded covs0 <- subset(lalonde, select = -c(treat, re78)) f <- reformulate(names(covs0), \"treat\")  #Generating covariate balancing propensity score weights for ATT cbps.out <- CBPS::CBPS(f, data = lalonde) ## [1] \"Finding ATT with T=1 as the treatment.  Set ATT=2 to find ATT with T=0 as the treatment\" bal.tab(cbps.out) ## Balance Measures ##                 Type Diff.Adj ## prop.score  Distance  -0.0057 ## age          Contin.  -0.0052 ## educ         Contin.  -0.0017 ## race_black    Binary   0.0019 ## race_hispan   Binary  -0.0002 ## race_white    Binary  -0.0017 ## married       Binary  -0.0029 ## nodegree      Binary   0.0042 ## re74         Contin.  -0.0078 ## re75         Contin.   0.0061 ##  ## Effective sample sizes ##            Control Treated ## Unadjusted  429.       185 ## Adjusted     99.97     185"},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt_A1_other_packages.html","id":"using-bal-tab-with-ebal","dir":"Articles","previous_headings":"bal.tab()","what":"Using bal.tab() with ebal","title":"Appendix 1: Using cobalt with Other Preprocessing Packages","text":"ebal package implements entropy balancing, method weighting ATT yields perfect balance desired moments covariate distributions groups. Rather estimate propensity score, entropy balancing generates weights directly satisfy user-defined moment condition, specifying moments balanced. functionality ebal contained within Weightit. ebal balance assessment function; thus, cobalt way assess balance without programming, ebal documentation instructs. simple example using bal.tab() ebal: First balance table containing mean differences covariates included original call ebalance. general, close 0. Next table displaying effective sample size information. “effective” sample size calculated done twang. See twang documentation, ?bal.tab, “Details Calculations” main vignette details calculation. common issue using entropy balancing small effective sample size, can yield low precision effect estimation using weighted regression, important users pay attention measure. input similar using bal.tab() Matching optmatch. addition ebalance object, one must specify either formula data set treatment vector data frame covariates.","code":"#Entropy balancing data(\"lalonde\", package = \"cobalt\") #If not yet loaded covs0 <- subset(lalonde, select = -c(treat, re78, race))  #Generating entropy balancing weights e.out <- ebal::ebalance(lalonde$treat, covs0) ## Converged within tolerance bal.tab(e.out, treat = lalonde$treat, covs = covs0) ## Balance Measures ##             Type Diff.Adj ## age      Contin.       -0 ## educ     Contin.       -0 ## married   Binary       -0 ## nodegree  Binary        0 ## re74     Contin.       -0 ## re75     Contin.       -0 ##  ## Effective sample sizes ##            Control Treated ## Unadjusted  429.       185 ## Adjusted    247.64     185"},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt_A1_other_packages.html","id":"using-bal-tab-with-designmatch","dir":"Articles","previous_headings":"bal.tab()","what":"Using bal.tab() with designmatch","title":"Appendix 1: Using cobalt with Other Preprocessing Packages","text":"designmatch package implements various matching methods use optimization find matches satisfy certain balance constraints. bal.tab() functions similarly designmatch’s meantab() command provides additional flexibility convenience. simple example using bal.tab() designmatch: input similar using bal.tab() Matching optmatch. addition designmatch() output object, one must specify either formula data set treatment vector data frame covariates. output similar optmatch.","code":"#Mixed integer programming matching library(\"designmatch\") data(\"lalonde\", package = \"cobalt\") #If not yet loaded covs0 <- subset(lalonde, select = -c(treat, re78, race))  #Matching for balance on covariates dmout <- bmatch(lalonde$treat,                 dist_mat = NULL,                 subset_weight = NULL,                 mom = list(covs = covs0,                            tols = absstddif(covs0, lalonde$treat, .005)),                 n_controls = 1,                 total_groups = 185) ##   Building the matching problem...  ##   GLPK optimizer is open...  ##   Finding the optimal matches...  ##   Optimal matches found bal.tab(dmout, treat = lalonde$treat, covs = covs0) ## Balance Measures ##             Type Diff.Adj ## age      Contin.   0.0038 ## educ     Contin.   0.0054 ## married   Binary   0.0000 ## nodegree  Binary   0.0054 ## re74     Contin.  -0.0120 ## re75     Contin.  -0.0076 ##  ## Sample sizes ##           Control Treated ## All           429     185 ## Matched       185     185 ## Unmatched     244       0"},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt_A1_other_packages.html","id":"using-bal-tab-with-sbw","dir":"Articles","previous_headings":"bal.tab()","what":"Using bal.tab() with sbw","title":"Appendix 1: Using cobalt with Other Preprocessing Packages","text":"sbw package implements optimization-based weighting estimate weights satisfy certain balance constraints minimal variance. bal.tab() functions similarly sbw’s summarize() function provides additional flexibility convenience. simple example using bal.tab() sbw: output similar output call summarize(). Rather stack several balance tables vertically, balance summary, displayed horizontally. Note due differences sbw cobalt compute standardization factor standardized mean difference, values may identical bal.tab() summarize(). Also note bal.tab()’s default display raw rather standardized mean differences binary variables.","code":"#Optimization-based weighting data(\"lalonde\", package = \"cobalt\") #If not yet loaded lalonde_split <- splitfactor(lalonde, drop.first = \"if2\") cov.names <- setdiff(names(lalonde_split), c(\"treat\", \"re78\"))  #Estimating balancing weights for the ATT sbw.out <- sbw::sbw(lalonde_split,                     ind = \"treat\",                     bal = list(bal_cov = cov.names,                                bal_alg = FALSE,                                 bal_tol = .001),                     par = list(par_est = \"att\")) ##   quadprog optimizer is opening...  ##   Finding the optimal weights...  ##   Optimal weights found. bal.tab(sbw.out, un = TRUE, disp.means = TRUE) ## Balance Measures ##                Type    M.0.Un    M.1.Un Diff.Un   M.0.Adj   M.1.Adj Diff.Adj ## age         Contin.   28.0303   25.8162 -0.3094   25.8054   25.8162   0.0015 ## educ        Contin.   10.2354   10.3459  0.0550   10.3431   10.3459   0.0014 ## race_black   Binary    0.2028    0.8432  0.6404    0.8428    0.8432   0.0004 ## race_hispan  Binary    0.1422    0.0595 -0.0827    0.0594    0.0595   0.0001 ## race_white   Binary    0.6550    0.0973 -0.5577    0.0978    0.0973  -0.0005 ## married      Binary    0.5128    0.1892 -0.3236    0.1897    0.1892  -0.0005 ## nodegree     Binary    0.5967    0.7081  0.1114    0.7076    0.7081   0.0005 ## re74        Contin. 5619.2365 2095.5737 -0.7211 2102.3624 2095.5737  -0.0014 ## re75        Contin. 2466.4844 1532.0553 -0.2903 1528.7633 1532.0553   0.0010 ##  ## Effective sample sizes ##            Control Treated ## Unadjusted  429.       185 ## Adjusted    108.99     185"},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt_A1_other_packages.html","id":"using-bal-tab-with-matchthem","dir":"Articles","previous_headings":"bal.tab()","what":"Using bal.tab() with MatchThem","title":"Appendix 1: Using cobalt with Other Preprocessing Packages","text":"MatchThem package essentially wrapper matchit() MatchIt weightit() WeightIt use multiply imputed data. Using bal.tab() mimids wimids objects MatchThem activates features accompany multiply imputed data; balance assessed within imputed dataset aggregated across imputations. See ?bal.tab.imp accompanying Appendix 2 information using cobalt multiply imputed data. simple example using bal.tab() MatchThem: input similar using bal.tab() MatchIt WeightIt.","code":"#PS weighting on multiply imputed data data(\"lalonde_mis\", package = \"cobalt\")  #Generate imputed data sets m <- 10 #number of imputed data sets imp.out <- mice::mice(lalonde_mis, m = m, print = FALSE)   #Matching for balance on covariates wt.out <- MatchThem::weightthem(treat ~ age + educ + married +                                     race + re74 + re75,                                  datasets = imp.out,                                 approach = \"within\",                                  method = \"ps\",                                 estimand = \"ATE\")  bal.tab(wt.out) ## Balance summary across all imputations ##                 Type Min.Diff.Adj Mean.Diff.Adj Max.Diff.Adj ## prop.score  Distance       0.1515        0.1563       0.1631 ## age          Contin.      -0.1938       -0.1881      -0.1825 ## educ         Contin.       0.0724        0.0830       0.0919 ## married       Binary      -0.1119       -0.1026      -0.0922 ## race_black    Binary       0.0545        0.0570       0.0591 ## race_hispan   Binary       0.0082        0.0100       0.0120 ## race_white    Binary      -0.0711       -0.0669      -0.0632 ## re74         Contin.      -0.2956       -0.2840      -0.2722 ## re75         Contin.      -0.1753       -0.1567      -0.1415 ##  ## Average effective sample sizes across imputations ##                 0      1 ## Unadjusted 429.   185.   ## Adjusted   331.53  67.45"},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt_A1_other_packages.html","id":"using-bal-tab-with-cem","dir":"Articles","previous_headings":"bal.tab()","what":"Using bal.tab() with cem","title":"Appendix 1: Using cobalt with Other Preprocessing Packages","text":"cem package implements coarsened exact matching binary multi-category treatments. bal.tab() functions similarly cems’s imbalance(). simple example using bal.tab() cem: input similar using bal.tab() Matching optmatch. addition cem() output object, one must specify either formula data set treatment vector data frame covariates. Unlike Matching, entering treatment variable optional already stored output object. output similar optmatch. using cem() multiply imputed data (.e., supplying list data.frames datalist argument cem()), argument imp specified bal.tab() mids object mice package given argument data. See ?bal.tab.imp accompanying Appendix 2 information using cobalt multiply imputed data. example using cem multiply imputed data mice:","code":"#Coarsened exact matching data(\"lalonde\", package = \"cobalt\") #If not yet loaded  #Matching for balance on covariates cem.out <- cem::cem(\"treat\", data = lalonde, drop = \"re78\") ##  ## Using 'treat'='1' as baseline group bal.tab(cem.out, data = lalonde, stats = c(\"m\", \"ks\")) ## Balance Measures ##                Type Diff.Adj KS.Adj ## age         Contin.   0.0512 0.1581 ## educ        Contin.  -0.0441 0.0445 ## race_black   Binary   0.0000 0.0000 ## race_hispan  Binary   0.0000 0.0000 ## race_white   Binary   0.0000 0.0000 ## married      Binary   0.0000 0.0000 ## nodegree     Binary   0.0000 0.0000 ## re74        Contin.  -0.0341 0.2418 ## re75        Contin.  -0.0528 0.1162 ##  ## Sample sizes ##                      Control Treated ## All                   429.       185 ## Matched (ESS)          36.29      68 ## Matched (Unweighted)   78.        68 ## Unmatched             351.       117 #Coarsened exact matching on multiply imputed data data(\"lalonde_mis\", package = \"cobalt\")  #Generate imputed data sets m <- 10 #number of imputed data sets imp.out <- mice::mice(lalonde_mis, m = m, print = FALSE)  imp.data.list <- mice::complete(imp.out, \"all\")  #Match within each imputed dataset cem.out.imp <- cem::cem(\"treat\", datalist = imp.data.list,                         drop = \"re78\") ##  ## Using 'treat'='1' as baseline group ##  ## Using 'treat'='1' as baseline group ##  ## Using 'treat'='1' as baseline group ##  ## Using 'treat'='1' as baseline group ##  ## Using 'treat'='1' as baseline group ##  ## Using 'treat'='1' as baseline group ##  ## Using 'treat'='1' as baseline group ##  ## Using 'treat'='1' as baseline group ##  ## Using 'treat'='1' as baseline group ##  ## Using 'treat'='1' as baseline group bal.tab(cem.out.imp, data = imp.out) ## Balance summary across all imputations ##                Type Min.Diff.Adj Mean.Diff.Adj Max.Diff.Adj ## age         Contin.       0.0468        0.0487       0.0515 ## educ        Contin.      -0.0441       -0.0332      -0.0167 ## race_black   Binary      -0.0000       -0.0000       0.0000 ## race_hispan  Binary      -0.0000        0.0000       0.0000 ## race_white   Binary      -0.0000       -0.0000       0.0000 ## married      Binary      -0.0000        0.0000       0.0000 ## nodegree     Binary       0.0000        0.0000       0.0000 ## re74        Contin.      -0.0477       -0.0379      -0.0326 ## re75        Contin.      -0.0766       -0.0572      -0.0498 ##  ## Average sample sizes across imputations ##                          0     1 ## All                  429.  185.  ## Matched (ESS)         35.4  65.6 ## Matched (Unweighted)  77.4  65.6 ## Unmatched            351.6 119.4"},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt_A1_other_packages.html","id":"using-bal-tab-with-other-packages","dir":"Articles","previous_headings":"bal.tab()","what":"Using bal.tab() with other packages","title":"Appendix 1: Using cobalt with Other Preprocessing Packages","text":"possible use bal.tab objects don’t come packages using default method. object doesn’t correspond output one specifically supported packages passed first argument bal.tab, bal.tab best process object come supported package. search components object items names like \"treat\", \"covs\", \"data\", \"weights\", etc., correct object types. additional arguments can specified user. goal default method allow package authors rely cobalt substitute balancing function might otherwise write. ensuring compatibility default method, package authors can users simply supply output compatible function cobalt functions without write specific method cobalt. package author need make sure output package contained enough information correctly named components; , cobalt functions can used conveniently output specifically supported packages. , demonstrate capability output optweight, performs version propensity score weighting using optimization, similar sbw. bal.tab method written optweight output mind; rather, optweight written output compatible default method bal.tab. output treated output specifically supported package. See ?bal.tab.default details another example.","code":"#Optimization-based weighting data(\"lalonde\", package = \"cobalt\")  #Estimate the weights using optimization ow.out <- optweight::optweight(treat ~ age + educ + married + race + re74 + re75,                                data = lalonde, estimand = \"ATE\", tols = .01)  #Note the contents of the output object: names(ow.out) ##  [1] \"weights\"   \"treat\"     \"covs\"      \"s.weights\" \"estimand\"  \"focal\"     ##  [7] \"call\"      \"tols\"      \"duals\"     \"info\" #Use bal.tab() directly on the output bal.tab(ow.out) ## Balance Measures ##                Type Diff.Adj ## age         Contin.  -0.0000 ## educ        Contin.   0.0100 ## married      Binary  -0.0100 ## race_black   Binary   0.0100 ## race_hispan  Binary  -0.0000 ## race_white   Binary  -0.0100 ## re74        Contin.  -0.0100 ## re75        Contin.   0.0085 ##  ## Effective sample sizes ##            Control Treated ## Unadjusted  429.    185.   ## Adjusted    349.42   52.04"},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt_A2_segmented_data.html","id":"cobalt-and-segmented-data","dir":"Articles","previous_headings":"","what":"cobalt and Segmented Data","title":"Appendix 2: Using cobalt with Clustered, Multiply Imputed, and Other Segmented Data","text":"First, let’s understand segmented data. Segmented data arises data involved balance assessment needs split segments appropriately assess balance. scenarios include clustered (e.g., multilevel) data, case balance assessed within cluster; data arising sequential study, case balance assessed time point; multi-category treatments, case balance assessed pair treatments; multiply imputed data, case balance assessed within imputation. cobalt can handle scenarios simultaneously, may little complicated. vignette explains scenarios handled. core idea basic unit balance assessment balance statistic covariate binary treatments pairs treatment levels, can (standardized) mean difference, variance ratio, Kolmogorov-Smirnoff (KS) statistic. continuous treatments, treatment-covariate correlation. statistics generated bal.tab() can plotted using love.plot() data segmented. data segmented, statistics need generated within segment. segmentation occurs several ways dataset (e.g., clustered multiply imputed data, longitudinal data multi-category treatments), balance assessment reflect layer segmentation. Although idea simply splitting data segments simple, options limitations cobalt important consider. basic idea regardless data segmented: layer segmentation, balance assessed within segments layer, layers stack heirarchically. example, clustered multiply imputed data, first data split cluster; within cluster, data split imputation; balance statistics computed within imputation within cluster. cases, summary balance across segments can produced simplify balance assessment. Matching weighting compatible segmented data, subclassification special form segmentation treated differently considered . cobalt’s primary functions (bal.tab(), bal.plot(), love.plot()) features handle segmented data sets. following sections describe data scenario relevant features function. ’ll take look common examples segmented data: clustered data, multiply imputed data, multi-category multiply imputed data.","code":""},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt_A2_segmented_data.html","id":"clustered-data","dir":"Articles","previous_headings":"","what":"Clustered Data","title":"Appendix 2: Using cobalt with Clustered, Multiply Imputed, and Other Segmented Data","text":"clustered data, data set must contain variable denoting group individual belongs . may group considered nuisance must accounted eliminate confounding (e.g., hospitals multi-site medical treatment study), group concern effect moderation (e.g., race gender). examples , imagine interested ATT treat re78 stratified race. Thus, condition propensity score within cluster. First, let’s estimate propensity scores perform matching within race group. can performing separate analyses within cluster, can also use exact matching MatchIt ensure matches occur within clusters. important note analysis necessarily represent sound statistical analysis used illustrative purposes .","code":"library(\"cobalt\") data(\"lalonde\", package = \"cobalt\")  m.out <- MatchIt::matchit(treat ~ race*(age + educ + married + nodegree + re74 + re75),                            data = lalonde, method = \"nearest\", exact = \"race\",                            replace = TRUE, ratio = 2)"},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt_A2_segmented_data.html","id":"bal-tab","dir":"Articles","previous_headings":"Clustered Data","what":"bal.tab()","title":"Appendix 2: Using cobalt with Clustered, Multiply Imputed, and Other Segmented Data","text":"output produced bal.tab() clustered data contains balance tables cluster summary balance across clusters. use bal.tab() groups, four arguments considered. cluster, .cluster, cluster.summary, cluster.fun. cluster vector group membership unit name variable provided data set containing group membership. .cluster determines clusters balance tables displayed, . (Default: display clusters) cluster.summary determines whether cluster summary displayed . (Default: hide cluster summary) cluster.fun determines function(s) used combine balance statistics across clusters cluster summary. (Default: abs = FALSE, minimum, mean, maximum; abs = TRUE, mean maximum) arguments addition arguments used bal.tab() display balance. imp.summary imp.fun can also set global options using set.cobalt.options(). Let’s examine balance data within race group. see balance tables cluster. output see use bal.tab() cluster separately (e.g., using subset argument). commands work bal.tab() also work results, except balance tallies variable greatest imbalance displayed usually threshold specified. Next, can request balance summary across clusters hide individual clusters setting .cluster = .none: table presents minimum, mean, maximum balance statistics variable across clusters. Setting un = TRUE also display values adjusted data set. binary treatments, setting disp = c(v = TRUE) thresholds = c(v = 2) display values variance ratios. Setting abs = TRUE requests summaries absolute balance statistics displays extremeness balance statistics variable; thus, , example, groups large negative mean differences groups large positive mean differences, table display large mean differences, even though average mean difference close 0. ’s important know average balance statistic overall, assessing absolute balance statistics provides information balance within cluster rather aggregate. examine balance just clusters time, users can enter values .cluster. can vector clusters indices (.e., 1, 2, 3, etc.) names (e.g., “black”, “hispan”, “white”). Users also specify .cluster = .none omit cluster balance clusters just see summary across clusters. Users can force display summary across clusters specifying TRUE FALSE cluster.summary. .cluster = .none, cluster.summary automatically set TRUE (else wouldn’t output!). examining balance within groups, can helpful examine balance within group ignore summary. examples use .cluster cluster.summary change bal.tab() output. can also set global options using, example, set.cobalt.options(cluster.fun = \"mean\"), allows users type non-default option every time call bal.tab.","code":"bal.tab(m.out, cluster = \"race\") ## Balance by cluster ##  ##  - - - Cluster: black - - -  ## Balance Measures ##                 Type Diff.Adj ## distance    Distance   0.0150 ## race_black    Binary   0.0000 ## race_hispan   Binary   0.0000 ## race_white    Binary   0.0000 ## age          Contin.  -0.1001 ## educ         Contin.   0.0794 ## married       Binary   0.0288 ## nodegree      Binary  -0.0032 ## re74         Contin.  -0.1501 ## re75         Contin.  -0.1406 ##  ## Sample sizes ##                          0   1 ## All                  87.   156 ## Matched (ESS)        41.42 156 ## Matched (Unweighted) 76.   156 ## Unmatched            11.     0 ##  ##  - - - Cluster: hispan - - -  ## Balance Measures ##                 Type Diff.Adj ## distance    Distance   0.0947 ## race_black    Binary   0.0000 ## race_hispan   Binary   0.0000 ## race_white    Binary   0.0000 ## age          Contin.   0.1914 ## educ         Contin.  -0.4159 ## married       Binary   0.1364 ## nodegree      Binary   0.2273 ## re74         Contin.   0.1161 ## re75         Contin.   0.0683 ##  ## Sample sizes ##                          0  1 ## All                  61.   11 ## Matched (ESS)        15.12 11 ## Matched (Unweighted) 18.   11 ## Unmatched            43.    0 ##  ##  - - - Cluster: white - - -  ## Balance Measures ##                 Type Diff.Adj ## distance    Distance   0.0216 ## race_black    Binary   0.0000 ## race_hispan   Binary   0.0000 ## race_white    Binary   0.0000 ## age          Contin.  -0.4201 ## educ         Contin.  -0.1403 ## married       Binary  -0.0556 ## nodegree      Binary   0.1111 ## re74         Contin.  -0.0417 ## re75         Contin.   0.0298 ##  ## Sample sizes ##                           0  1 ## All                  281.   18 ## Matched (ESS)         25.92 18 ## Matched (Unweighted)  31.   18 ## Unmatched            250.    0 ##  - - - - - - - - - - - - - - bal.tab(m.out, cluster = \"race\", which.cluster = .none) ## Balance summary across all clusters ##                 Type Min.Diff.Adj Mean.Diff.Adj Max.Diff.Adj ## distance    Distance       0.0150        0.0438       0.0947 ## race_black    Binary       0.0000        0.0000       0.0000 ## race_hispan   Binary       0.0000        0.0000       0.0000 ## race_white    Binary       0.0000        0.0000       0.0000 ## age          Contin.      -0.4201       -0.1096       0.1914 ## educ         Contin.      -0.4159       -0.1590       0.0794 ## married       Binary      -0.0556        0.0366       0.1364 ## nodegree      Binary      -0.0032        0.1117       0.2273 ## re74         Contin.      -0.1501       -0.0252       0.1161 ## re75         Contin.      -0.1406       -0.0142       0.0683 ##  ## Total sample sizes across clusters ##                           0   1 ## All                  429.   185 ## Matched (ESS)         82.47 185 ## Matched (Unweighted) 125.   185 ## Unmatched            304.     0 #Just for black bal.tab(m.out, cluster = \"race\", which.cluster = \"black\") ## Balance by cluster ##  ##  - - - Cluster: black - - -  ## Balance Measures ##                 Type Diff.Adj ## distance    Distance   0.0150 ## race_black    Binary   0.0000 ## race_hispan   Binary   0.0000 ## race_white    Binary   0.0000 ## age          Contin.  -0.1001 ## educ         Contin.   0.0794 ## married       Binary   0.0288 ## nodegree      Binary  -0.0032 ## re74         Contin.  -0.1501 ## re75         Contin.  -0.1406 ##  ## Sample sizes ##                          0   1 ## All                  87.   156 ## Matched (ESS)        41.42 156 ## Matched (Unweighted) 76.   156 ## Unmatched            11.     0 ##  - - - - - - - - - - - - - - #Just the balance summary across clusters with only the mean bal.tab(m.out, cluster = \"race\", which.cluster = .none, cluster.fun = \"mean\") ## Balance summary across all clusters ##                 Type Mean.Diff.Adj ## distance    Distance        0.0438 ## race_black    Binary        0.0000 ## race_hispan   Binary        0.0000 ## race_white    Binary        0.0000 ## age          Contin.       -0.1096 ## educ         Contin.       -0.1590 ## married       Binary        0.0366 ## nodegree      Binary        0.1117 ## re74         Contin.       -0.0252 ## re75         Contin.       -0.0142 ##  ## Total sample sizes across clusters ##                           0   1 ## All                  429.   185 ## Matched (ESS)         82.47 185 ## Matched (Unweighted) 125.   185 ## Unmatched            304.     0"},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt_A2_segmented_data.html","id":"bal-plot","dir":"Articles","previous_headings":"Clustered Data","what":"bal.plot()","title":"Appendix 2: Using cobalt with Clustered, Multiply Imputed, and Other Segmented Data","text":"bal.plot() functions non-clustered data, except multiple plots can produced time displaying balance cluster. arguments bal.plot() bal.tab(), except cluster.summary absent. example use bal.plot() clustered data:  Balance plots cluster displayed next . can specify .cluster bal.tab() restrict plotting subset clusters.","code":"bal.plot(m.out, var.name = \"age\", cluster = \"race\", which = \"both\")"},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt_A2_segmented_data.html","id":"love-plot","dir":"Articles","previous_headings":"Clustered Data","what":"love.plot()","title":"Appendix 2: Using cobalt with Clustered, Multiply Imputed, and Other Segmented Data","text":"love.plot() shines clustered data several options unique cobalt help visual display balance. One way display cluster balance love.plot() produce different plots cluster, bal.plot() . method used many clusters, plots unreadable. present example, issue. , .cluster argument bal.tab() love.plot() must set names indices clusters balance plotted. .cluster set .(default), clusters plotted. example:  plots function like using love.plot() non-clustered data, except sorted based values balance statistics (can still sorted alphabetically, though). ensure covariates line across plots. axis limits apply plots. Second, balance can displayed summarizing across clusters plotting aggregate function (.e., mean maximum) balance statistic covariate across clusters. , .cluster love.plot command must set .none. change aggregate function displayed, use argument agg.fun, may “mean” “max”. example:  third option set agg.fun = \"range\" (default), produces similar plot except minimum maximum values balance statistics covariate displayed well. See example:  point represents mean balance statistic, bars represent intervals bounded minimum maximum balance statistic. display can especially helpful many clusters given mean alone may tell whole story. cases, might useful set limits x-axis using limits argument love.plot(); may cut ranges, whatever left displayed. love.plot() arguments work methods case non-clustered data. var.order specified \"unadjusted\" \"adjusted\", ordering occur mean balance statistic using agg.fun = \"range\". one argument stats allowed segmented data produces one plot (.e., .cluster = .).","code":"love.plot(m.out, cluster = \"race\") love.plot(m.out, cluster = \"race\", which.cluster = .none, agg.fun = \"mean\") love.plot(m.out, cluster = \"race\", which.cluster = .none, agg.fun = \"range\")"},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt_A2_segmented_data.html","id":"multiply-imputed-data","dir":"Articles","previous_headings":"","what":"Multiply Imputed Data","title":"Appendix 2: Using cobalt with Clustered, Multiply Imputed, and Other Segmented Data","text":"Multiply imputed data works similar way clustered data, except “grouping” variable refers imputations rather clusters. Thus, row belongs one imputation (.e., data set “long” format). data set used include imputed data sets original data set missing values (unlike Stata’s mi commands, require original data set well). imputed data sets can different sizes (.e., matching reduced size differently), preferred size weights used indicate units belong sample . example , use version Lalonde data set values missing. use mice package implement multiple imputation chained equations. perform “within” approach using MatchThem perform propensity score weighting within imputation educ continuous treatment (substantively analysis makes sense just illustration).","code":"data(\"lalonde_mis\", package = \"cobalt\")  #Generate imputed data sets m <- 10 #number of imputed data sets imp.out <- mice::mice(lalonde_mis, m = m, print = FALSE)    #Performing generalized propensity score weighting in each imputation wt.out <- MatchThem::weightthem(educ ~ age + race + married +                                      re74 + re75, datasets = imp.out,                                  approach = \"within\", method = \"ps\")"},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt_A2_segmented_data.html","id":"bal-tab-1","dir":"Articles","previous_headings":"Multiply Imputed Data","what":"bal.tab()","title":"Appendix 2: Using cobalt with Clustered, Multiply Imputed, and Other Segmented Data","text":"ways use bal.tab() imputed data sets. using mimids wimids methods MatchThem objects, output object needs supplied. using methods, argument imp can supplied; contain imputation identifiers unit name variable supplied dataset (e.g., data argument) contains imputation identifiers. Alternatively, mids object resulting call mice can supplied data argument, automatically populates imp. four arguments relevant imputed data: imp vector imputation numbers unit name variable available data set containing imputation numbers. data mids object mimids wimids methods used, doesn’t need specified. .imp determines imputation balance assessment displayed. Often can useful examine balance just imputations detailed examination going . Can .display imputations (recommended), .none display none, vector providing imputation numbers desired imputations. (Default: imputations displayed.) imp.summary determines whether display summary balance across imputations. (Default: summary balance across imputations displayed.) imp.fun determines function(s) used combine balance statistics across imputations summary balance across imputations. (Default: abs = FALSE, minimum, mean, maximum; abs = TRUE, mean maximum) imp.summary imp.fun can also set global options using set.cobalt.options() like corresponding cluster options. many cases, variables imputed, often treatment variable imputed. imputation number units, can specify arguments (e.g., treatment, distance) specifying object length one imputation, vector applied imputations. come handy supplying additional covariates weren’t involved imputation propensity score estimation addl. , imputed data set must sorted imputation unit ID. ’re using wimids object, can just call bal.tab() first argument. First, see balance summary across imputations. table presents minimum, mean, maximum balance statistics variable across imputations. Setting un = TRUE also display values adjusted data set. Setting abs = TRUE make bal.tab report summaries absolute values balance statistics. table functions way table balance across clusters. average sample size across imputations; matching weighting schemes, sample size (effective sample size) may differ across imputations. view balance individual imputations, can specify imputation number .imp. (summary across imputations automatically hidden can forced displayed using imp.summary.) clustered data, bal.tab() options work non-imputed data. Indeed, functions clustered imputed data nearly identical except imputed data, bal.tab() computes average sample size across imputations, whereas forms segmented data, bal.tab() computes total sample size across groups.","code":"#Checking balance on the output object bal.tab(wt.out) ## Balance summary across all imputations ##                Type Min.Corr.Adj Mean.Corr.Adj Max.Corr.Adj ## age         Contin.       0.0259        0.0382       0.0480 ## race_black   Binary      -0.0532       -0.0441      -0.0396 ## race_hispan  Binary       0.0061        0.0102       0.0123 ## race_white   Binary       0.0316        0.0366       0.0451 ## married      Binary       0.0344        0.0403       0.0481 ## re74        Contin.      -0.0224       -0.0065       0.0066 ## re75        Contin.      -0.0183       -0.0019       0.0199 ##  ## Average effective sample sizes across imputations ##             Total ## Unadjusted 614.   ## Adjusted   541.85 bal.tab(wt.out, which.imp = 1) ## Balance by imputation ##  ##  - - - Imputation 1 - - -  ## Balance Measures ##                Type Corr.Adj ## age         Contin.   0.0480 ## race_black   Binary  -0.0418 ## race_hispan  Binary   0.0084 ## race_white   Binary   0.0355 ## married      Binary   0.0410 ## re74        Contin.  -0.0166 ## re75        Contin.  -0.0183 ##  ## Effective sample sizes ##             Total ## Unadjusted 614.   ## Adjusted   536.41 ##  - - - - - - - - - - - - - -"},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt_A2_segmented_data.html","id":"bal-plot-1","dir":"Articles","previous_headings":"Multiply Imputed Data","what":"bal.plot()","title":"Appendix 2: Using cobalt with Clustered, Multiply Imputed, and Other Segmented Data","text":"bal.plot() works imputed data non-imputed data, except multiple plots can produced displaying balance multiple imputations time. arguments bal.plot() bal.tab(), except imp.summary absent. example use bal.plot() imputed matched data MatchThem, examining balance first imputation:  many imputations generated, recommended plot time specifying argument .imp, done . .imp set .none, data combined across imputation produce single plot, can act summary heuristic may obscure imbalances occurring imputations others.","code":"bal.plot(wt.out, which.imp = 1, var.name = \"age\", which = \"both\")"},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt_A2_segmented_data.html","id":"love-plot-1","dir":"Articles","previous_headings":"Multiply Imputed Data","what":"love.plot()","title":"Appendix 2: Using cobalt with Clustered, Multiply Imputed, and Other Segmented Data","text":"love.plot() functions imputed data clustered data. recommended display balance multiple imputations time, rather display balance summarized across imputations:  Often ranges small imputed data sets similar , imputations generated, wider ranges tend .","code":"love.plot(wt.out, threshold = .05)"},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt_A2_segmented_data.html","id":"multi-category-treatments-with-multiply-imputed-data","dir":"Articles","previous_headings":"","what":"Multi-Category Treatments with Multiply Imputed Data","title":"Appendix 2: Using cobalt with Clustered, Multiply Imputed, and Other Segmented Data","text":"far ’ve seen cobalt functions work one layer data segmentation, now let’s see ’s like work two layers segmentation. example, ’ll first look multiply imputed data multi-category treatment. multi-category treatments, balance typically assessed examining balance statistics computed pairs treatments. multi-category multiply imputed data, data segmented imputation treatment pair. ’ll use three-category race variable multi-category treatment use imputed data . , MatchThem package can used estimate weights multiply imputed data. ’ll use propensity score weighting estimate ATE race. , analysis makes sense substantively just illustration.","code":"#Estimate weights within each imputation using propensity scores wt3.out <- MatchThem::weightthem(race ~ age + educ + married +                                       nodegree + re74 + re75,                                   datasets = imp.out, approach = \"within\",                                   method = \"ps\", estimand = \"ATE\",                                  use.mlogit = FALSE)"},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt_A2_segmented_data.html","id":"bal-tab-2","dir":"Articles","previous_headings":"Multi-Category Treatments with Multiply Imputed Data","what":"bal.tab()","title":"Appendix 2: Using cobalt with Clustered, Multiply Imputed, and Other Segmented Data","text":"Using bal.tab() resulting object following: pair treatments, balance assessed imputation aggregated across imputations. , pair treatments, everything described previous section occur. options can supplied choose balance computed multi-category treatments; described ?bal.tab.multi main vignette. Importantly, though, balance summary across treatment pairs available.","code":"bal.tab(wt3.out) ## Balance by treatment pair ##  ##  - - - black (0) vs. hispan (1) - - -  ## Balance summary across all imputations ##             Type Min.Diff.Adj Mean.Diff.Adj Max.Diff.Adj ## age      Contin.       0.0031        0.0242       0.0560 ## educ     Contin.      -0.1061       -0.0881      -0.0508 ## married   Binary      -0.0427       -0.0343      -0.0236 ## nodegree  Binary       0.0268        0.0361       0.0426 ## re74     Contin.      -0.1170       -0.0414       0.0118 ## re75     Contin.      -0.1133       -0.0903      -0.0735 ##  ## Average effective sample sizes across imputations ##             black hispan ## Unadjusted 243.    72.   ## Adjusted   162.59  55.02 ##  ##  - - - black (0) vs. white (1) - - -  ## Balance summary across all imputations ##             Type Min.Diff.Adj Mean.Diff.Adj Max.Diff.Adj ## age      Contin.       0.0256        0.0356       0.0488 ## educ     Contin.      -0.0735       -0.0574      -0.0288 ## married   Binary       0.0020        0.0063       0.0104 ## nodegree  Binary       0.0138        0.0201       0.0251 ## re74     Contin.      -0.1368       -0.0879      -0.0469 ## re75     Contin.      -0.1246       -0.0995      -0.0765 ##  ## Average effective sample sizes across imputations ##             black  white ## Unadjusted 243.   299.   ## Adjusted   162.59 260.55 ##  ##  - - - hispan (0) vs. white (1) - - -  ## Balance summary across all imputations ##             Type Min.Diff.Adj Mean.Diff.Adj Max.Diff.Adj ## age      Contin.      -0.0176        0.0114       0.0313 ## educ     Contin.       0.0170        0.0307       0.0361 ## married   Binary       0.0340        0.0406       0.0462 ## nodegree  Binary      -0.0212       -0.0161      -0.0087 ## re74     Contin.      -0.0628       -0.0465      -0.0197 ## re75     Contin.      -0.0211       -0.0092       0.0029 ##  ## Average effective sample sizes across imputations ##            hispan  white ## Unadjusted  72.   299.   ## Adjusted    55.02 260.55 ##  - - - - - - - - - - - - - - - - - - - - - - - -"},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt_A2_segmented_data.html","id":"bal-plot-2","dir":"Articles","previous_headings":"Multi-Category Treatments with Multiply Imputed Data","what":"bal.plot()","title":"Appendix 2: Using cobalt with Clustered, Multiply Imputed, and Other Segmented Data","text":"bal.plot() works multi-category treatments way binary treatments. treatment levels displayed plot. , multiply imputed data, balance can examined one imputations time.","code":"bal.plot(wt3.out, var.name = \"married\", which.imp = 1,          which = \"both\")"},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt_A2_segmented_data.html","id":"love-plot-2","dir":"Articles","previous_headings":"Multi-Category Treatments with Multiply Imputed Data","what":"love.plot()","title":"Appendix 2: Using cobalt with Clustered, Multiply Imputed, and Other Segmented Data","text":"multiple layers segmentation, love.plot() options. , saw facet plot segments aggregate across segments; multiple layers, can . love.plot() can aggregate across many layers can facet segments one layer. two layers segmentation, least one . arguments must .none (aggregate) length 1 (facet one segment layer). ’ll demonstrate aggregating across imputations faceting treatment pairs.  arguments .treat, .imp, abs, agg.fun can used control plots faceted aggregated can single-layer data.","code":"love.plot(wt3.out, threshold = .1, agg.fun = \"mean\")"},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt_A2_segmented_data.html","id":"concluding-remarks","dir":"Articles","previous_headings":"","what":"Concluding Remarks","title":"Appendix 2: Using cobalt with Clustered, Multiply Imputed, and Other Segmented Data","text":"demonstrated use cobalt clustered data, multiply imputed data, multiply imputed data multi-category treatment. Though published recommendations display balance cases, believe tools may encourage development area. general, believe displaying relevant information compactly possible, thus recommend using love.plot() degree aggregation inclusion published work.","code":""},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt_A3_longitudinal_treat.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Appendix 3: Using cobalt with Longitudinal Treatments","text":"’re going use iptwExWide data set twang package. variables outcome, outcome, gender, age, use0, baseline covariates, use1 use2, time-varying covariates measured treatment periods 1 2, tx1, tx2, tx3, treatments three treatment periods. goal balance assessment scenario ensure following: tx1 independent gender, age, use0 tx2 independent gender, age, use0, tx1, use1 tx3 independent gender, age, use0, tx1, use1, tx2, use2 estimate weights, ’ll use WeightIt fit series logistic regressions generate weights. See WeightIt documentation information use WeightIt longitudinal treatments. Next ’ll use bal.tab() examine balance applying weights.","code":"library(\"cobalt\") data(\"iptwExWide\", package = \"twang\") head(iptwExWide) ##      outcome gender age        use0         use1       use2 tx1 tx2 tx3 ## 1 -0.2782802      0  43  1.13496509  0.467482544  0.3174825   1   1   1 ## 2  0.5319329      0  50  1.11193185  0.455965923  0.4059659   1   0   1 ## 3 -0.8173614      1  36 -0.87077763 -0.535388817 -0.5853888   1   0   0 ## 4 -0.1530853      1  63  0.21073159  0.005365793 -0.1446342   1   1   1 ## 5 -0.7344267      0  24  0.06939565 -0.065302176 -0.1153022   1   0   1 ## 6 -0.8519376      1  20 -1.66264885 -0.931324426 -1.0813244   1   1   1 Wmsm <- WeightIt::weightitMSM(     list(tx1 ~ use0 + gender + age,          tx2 ~ use0 + gender + age + use1 + tx1,          tx3 ~ use0 + gender + age + use1 + tx1 + use2 + tx2),     data = iptwExWide,     method = \"ps\")"},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt_A3_longitudinal_treat.html","id":"bal-tab","dir":"Articles","previous_headings":"","what":"bal.tab()","title":"Appendix 3: Using cobalt with Longitudinal Treatments","text":"examine balance original data, can specify treatment-covariate relationship want assess using either formula data frame interfaces bal.tab(). formula interface requires list formulas, one treatment, data set containing relevant variables. data set must “wide” setup, time point receives columns unit exactly one row data. formula interface similar WeightIt input seen . data frame interface requires list treatment values time point data frame list covariates time point. ’ll use data frame interface . see summary balance across time points. displays variable, many times appears balance tables, type, greatest imbalance variable across time points. summary sample sizes across time points. request balance individual time points, can use .time argument, can set one numbers ..none (default). ’ll request balance time points setting .time = .. hides balance summary across time points, can requested setting msm.summary = TRUE. see balance time point. time point, bal.tab object produced time point. function just like regular bal.tab objects. output appear matter treatment types (.e., binary, continuous, multi-category), multi-category treatments treatment types vary multiply imputed data, balance summary computed displayed. can use bal.tab() weightitMSM object generated . Setting un = TRUE produce balance statistics adjustment, like . ’ll set .time = .msm.summary = TRUE see balance time point across time points. Note add covariates, must use addl.list (can abbreviated addl), functions like addl point treatments. input addl.list must list covariates time point, single data data frame variables assessed time points. goes adding distance variables, must done distance.list (can abbreviated distance). Next ’ll use bal.plot() finely examine covariate balance.","code":"bal.tab(list(iptwExWide[c(\"use0\", \"gender\", \"age\")],              iptwExWide[c(\"use0\", \"gender\", \"age\", \"use1\", \"tx1\")],              iptwExWide[c(\"use0\", \"gender\", \"age\", \"use1\", \"tx1\", \"use2\", \"tx2\")]),         treat.list = iptwExWide[c(\"tx1\", \"tx2\", \"tx3\")]) ## Balance summary across all time points ##          Times    Type Max.Diff.Un ## use0   1, 2, 3 Contin.      0.2668 ## gender 1, 2, 3  Binary      0.2945 ## age    1, 2, 3 Contin.      0.3799 ## use1      2, 3 Contin.      0.1662 ## tx1       2, 3  Binary      0.1695 ## use2         3 Contin.      0.1087 ## tx2          3  Binary      0.2423 ##  ## Sample sizes ##  - Time 1 ##     Control Treated ## All     294     706 ##  - Time 2 ##     Control Treated ## All     492     508 ##  - Time 3 ##     Control Treated ## All     415     585 bal.tab(list(iptwExWide[c(\"use0\", \"gender\", \"age\")],              iptwExWide[c(\"use0\", \"gender\", \"age\", \"use1\", \"tx1\")],              iptwExWide[c(\"use0\", \"gender\", \"age\", \"use1\", \"tx1\", \"use2\", \"tx2\")]),         treat.list = iptwExWide[c(\"tx1\", \"tx2\", \"tx3\")],         which.time = .all) ## Balance by Time Point ##  ##  - - - Time: 1 - - -  ## Balance Measures ##           Type Diff.Un ## use0   Contin.  0.2668 ## gender  Binary  0.2945 ## age    Contin.  0.3799 ##  ## Sample sizes ##     Control Treated ## All     294     706 ##  ##  - - - Time: 2 - - -  ## Balance Measures ##           Type Diff.Un ## use0   Contin.  0.1169 ## gender  Binary  0.1927 ## age    Contin.  0.2240 ## use1   Contin.  0.0848 ## tx1     Binary  0.1695 ##  ## Sample sizes ##     Control Treated ## All     492     508 ##  ##  - - - Time: 3 - - -  ## Balance Measures ##           Type Diff.Un ## use0   Contin.  0.1859 ## gender  Binary  0.1532 ## age    Contin.  0.3431 ## use1   Contin.  0.1662 ## tx1     Binary  0.1071 ## use2   Contin.  0.1087 ## tx2     Binary  0.2423 ##  ## Sample sizes ##     Control Treated ## All     415     585 ##  - - - - - - - - - - - bal.tab(Wmsm, un = TRUE, which.time = .all, msm.summary = TRUE) ## Balance by Time Point ##  ##  - - - Time: 1 - - -  ## Balance Measures ##                Type Diff.Un Diff.Adj ## prop.score Distance  0.7862   0.0251 ## use0        Contin.  0.2668   0.0558 ## gender       Binary  0.2945   0.0224 ## age         Contin.  0.3799  -0.0019 ##  ## Effective sample sizes ##            Control Treated ## Unadjusted  294.     706.  ## Adjusted    185.18   573.6 ##  ##  - - - Time: 2 - - -  ## Balance Measures ##                Type Diff.Un Diff.Adj ## prop.score Distance  0.5288  -0.0065 ## use0        Contin.  0.1169  -0.0327 ## gender       Binary  0.1927  -0.0117 ## age         Contin.  0.2240   0.0703 ## use1        Contin.  0.0848  -0.0311 ## tx1          Binary  0.1695  -0.0088 ##  ## Effective sample sizes ##            Control Treated ## Unadjusted   492.   508.   ## Adjusted     318.9  264.49 ##  ##  - - - Time: 3 - - -  ## Balance Measures ##                Type Diff.Un Diff.Adj ## prop.score Distance  0.6565   0.0229 ## use0        Contin.  0.1859  -0.0347 ## gender       Binary  0.1532   0.0263 ## age         Contin.  0.3431   0.0182 ## use1        Contin.  0.1662  -0.0316 ## tx1          Binary  0.1071  -0.0171 ## use2        Contin.  0.1087  -0.0315 ## tx2          Binary  0.2423   0.0085 ##  ## Effective sample sizes ##            Control Treated ## Unadjusted  415.     585.  ## Adjusted    235.67   366.4 ##  - - - - - - - - - - -  ##  ## Balance summary across all time points ##              Times     Type Max.Diff.Un Max.Diff.Adj ## prop.score 1, 2, 3 Distance      0.7862       0.0251 ## use0       1, 2, 3  Contin.      0.2668       0.0558 ## gender     1, 2, 3   Binary      0.2945       0.0263 ## age        1, 2, 3  Contin.      0.3799       0.0703 ## use1          2, 3  Contin.      0.1662       0.0316 ## tx1           2, 3   Binary      0.1695       0.0171 ## use2             3  Contin.      0.1087       0.0315 ## tx2              3   Binary      0.2423       0.0085 ##  ## Effective sample sizes ##  - Time 1 ##            Control Treated ## Unadjusted  294.     706.  ## Adjusted    185.18   573.6 ##  - Time 2 ##            Control Treated ## Unadjusted   492.   508.   ## Adjusted     318.9  264.49 ##  - Time 3 ##            Control Treated ## Unadjusted  415.     585.  ## Adjusted    235.67   366.4"},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt_A3_longitudinal_treat.html","id":"bal-plot","dir":"Articles","previous_headings":"","what":"bal.plot()","title":"Appendix 3: Using cobalt with Longitudinal Treatments","text":"can compare distributions covariates across treatment groups time point using bal.plot(), just point treatments.  Balance variables appear certain time points displayed time points:  bal.tab(), .time can specified limit output chosen time points. Finally, ’ll examine using love.plot() longitudinal treatments display balance presentation.","code":"bal.plot(Wmsm, var.name = \"age\", which = \"both\") bal.plot(Wmsm, var.name = \"tx1\", which = \"both\")"},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt_A3_longitudinal_treat.html","id":"love-plot","dir":"Articles","previous_headings":"","what":"love.plot()","title":"Appendix 3: Using cobalt with Longitudinal Treatments","text":"love.plot() works longitudinal treatments just point treatments, except user can choose whether display separate plots time point one plot summary across time points. bal.tab(), user can set .time display certain time points. set .none, summary across time points displayed. agg.fun argument set \"max\" default.","code":"love.plot(Wmsm, abs = TRUE) ## Warning: Standardized mean differences and raw mean differences are present in the same plot.  ## Use the 'stars' argument to distinguish between them and appropriately label the x-axis. love.plot(Wmsm, which.time = .none) ## Warning: Standardized mean differences and raw mean differences are present in the same plot.  ## Use the 'stars' argument to distinguish between them and appropriately label the x-axis."},{"path":"https://ngreifer.github.io/cobalt/articles/cobalt_A3_longitudinal_treat.html","id":"other-packages","dir":"Articles","previous_headings":"","what":"Other Packages","title":"Appendix 3: Using cobalt with Longitudinal Treatments","text":"used WeightIt generate MSM weights, cobalt compatible packages longitudinal treatments well. CBMSM objects CBPS package iptw objects twang package can used place weightitMSM object examples. addition, users generated balancing weights outside package can specify argument weights bal.tab() formula data frame methods assess balance using weights, can use default method bal.tab() supply object containing objects required balance assessment (output optweight particularly well suited ). Note CBPS estimates assesses balance MSM weights differently twang cobalt. focus ensuring balance across treatment history permutations, whereas cobalt focuses evaluating similarity sequential randomization. reason, may appear CBMSM objects different balance qualities measured two packages.","code":""},{"path":[]},{"path":[]},{"path":"https://ngreifer.github.io/cobalt/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Noah Greifer. Author, maintainer.","code":""},{"path":"https://ngreifer.github.io/cobalt/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Greifer N (2022). cobalt: Covariate Balance Tables Plots. https://ngreifer.github.io/cobalt/, https://github.com/ngreifer/cobalt.","code":"@Manual{,   title = {cobalt: Covariate Balance Tables and Plots},   author = {Noah Greifer},   year = {2022},   note = {https://ngreifer.github.io/cobalt/, https://github.com/ngreifer/cobalt}, }"},{"path":[]},{"path":[]},{"path":"https://ngreifer.github.io/cobalt/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Covariate Balance Tables and Plots","text":"Welcome cobalt, stands Covariate Balance Tables (Plots). cobalt allows users assess balance covariate distributions preprocessed groups generated weighting, matching, subclassification, using propensity score. cobalt’s primary function bal.tab(), stands “balance table”, meant replace (supplement) balance assessment tools found R packages. examine bal.tab() integrates packages others, see help file bal.tab() ?bal.tab, links methods used package. page examples bal.tab() used package. also five vignettes detailing use cobalt, can accessed vignette(\"cobalt\"): one basic uses cobalt, one use cobalt additional packages, one use cobalt multiply imputed /clustered data, one use cobalt longitudinal treatments, one use cobalt generate publication-ready plots. Currently, cobalt compatible output MatchIt, twang, Matching, optmatch, CBPS, ebal, WeightIt, designmatch, sbw, MatchThem, cem well data processed packages. information, check cobalt website!","code":""},{"path":"https://ngreifer.github.io/cobalt/index.html","id":"why-cobalt","dir":"","previous_headings":"","what":"Why cobalt?","title":"Covariate Balance Tables and Plots","text":"major conditioning packages contain functions assess balance; use cobalt ? cobalt arose several desiderata using packages: standardized measures consistent across conditioning packages, allow flexibility calculation display balance measures, incorporate recent methodological recommendations assessment balance. addition, cobalt unique plotting capabilities make use ggplot2 R balance assessment reporting. conditioning methods spread across several packages idiosyncrasies report balance (), comparing resulting balance various conditioning methods can challenge. cobalt unites packages providing single, flexible tool intelligently processes output conditioning packages provides user useful defaults customizable options display calculation. cobalt also allows balance assessment data generated conditioning packages. addition, cobalt tools assessing reporting balance clustered data sets, data sets generated multiple imputation, data sets continuous treatment variable, features exist limited capacities packages. large focus developing cobalt streamline output useful, non-redundant, complete information displayed, user’s choice. Balance statistics intuitive, methodologically informed, simple interpret. Visual displays balance reflect goals balance assessment rather steps removed. packages focused efforts processing data, cobalt assesses balance, particularly well. New features added time, following cutting edge methodological work balance assessment. new packages methods developed, cobalt ready integrate goal simple, unified balance assessment.","code":""},{"path":"https://ngreifer.github.io/cobalt/index.html","id":"examples","dir":"","previous_headings":"","what":"Examples","title":"Covariate Balance Tables and Plots","text":"examples cobalt’s primary functions:   Please remember cite package using analyze data. example, manuscript, write: “Matching performed using Matching package (Sekhon, 2011), covariate balance assessed using cobalt (Greifer, 2022), R (R Core Team, 2022).” Use citation(\"cobalt\") generate bibliographic reference cobalt package. Bugs appear cobalt occasionally, often found users. Please report bugs https://github.com/ngreifer/cobalt/issues. install latest development version cobalt, may removed bug ’re experiencing, use following code:","code":"library(\"cobalt\") data(\"lalonde\", package = \"cobalt\")  #Nearest neighbor matching with MatchIt m.out <- MatchIt::matchit(treat ~ age + educ + race + married +                               nodegree + re74 + re75,                           data = lalonde)  #Checking balance before and after matching: bal.tab(m.out, thresholds = c(m = .1), un = TRUE) #> Balance Measures #>                 Type Diff.Un Diff.Adj        M.Threshold #> distance    Distance  1.7941   0.9739                    #> age          Contin. -0.3094   0.0718     Balanced, <0.1 #> educ         Contin.  0.0550  -0.1290 Not Balanced, >0.1 #> race_black    Binary  0.6404   0.3730 Not Balanced, >0.1 #> race_hispan   Binary -0.0827  -0.1568 Not Balanced, >0.1 #> race_white    Binary -0.5577  -0.2162 Not Balanced, >0.1 #> married       Binary -0.3236  -0.0216     Balanced, <0.1 #> nodegree      Binary  0.1114   0.0703     Balanced, <0.1 #> re74         Contin. -0.7211  -0.0505     Balanced, <0.1 #> re75         Contin. -0.2903  -0.0257     Balanced, <0.1 #>  #> Balance tally for mean differences #>                    count #> Balanced, <0.1         5 #> Not Balanced, >0.1     4 #>  #> Variable with the greatest mean difference #>    Variable Diff.Adj        M.Threshold #>  race_black    0.373 Not Balanced, >0.1 #>  #> Sample sizes #>           Control Treated #> All           429     185 #> Matched       185     185 #> Unmatched     244       0 #Examining distributional balance with plots: bal.plot(m.out, var.name = \"educ\") bal.plot(m.out, var.name = \"distance\",          mirror = TRUE, type = \"histogram\") #Generating a Love plot to report balance: love.plot(m.out, stats = c(\"mean.diffs\", \"variance.ratios\"),           thresholds = c(m = .1, v = 2), abs = TRUE,            binary = \"std\",           var.order = \"unadjusted\") devtools::install_github(\"ngreifer/cobalt\")"},{"path":"https://ngreifer.github.io/cobalt/reference/bal.plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize Distributional Balance — bal.plot","title":"Visualize Distributional Balance — bal.plot","text":"Generates density plots, bar graphs, scatterplots displaying distributional balance treatment covariates using ggplot2.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize Distributional Balance — bal.plot","text":"","code":"bal.plot(x,      var.name,      ...,      which,      which.sub = NULL,      cluster = NULL,     which.cluster = NULL,      imp = NULL,     which.imp = NULL,      which.treat = NULL,     which.time = NULL,     mirror = FALSE,      type = \"density\",      colors = NULL,     grid = FALSE,     sample.names,     position = \"right\",      facet.formula = NULL,      disp.means = getOption(\"cobalt_disp.means\", FALSE),     alpha.weight = TRUE)"},{"path":"https://ngreifer.github.io/cobalt/reference/bal.plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize Distributional Balance — bal.plot","text":"x object balance assessed; can object support bal.tab(). var.name character; name variable whose values plotted. view distributions distance measure (e.g., propensity score), , use \"distance\" argument unless distance variable named. duplicate variable names across inputs, bal.plot() first look covariate data.frame x, followed addl, distance, . specified, use first covariate available warning. ... arguments define variable, treatment, weights. inputs required depending method. See Additional Arguments. Can also used supply bw, adjust, kernel, n arguments ggplot2::geom_density() bins argument ggplot2::geom_histogram(). whether display distributional balance adjusted (\"adjusted\") unadjusted sample (\"unadjusted\") time (\"\"). multiple weights present, names weights can supplied, . default display balance adjusted sample unless weights, subclasses, matching strata specified. Multiple values abbreviations allowed. .sub numeric; subclassification used, vector corresponding subclass(es) distributions displayed. .(default), distributions subclasses displayed grid. cluster optional; vector cluster membership, name variable available data set passed bal.plot() contains cluster membership. .cluster clusters used, cluster(s) display. Can cluster names numerical indices display balance. Indices correspond alphabetical order cluster names. .(default), clusters displayed. .none, cluster information ignored marginal distribution covariates displayed. imp optional; vector imputation indices, name variable available data set passed bal.plot() contains imputation indices. .imp imputations used, imputations(s) display. Must numerical indices display balance. .(default), imputations displayed. .none, data imputations combined one distribution. .treat treatment groups display. NULL (default) NA, treatment groups displayed. .time longitudinal treatments, time points display. Can treatment names time period indices. NULL (default) NA, time points displayed. mirror logical; treatment binary, covariate continuous, densities histograms requested, whether display mirrored densities/histograms overlapping densities/histograms. Ignored otherwise. type character; binary multi-category treatments continuous covariate, whether display densities (\"density\"), histograms  (\"histogram\"), empirical cumulative density function plots (\"ecdf\"). default display densities. Abbreviations allowed. colors vector colors plotted densities/histograms. See 'Color Specification' graphics::par(). Defaults default ggplot2 colors. grid logical; whether gridlines shown plot. Default TRUE. sample.names character; new names given samples (.e., place \"Unadjusted Sample\" \"Adjusted Sample\"). example, matching used, may useful enter c(\"Unmatched\", \"Matched\"). position position legend. can value appropriate argument legend.position ggplot2::theme(). facet.formula formula designating facets rows columns. \"historical\" formula interface ggplot2::facet_grid(). form ~ b, faceted rows b columns. facet rows, provide one-sided formula empty left-hand side. facet columns, formula form ~ . (.e., . right-hand side). allowable facets depend arguments supplied bal.plot(); possible values include , cluster, imp, (longitudinal treatments) time. NULL, bal.plot() decide looks best; argument exists case disagree choice. disp.means logical; categorical treatment continuous covariate, whether line drawn treatment level denoting (weighted) mean covariate. Ignored type \"density\" \"histogram\". Default FALSE. alpha.weight logical; treatment covariate continuous, whether points shaded according weight. Fainter points smaller weights. Default TRUE.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.plot.html","id":"additional-arguments","dir":"Reference","previous_headings":"","what":"Additional Arguments","title":"Visualize Distributional Balance — bal.plot","text":"bal.plot() works like bal.tab() can take variety types inputs yield output . Depending kind input given, different additional parameters required .... details required allowed additional input defaults, see help file bal.tab() method associated input. following required additional arguments based input type: matchit objects: None weightit objects: None ps, ps.cont, mnps, iptw objects: (stop.method; see defaults). Match objects: formula data covs treat. optmatch objects: formula data covs (treat required). CBPS objects: None ebalance objects: formula data covs treat. formulas: data data.frames: treat designmatch objects: formula data covs treat. sbw objects: None mimids wimids objects: None, argument .imp specified. objects processed bal.tab()'s default method, whichever arguments required identify treatment, variables, conditioning method ().","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.plot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Visualize Distributional Balance — bal.plot","text":"bal.plot() uses ggplot2::ggplot() ggplot2 package, (invisibly) returns \"ggplot\" object. categorical treatments continuous covariates continuous treatments categorical covariates, density plots created using ggplot2::geom_density(), histograms created using ggplot2::geom_histogram(), empirical CDF plots created using geom_step(); categorical treatments categorical covariates, bar graphs created using ggplot2::geom_bar(); continuous treatments continuous covariates, scatterplots created using ggplot2::geom_point(). continuous treatments continuous covariates, four additional lines presented aid balance assessment. red line linear fit line. blue line smoothing curve generated ggplot2's ggplot2::geom_smooth() method = \"auto\". horizontal black line horizontal reference line intercepting (unweighted) treatment mean. vertical black line reference line intercepting (unweighted) treatment mean. Balance indicated flatness fit lines whether pass intersection two black reference lines. multiple plots displayed (.e., requesting subclass balance, cluster balance, imputation balance, multiple sets weights provided = \"\", treatment longitudinal), plots displayed grid using ggplot2's ggplot2::facet_grid(). Subclassification used clusters multiply imputed data. change plot axis titles, use ggplot2::labs(). output ggplot object, elements can changed using ggplot2 functions; see example.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Visualize Distributional Balance — bal.plot","text":"\"ggplot\" object, returned invisibly.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.plot.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Visualize Distributional Balance — bal.plot","text":"Noah Greifer","code":""},{"path":[]},{"path":"https://ngreifer.github.io/cobalt/reference/bal.plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualize Distributional Balance — bal.plot","text":"","code":"if (requireNamespace(\"MatchIt\", quietly = TRUE)) { data(\"lalonde\", package = \"cobalt\")  #Nearest Neighbor Matching library(MatchIt) m.out <- matchit(treat ~ age + educ + race +                   married + nodegree + re74 + re75,                   data = lalonde)  bal.plot(m.out, \"age\", which = \"both\") bal.plot(m.out, \"re74\", which = \"both\", type = \"ecdf\") bal.plot(m.out, \"race\", which = \"both\") bal.plot(m.out, \"distance\", which = \"both\", mirror = TRUE,          type = \"histogram\", colors = c(\"white\", \"black\")) }; if (requireNamespace(\"WeightIt\", quietly = TRUE)) { #PS weighting with a continuous treatment library(WeightIt) w.out <- weightit(re75 ~ age + I(age^2) + educ +                    race + married + nodegree,                   data = lalonde)                    bal.plot(w.out, \"age\", which = \"both\") bal.plot(w.out, \"married\", which = \"both\") } #>  #> Attaching package: ‘MatchIt’ #> The following object is masked _by_ ‘.GlobalEnv’: #>  #>     lalonde #> The following object is masked from ‘package:cobalt’: #>  #>     lalonde"},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.CBPS.html","id":null,"dir":"Reference","previous_headings":"","what":"Balance statistics for CBPS Objects — bal.tab.CBPS","title":"Balance statistics for CBPS Objects — bal.tab.CBPS","text":"Generates balance statistics CBPS CBMSM objects CBPS package.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.CBPS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Balance statistics for CBPS Objects — bal.tab.CBPS","text":"","code":"# S3 method for CBPS bal.tab(x,          stats,         int = FALSE,         poly = 1,         distance = NULL,         addl = NULL,         data = NULL,         continuous,         binary,         s.d.denom,         thresholds = NULL,         weights = NULL,         cluster = NULL,         imp = NULL,         pairwise = TRUE,         s.weights = NULL,         abs = FALSE,         subset = NULL,         quick = TRUE,         ...)"},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.CBPS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Balance statistics for CBPS Objects — bal.tab.CBPS","text":"x CBPS CBMSM object; output call CBPS::CBPS() CBPS::CBMSM(). stats, int, poly, data, continuous, binary, thresholds, weights, cluster, imp, pairwise, abs, subset, quick, ... see bal.tab() details. See special notes distance, addl, s.d.denom, s.weights arguments. following arguments special notes used CBPS CBMSM objects: distance propensity scores generated CBPS() CBMSM() automatically included named \"prop.score\". CBMSM objects, dataset list supplied distance must one row per individual, unlike data frame original call CBMSM(). addl CBMSM objects, dataset list supplied addl must one row per individual, unlike data frame original call CBMSM(). s.d.denom specified, bal.tab() use \"treated\" estimand call CBPS() ATT \"pooled\" estimand ATE. s.weights CBPS object return sampling weights even used; rather, weights returned already sampling weights combined within . checks defaults bal.tab() rely patterns weights, using sampling weights CBPS() without specifying bal.tab() can lead incorrect results. sampling weights used CBPS(), important specified bal.tab() well using s.weights argument.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.CBPS.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Balance statistics for CBPS Objects — bal.tab.CBPS","text":"bal.tab.CBPS() bal.tab.CBMSM() generate list balance summaries CBPS CBMSM object given functions similarly CBPS::balance().","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.CBPS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Balance statistics for CBPS Objects — bal.tab.CBPS","text":"point treatments, clusters specified, object class \"bal.tab\" containing balance summaries CBPS object. See bal.tab() details. clusters specified, object class \"bal.tab.cluster\" containing balance summaries within cluster summary balance across clusters. See bal.tab.cluster details. CBPS() used multi-category treatments, object class \"bal.tab.multi\" containing balance summaries pairwise treatment comparison summary balance across pairwise comparisons. See bal.tab.multi details. CBMSM() used longitudinal treatments, object class \"bal.tab.msm\" containing balance summaries time period summary balance across time periods. See bal.tab.msm details.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.CBPS.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Balance statistics for CBPS Objects — bal.tab.CBPS","text":"Noah Greifer","code":""},{"path":[]},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.CBPS.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Balance statistics for CBPS Objects — bal.tab.CBPS","text":"","code":"library(CBPS) #> Loading required package: MASS #> Loading required package: nnet #> Loading required package: numDeriv #> Loading required package: glmnet #> Loading required package: Matrix #> Loaded glmnet 4.1-4 #> CBPS: Covariate Balancing Propensity Score #> Version: 0.23 #> Authors: Christian Fong [aut, cre], #>   Marc Ratkovic [aut], #>   Kosuke Imai [aut], #>   Chad Hazlett [ctb], #>   Xiaolin Yang [ctb], #>   Sida Peng [ctb], #>   Inbeom Lee [ctb] data(\"lalonde\", package = \"cobalt\")  ## Using CBPS() for generating covariate balancing  ## propensity score weights cbps.out <- CBPS(treat ~ age + educ + married + race +              nodegree + re74 + re75, data = lalonde) #> [1] \"Finding ATT with T=1 as the treatment.  Set ATT=2 to find ATT with T=0 as the treatment\"               bal.tab(cbps.out) #> Balance Measures #>                 Type Diff.Adj #> prop.score  Distance  -0.0057 #> age          Contin.  -0.0052 #> educ         Contin.  -0.0017 #> married       Binary  -0.0029 #> race_black    Binary   0.0019 #> race_hispan   Binary  -0.0002 #> race_white    Binary  -0.0017 #> nodegree      Binary   0.0042 #> re74         Contin.  -0.0078 #> re75         Contin.   0.0061 #>  #> Effective sample sizes #>            Control Treated #> Unadjusted  429.       185 #> Adjusted     99.97     185"},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.Match.html","id":null,"dir":"Reference","previous_headings":"","what":"Balance Statistics for Matching, optmatch, ebal, and designmatch Objects — bal.tab.Match","title":"Balance Statistics for Matching, optmatch, ebal, and designmatch Objects — bal.tab.Match","text":"Generates balance statistics output objects Matching, optmatch, ebal, designmatch.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.Match.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Balance Statistics for Matching, optmatch, ebal, and designmatch Objects — bal.tab.Match","text":"","code":"# S3 method for Match bal.tab(x,          formula = NULL,         data = NULL,         treat = NULL,         covs = NULL,         stats,         int = FALSE,         poly = 1,         distance = NULL,         addl = NULL,         continuous,         binary,         s.d.denom,         thresholds = NULL,         weights = NULL,         cluster = NULL,         imp = NULL,         pairwise = TRUE,         s.weights = NULL,         abs = FALSE,         subset = NULL,         quick = TRUE,         ...)"},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.Match.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Balance Statistics for Matching, optmatch, ebal, and designmatch Objects — bal.tab.Match","text":"x either Match object (output call Matching::Match() Matching::Matchby()), optmatch object (output call optmatch::pairmatch() optmatch::fullmatch()), ebalance object (output call ebal::ebalance() ebal::ebalance.trim()), output call designmatch::bmatch() related wrapper functions designmatch package. formula formula treatment variable response covariates balance assessed predictors. named variables must data. See Details. data data frame containing variables named formula, supplied, arguments. treat vector treatment statuses. See Details. covs data frame covariate values check balance. See Details. stats, int, poly, distance, addl, continuous, binary, thresholds, weights, cluster, imp, pairwise, s.weights, abs, subset, quick, ... see bal.tab() details. See special note s.d.denom argument. following argument special notes used input objects: s.d.denom specified, Match objects, bal.tab() use \"treated\" estimand call Match() ATT, \"pooled\" estimand ATE, \"control\" estimand ATC; optmatch, ebal, designmatch objects, bal.tab() determine value makes sense based input. Abbreviations allowed.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.Match.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Balance Statistics for Matching, optmatch, ebal, and designmatch Objects — bal.tab.Match","text":"bal.tab() generates list balance summaries object given, function similarly Matching::MatchBalance() designmatch::meantab(). Note output objects designmatch class; bal.tab() first checks whether object meets criteria treated designmatch object dispatching correct method. Renaming removing items output object can create unintended consequences. input bal.tab.Match(), bal.tab.optmatch(), bal.tab.ebalance(), bal.tab.designmatch() must include either formula data covs treat. Using formula + data inputs mirrors Matching::MatchBalance() used, using covs + treat input mirrors designmatch::meantab() used. (Note see identical results meantab(), s.d.denom must set \"pooled\", though recommended.) optmatch output objects, specifying treatment required.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.Match.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Balance Statistics for Matching, optmatch, ebal, and designmatch Objects — bal.tab.Match","text":"point treatments, clusters imputations specified, object class \"bal.tab\" containing balance summaries given object. See bal.tab() details. clusters specified, object class \"bal.tab.cluster\" containing balance summaries within cluster summary balance across clusters. See bal.tab.cluster details.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.Match.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Balance Statistics for Matching, optmatch, ebal, and designmatch Objects — bal.tab.Match","text":"Noah Greifer","code":""},{"path":[]},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.Match.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Balance Statistics for Matching, optmatch, ebal, and designmatch Objects — bal.tab.Match","text":"","code":"########## Matching ##########  library(Matching); data(\"lalonde\", package = \"cobalt\") #> ##  #> ##  Matching (Version 4.10-4, Build Date: 2022-10-26) #> ##  See http://sekhon.berkeley.edu/matching for additional documentation. #> ##  Please cite software as: #> ##   Jasjeet S. Sekhon. 2011. ``Multivariate and Propensity Score Matching #> ##   Software with Automated Balance Optimization: The Matching package for R.'' #> ##   Journal of Statistical Software, 42(7): 1-52.  #> ##  p.score <- glm(treat ~ age + educ + race +              married + nodegree + re74 + re75,              data = lalonde, family = \"binomial\")$fitted.values Match.out <- Match(Tr = lalonde$treat, X = p.score)  ## Using formula and data bal.tab(Match.out, formula = treat ~ age + educ + race +          married + nodegree + re74 + re75, data = lalonde) #> Balance Measures #>                Type Diff.Adj #> age         Contin.   0.2106 #> educ        Contin.   0.0201 #> race_black   Binary   0.0054 #> race_hispan  Binary  -0.0051 #> race_white   Binary  -0.0003 #> married      Binary   0.0661 #> nodegree     Binary  -0.0079 #> re74        Contin.  -0.0772 #> re75        Contin.  -0.0127 #>  #> Sample sizes #>                      Control Treated #> All                   429.       185 #> Matched (ESS)          49.17     185 #> Matched (Unweighted)  136.       185 #> Unmatched             293.         0 ########## optmatch ##########  library(\"optmatch\"); data(\"lalonde\", package = \"cobalt\")  lalonde$prop.score <- glm(treat ~ age + educ + race +              married + nodegree + re74 + re75,              data = lalonde, family = binomial)$fitted.values pm <- pairmatch(treat ~ prop.score, data = lalonde)  ## Using formula and data bal.tab(pm, formula = treat ~ age + educ + race +          married + nodegree + re74 + re75, data = lalonde,         distance = \"prop.score\") #> Balance Measures #>                 Type Diff.Adj #> prop.score  Distance   0.9740 #> age          Contin.   0.0922 #> educ         Contin.  -0.1264 #> race_black    Binary   0.3730 #> race_hispan   Binary  -0.1568 #> race_white    Binary  -0.2162 #> married       Binary  -0.0162 #> nodegree      Binary   0.0703 #> re74         Contin.  -0.0539 #> re75         Contin.  -0.0247 #>  #> Sample sizes #>           Control Treated #> All           429     185 #> Matched       185     185 #> Unmatched     244       0 ########## ebal ##########  library(\"ebal\"); data(\"lalonde\", package = \"cobalt\") #> ## #> ## ebal Package: Implements Entropy Balancing. #> ## See http://www.stanford.edu/~jhain/ for additional information. #>   covariates <- subset(lalonde, select = -c(re78, treat, race)) e.out <- ebalance(lalonde$treat, covariates) #> Converged within tolerance   ## Using treat and covs bal.tab(e.out, treat = lalonde$treat, covs = covariates) #> Balance Measures #>               Type Diff.Adj #> age        Contin.       -0 #> educ       Contin.       -0 #> married     Binary       -0 #> nodegree    Binary        0 #> re74       Contin.       -0 #> re75       Contin.       -0 #> prop.score Contin.        0 #>  #> Effective sample sizes #>            Control Treated #> Unadjusted  429.       185 #> Adjusted     95.28     185 ########## designmatch ########## # \\donttest{ library(\"designmatch\"); data(\"lalonde\", package = \"cobalt\") #> Loading required package: lattice #> Loading required package: slam #> Loading required package: Rglpk #> Using the GLPK callable library version 4.65  covariates <- as.matrix(lalonde[c(\"age\", \"educ\", \"re74\", \"re75\")]) treat <- lalonde$treat dmout <- bmatch(treat,                 total_groups = sum(treat == 1),                 mom = list(covs = covariates,                            tols = absstddif(covariates,                                              treat, .05))                 ) #>   Building the matching problem...  #>   GLPK optimizer is open...  #>   Finding the optimal matches...  #>   Optimal matches found   ## Using treat and covs bal.tab(dmout, treat = treat, covs = covariates) #> Balance Measures #>         Type Diff.Adj #> age  Contin.   0.0567 #> educ Contin.  -0.0538 #> re74 Contin.  -0.0613 #> re75 Contin.  -0.0501 #>  #> Sample sizes #>           Control Treated #> All           429     185 #> Matched       185     185 #> Unmatched     244       0 # }"},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.cem.match.html","id":null,"dir":"Reference","previous_headings":"","what":"Balance Statistics for cem Objects — bal.tab.cem.match","title":"Balance Statistics for cem Objects — bal.tab.cem.match","text":"Generates balance statistics cem.match objects cem.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.cem.match.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Balance Statistics for cem Objects — bal.tab.cem.match","text":"","code":"# S3 method for cem.match bal.tab(x,          data,         stats,         int = FALSE,         poly = 1,         distance = NULL,         addl = NULL,         continuous,         binary,         s.d.denom,         thresholds = NULL,         weights = NULL,         cluster = NULL,         imp = NULL,         pairwise = TRUE,         s.weights = NULL,         abs = FALSE,         subset = NULL,         quick = TRUE,         ...)"},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.cem.match.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Balance Statistics for cem Objects — bal.tab.cem.match","text":"x cem.match cem.match.list object; output call cem::cem(). data data frame containing variables named arguments. argument data required. must data used call cem() mids object data supplied datalist cem() call originated. stats, int, poly, distance, addl, continuous, binary, thresholds, weights, cluster, imp, pairwise, s.weights, abs, subset, quick, ... see bal.tab() details. See special note s.d.denom argument. following argument special note used cem.match cem.match.list objects: s.d.denom default \"treated\", treated group corresponds baseline.group call cem().","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.cem.match.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Balance Statistics for cem Objects — bal.tab.cem.match","text":"bal.tab.cem.match() generates list balance summaries cem.match object given, functions similarly cem::imbalance().","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.cem.match.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Balance Statistics for cem Objects — bal.tab.cem.match","text":"clusters imputations specified, object class \"bal.tab\" containing balance summaries cem.match object. See bal.tab() details. imputations specified, object class \"bal.tab.imp\" containing balance summaries imputation summary balance across imputations. See bal.tab.imp details. cem() used multi-category treatments, object class \"bal.tab.multi\" containing balance summaries pairwise treatment comparison. See bal.tab.multi details. clusters specified, object class \"bal.tab.cluster\" containing balance summaries within cluster summary balance across clusters. See bal.tab.cluster details.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.cem.match.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Balance Statistics for cem Objects — bal.tab.cem.match","text":"Noah Greifer","code":""},{"path":[]},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.cem.match.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Balance Statistics for cem Objects — bal.tab.cem.match","text":"","code":"library(cem); data(\"lalonde\", package = \"cobalt\") #> Loading required package: tcltk #>  #> How to use CEM? Type vignette(\"cem\") #>  #> Attaching package: ‘cem’ #> The following object is masked from ‘package:optmatch’: #>  #>     pair  ## Coarsened exact matching cem.out <- cem(\"treat\", data = lalonde, drop = \"re78\") #>  #> Using 'treat'='1' as baseline group  bal.tab(cem.out, data = lalonde, un = TRUE,          stats = c(\"m\", \"k\")) #> Balance Measures #>                Type Diff.Un  KS.Un Diff.Adj KS.Adj #> age         Contin. -0.3094 0.1577   0.0512 0.1581 #> educ        Contin.  0.0550 0.1114  -0.0441 0.0445 #> race_black   Binary  0.6404 0.6404   0.0000 0.0000 #> race_hispan  Binary -0.0827 0.0827   0.0000 0.0000 #> race_white   Binary -0.5577 0.5577   0.0000 0.0000 #> married      Binary -0.3236 0.3236   0.0000 0.0000 #> nodegree     Binary  0.1114 0.1114   0.0000 0.0000 #> re74        Contin. -0.7211 0.4470  -0.0341 0.2418 #> re75        Contin. -0.2903 0.2876  -0.0528 0.1162 #>  #> Sample sizes #>                      Control Treated #> All                   429.       185 #> Matched (ESS)          36.29      68 #> Matched (Unweighted)   78.        68 #> Unmatched             351.       117"},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.default.html","id":null,"dir":"Reference","previous_headings":"","what":"Balance Statistics for Other Objects — bal.tab.default","title":"Balance Statistics for Other Objects — bal.tab.default","text":"Generates balance statistics using object defined method.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.default.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Balance Statistics for Other Objects — bal.tab.default","text":"","code":"# S3 method for default bal.tab(x,         stats,         int = FALSE,         poly = 1,         distance = NULL,         addl = NULL,         data = NULL,         continuous,         binary,         s.d.denom,         thresholds = NULL,         weights = NULL,         cluster = NULL,         imp = NULL,         pairwise = TRUE,         s.weights = NULL,         abs = FALSE,         subset = NULL,         quick = TRUE,         ...)"},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.default.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Balance Statistics for Other Objects — bal.tab.default","text":"x object containing information conditioning. See Details. stats, int, poly, distance, addl, data, continuous, binary, s.d.denom, thresholds, weights, cluster, imp, pairwise, s.weights, abs, subset, quick see bal.tab() details. ... arguments passed bal.tab.formula(), bal.tab.data.frame(), bal.tab.time.list(). See Details.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.default.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Balance Statistics for Other Objects — bal.tab.default","text":"bal.tab.default() processes input attempt extract enough information display covariate balance x. purpose method allow users created objects containing conditioning information (.e., weights, subclasses, treatments, covariates, etc.) access capabilities bal.tab() without special method written . including correct items x, bal.tab.default() can present balance tables input output one specifically supported packages (e.g., MatchIt, twang, etc.). function search x following named items attempt process : treat vector (numeric, character, factor) containing values treatment unit name column data containing . Essentially input treat bal.tab.data.frame(). treat.list list vectors (numeric, character, factor) containing, time point, values treatment unit name column data containing . Essentially input treat.list bal.tab.time.list(). covs data.frame containing values covariates unit. Essentially input covs bal.tab.data.frame(). covs.list list data.frames containing, time point, values covariates unit. Essentially input covs.list bal.tab.time.list(). formula formula treatment variable response covariates balance assessed terms. Essentially input formula bal.tab.formula(). formula.list list formulas , time point, treatment variable response covariates balance assessed terms. Essentially input formula.list bal.tab.time.list(). data data.frame containing variables names used arguments components (e.g., formula, weights, etc.). Essentially input data bal.tab.formula(), bal.tab.data.frame(), bal.tab.time.list(). weights vector, list, data.frame containing weights unit string containing names weights variables data. Essentially input weights bal.tab.data.frame() bal.tab.time.list(). distance vector, formula, data frame containing distance values (e.g., propensity scores) character vector containing names. formula variable names specified, bal.tab() look argument data, specified. Essentially input distance bal.tab.data.frame(). formula.list list vectors data.frames containing, time point, distance values (e.g., propensity scores) unit string containing name distance variable data. Essentially input distance.list bal.tab.time.list(). subclass vector containing subclass membership unit string containing name subclass variable data. Essentially input subclass bal.tab.data.frame(). match.strata vector containing matching stratum membership unit string containing name matching stratum variable data. Essentially input match.strata bal.tab.data.frame(). estimand character vector; whether desired estimand \"ATT\", \"ATC\", \"ATE\" set weights. Essentially input estimand bal.tab.data.frame(). s.weights vector containing sampling weights unit string containing name sampling weight variable data. Essentially input s.weights bal.tab.data.frame() bal.tab.time.list(). focal name focal treatment multi-category treatments used. Essentially input focal bal.tab.data.frame(). call call object containing function call, usually generated using match.call() inside function created x. items can also supplied directly bal.tab.default, e.g., bal.tab.default(x, formula = treat ~ x1 + x2). supplied, override object role x. addition, arguments bal.tab.formula(), bal.tab.data.frame(), bal.tab.time.list() allowed perform function. least inputs containing information create treatment covariates required (e.g., formula data covs treat). arguments optional defaults bal.tab.data.frame() bal.tab.time.list(). treat.list, covs.list, formula.list supplied x argument bal.tab.default(), function proceed considering longitudinal treatment. Otherwise, proceed considering point treatment. bal.tab.default(), like bal.tab methods, just shortcut supply arguments bal.tab.data.frame() bal.tab.time.list(). Therefore, matters regarding argument priority function described documentation methods.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.default.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Balance Statistics for Other Objects — bal.tab.default","text":"point treatments, clusters imputations specified, object class \"bal.tab\" containing balance summaries specified treatment covariates. See bal.tab() details. clusters specified, object class \"bal.tab.cluster\" containing balance summaries within cluster summary balance across clusters. See bal.tab.cluster details. imputations specified, object class \"bal.tab.imp\" containing balance summaries imputation summary balance across imputations, just clusters. See bal.tab.imp details. multi-category treatments used, object class \"bal.tab.multi\" containing balance summaries pairwise treatment comparison summary balance across pairwise comparisons. See bal.tab.multi details. longitudinal treatments used, object class \"bal.tab.msm\" containing balance summaries time point. balance summary bal.tab object. See bal.tab.msm details.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.default.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Balance Statistics for Other Objects — bal.tab.default","text":"Noah Greifer","code":""},{"path":[]},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.default.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Balance Statistics for Other Objects — bal.tab.default","text":"","code":"data(\"lalonde\", package = \"cobalt\") covs <- subset(lalonde,  select = -c(treat, re78))  ##Writing a function the produces output for direct ##use in bal.tab.default  ate.weights <- function(treat, covs) {     data <- data.frame(treat, covs)     formula <- formula(data)     ps <- glm(formula, data = data,                family = \"binomial\")$fitted.values     weights <- treat/ps + (1-treat)/(1-ps)     call <- match.call()     out <- list(treat = treat,                 covs = covs,                 distance = ps,                 weights = weights,                 estimand = \"ATE\",                 call = call)     return(out) }  out <- ate.weights(lalonde$treat, covs)  bal.tab(out, un = TRUE) #> Balance Measures #>                 Type Diff.Un Diff.Adj #> distance    Distance  1.7569   0.1360 #> age          Contin. -0.2419  -0.1676 #> educ         Contin.  0.0448   0.1296 #> race_black    Binary  0.6404   0.0499 #> race_hispan   Binary -0.0827   0.0047 #> race_white    Binary -0.5577  -0.0546 #> married       Binary -0.3236  -0.0944 #> nodegree      Binary  0.1114  -0.0547 #> re74         Contin. -0.5958  -0.2740 #> re75         Contin. -0.2870  -0.1579 #>  #> Effective sample sizes #>            Control Treated #> Unadjusted  429.    185.   #> Adjusted    329.01   58.33"},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.df.formula.html","id":null,"dir":"Reference","previous_headings":"","what":"Balance Statistics for Data Sets — bal.tab.df.formula","title":"Balance Statistics for Data Sets — bal.tab.df.formula","text":"Generates balance statistics unadjusted, matched, weighted, stratified data using either data.frame formula interface.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.df.formula.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Balance Statistics for Data Sets — bal.tab.df.formula","text":"","code":"# S3 method for data.frame bal.tab(x,          treat,         stats,         int = FALSE,         poly = 1,         distance = NULL,         addl = NULL,         data = NULL,         continuous,         binary,         s.d.denom,         thresholds = NULL,         weights = NULL,         cluster = NULL,         imp = NULL,         pairwise = TRUE,         s.weights = NULL,         abs = FALSE,         subset = NULL,         quick = TRUE,         subclass = NULL,         match.strata = NULL,         method,         estimand = NULL,         focal = NULL,         ...)  # S3 method for formula bal.tab(x,          data = NULL,         stats,         int = FALSE,         poly = 1,         distance = NULL,         addl = NULL,         continuous,         binary,         s.d.denom,         thresholds = NULL,         weights = NULL,         cluster = NULL,         imp = NULL,         pairwise = TRUE,         s.weights = NULL,         abs = FALSE,         subset = NULL,         quick = TRUE,         subclass = NULL,         match.strata = NULL,         method,         estimand = NULL,         focal = NULL,         ...)"},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.df.formula.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Balance Statistics for Data Sets — bal.tab.df.formula","text":"x either data.frame containing covariate values unit formula treatment variable response covariates balance assessed terms. formula supplied, terms must present variable names data global environment. treat either vector containing treatment status values unit string containing name treatment variable data. Required data.frame method. stats, int, poly, distance, addl, data, continuous, binary, thresholds, weights, cluster, imp, pairwise, s.weights, abs, subset, quick, ... see bal.tab() details. See special note s.d.denom argument. subclass optional; either vector containing subclass membership unit string containing name subclass variable data. match.strata optional; either vector containing matching stratum membership unit string containing name matching stratum variable data. See Details. method character; method adjustment, . weights specified, user can specify either \"matching\" \"weighting\"; \"weighting\" default. multiple sets weights used, must corresponding value method, type, one value required. subclass specified, \"subclassification\" default. Abbreviations allowed. distinction \"matching\" \"weighting\" sample sizes displayed. estimand character; whether desired estimand \"ATT\", \"ATC\", \"ATE\" set weights. argument can used place s.d.denom specify standardized differences calculated. focal name focal treatment multi-category treatments used. See bal.tab.multi details. following argument special note used data.frame formula input objects: s.d.denom weights supplied, set weights corresponding entry s.d.denom; single entry recycled sets weights. left blank one weights, subclass, match.strata supplied, bal.tab() figure one best based estimand, given (ATT, \"treated\"; ATC, \"control\"; otherwise \"pooled\") clues .","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.df.formula.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Balance Statistics for Data Sets — bal.tab.df.formula","text":"bal.tab.data.frame() generates list balance summaries covariates treatment status values given. bal.tab.formula() uses formula interface instead.  formula interface used, formula data reshaped treatment vector data.frame covariates simply passed data.frame method. weights, subclass match.strata NULL, balance information presented unadjusted sample. argument match.strata corresponds factor vector containing name index pair/stratum units conditioned matching, example, using optmatch package. one weights, subclass, match.strata specified, bal.tab() attempt figure one apply. Currently one can applied ta time. bal.tab() behaves differently depending whether subclasses used conditioning . used, bal.tab() creates balance statistics subclass sample aggregate. See bal.tab.subclass information. Multiple sets weights can supplied simultaneously entering data.frame character vector containing names weight variables found data list weights vectors names. arguments method, s.d.denom, estimand, , must either length number sets weights length one, sole entry applied sets. standardized differences computed unadjusted group, done using first entry s.d.denom estimand. one set weights supplied, output adjusted group simply called \"Adj\", otherwise named corresponding set weights. Specifying multiple sets weights also add components outputs bal.tab().","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.df.formula.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Balance Statistics for Data Sets — bal.tab.df.formula","text":"point treatments, clusters imputations specified, object class \"bal.tab\" containing balance summaries specified treatment covariates. See bal.tab() details. imputations specified, object class \"bal.tab.imp\" containing balance summaries imputation summary balance across imputations. See bal.tab.imp details. multi-category treatments used, object class \"bal.tab.multi\" containing balance summaries pairwise treatment comparison. See bal.tab.multi details. clusters specified, object class \"bal.tab.cluster\" containing balance summaries within cluster summary balance across clusters. See bal.tab.cluster details.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.df.formula.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Balance Statistics for Data Sets — bal.tab.df.formula","text":"Noah Greifer","code":""},{"path":[]},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.df.formula.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Balance Statistics for Data Sets — bal.tab.df.formula","text":"","code":"data(\"lalonde\", package = \"cobalt\") lalonde$p.score <- glm(treat ~ age + educ + race, data = lalonde,                         family = \"binomial\")$fitted.values covariates <- subset(lalonde, select = c(age, educ, race))                       ## Propensity score weighting using IPTW lalonde$iptw.weights <- ifelse(lalonde$treat==1,                                 1/lalonde$p.score,                                 1/(1-lalonde$p.score))  # data frame interface: bal.tab(covariates, treat = \"treat\", data = lalonde,          weights = \"iptw.weights\", s.d.denom = \"pooled\") #> Balance Measures #>                Type Diff.Adj #> age         Contin.  -0.1242 #> educ        Contin.   0.0727 #> race_black   Binary   0.0053 #> race_hispan  Binary  -0.0025 #> race_white   Binary  -0.0029 #>  #> Effective sample sizes #>            Control Treated #> Unadjusted  429.    185.   #> Adjusted    344.33   65.47  # Formula interface: bal.tab(treat ~ age + educ + race, data = lalonde,          weights = \"iptw.weights\", s.d.denom = \"pooled\") #> Balance Measures #>                Type Diff.Adj #> age         Contin.  -0.1242 #> educ        Contin.   0.0727 #> race_black   Binary   0.0053 #> race_hispan  Binary  -0.0025 #> race_white   Binary  -0.0029 #>  #> Effective sample sizes #>            Control Treated #> Unadjusted  429.    185.   #> Adjusted    344.33   65.47        ## Propensity score subclassification lalonde$subclass <- findInterval(lalonde$p.score,                          quantile(lalonde$p.score,                          (0:6)/6), all.inside = TRUE)  # data frame interface: bal.tab(covariates, treat = \"treat\", data = lalonde,          subclass = \"subclass\", disp.subclass = TRUE,          s.d.denom = \"pooled\") #> Balance by subclass #>  - - - Subclass 1 - - -  #>                Type Diff.Adj #> age         Contin.  -1.2029 #> educ        Contin.  -0.2551 #> race_black   Binary   0.0000 #> race_hispan  Binary   0.0000 #> race_white   Binary   0.0000 #>  #>  - - - Subclass 2 - - -  #>                Type Diff.Adj #> age         Contin.   0.4108 #> educ        Contin.   0.3005 #> race_black   Binary   0.0000 #> race_hispan  Binary   0.0000 #> race_white   Binary   0.0000 #>  #>  - - - Subclass 3 - - -  #>                Type Diff.Adj #> age         Contin.  -0.1400 #> educ        Contin.   0.0295 #> race_black   Binary   0.0000 #> race_hispan  Binary  -0.0833 #> race_white   Binary   0.0833 #>  #>  - - - Subclass 4 - - -  #>                Type Diff.Adj #> age         Contin.   0.2294 #> educ        Contin.  -0.4409 #> race_black   Binary   0.3467 #> race_hispan  Binary  -0.3467 #> race_white   Binary   0.0000 #>  #>  - - - Subclass 5 - - -  #>                Type Diff.Adj #> age         Contin.   0.4675 #> educ        Contin.   0.3427 #> race_black   Binary   0.0000 #> race_hispan  Binary   0.0000 #> race_white   Binary   0.0000 #>  #>  - - - Subclass 6 - - -  #>                Type Diff.Adj #> age         Contin.   0.1293 #> educ        Contin.  -0.0838 #> race_black   Binary   0.0000 #> race_hispan  Binary   0.0000 #> race_white   Binary   0.0000 #>   # Formula interface: bal.tab(treat ~ age + educ + race, data = lalonde,        subclass = \"subclass\", disp.subclass = TRUE,        s.d.denom = \"pooled\") #> Balance by subclass #>  - - - Subclass 1 - - -  #>                Type Diff.Adj #> age         Contin.  -1.2029 #> educ        Contin.  -0.2551 #> race_black   Binary   0.0000 #> race_hispan  Binary   0.0000 #> race_white   Binary   0.0000 #>  #>  - - - Subclass 2 - - -  #>                Type Diff.Adj #> age         Contin.   0.4108 #> educ        Contin.   0.3005 #> race_black   Binary   0.0000 #> race_hispan  Binary   0.0000 #> race_white   Binary   0.0000 #>  #>  - - - Subclass 3 - - -  #>                Type Diff.Adj #> age         Contin.  -0.1400 #> educ        Contin.   0.0295 #> race_black   Binary   0.0000 #> race_hispan  Binary  -0.0833 #> race_white   Binary   0.0833 #>  #>  - - - Subclass 4 - - -  #>                Type Diff.Adj #> age         Contin.   0.2294 #> educ        Contin.  -0.4409 #> race_black   Binary   0.3467 #> race_hispan  Binary  -0.3467 #> race_white   Binary   0.0000 #>  #>  - - - Subclass 5 - - -  #>                Type Diff.Adj #> age         Contin.   0.4675 #> educ        Contin.   0.3427 #> race_black   Binary   0.0000 #> race_hispan  Binary   0.0000 #> race_white   Binary   0.0000 #>  #>  - - - Subclass 6 - - -  #>                Type Diff.Adj #> age         Contin.   0.1293 #> educ        Contin.  -0.0838 #> race_black   Binary   0.0000 #> race_hispan  Binary   0.0000 #> race_white   Binary   0.0000 #>"},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.df.formula.list.html","id":null,"dir":"Reference","previous_headings":"","what":"Balance Statistics for Longitudinal Datasets — bal.tab.df.formula.list","title":"Balance Statistics for Longitudinal Datasets — bal.tab.df.formula.list","text":"Generates balance statistics data coming longitudinal treatment scenario. primary input form list formulas data.frames contain covariates time point. bal.tab() automatically classifies list either data.frame.list formula.list, respectively.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.df.formula.list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Balance Statistics for Longitudinal Datasets — bal.tab.df.formula.list","text":"","code":"# S3 method for data.frame.list bal.tab(x,          treat.list,         stats,         int = FALSE,         poly = 1,         distance = NULL,         addl = NULL,         data = NULL,         continuous,         binary,         s.d.denom,         thresholds = NULL,         weights = NULL,         cluster = NULL,         imp = NULL,         pairwise = TRUE,         s.weights = NULL,         abs = FALSE,         subset = NULL,         quick = TRUE,         ...)      # S3 method for formula.list bal.tab(x,          stats,         int = FALSE,         poly = 1,         distance = NULL,         addl = NULL,         data = NULL,         continuous,         binary,         s.d.denom,         thresholds = NULL,         weights = NULL,         cluster = NULL,         imp = NULL,         pairwise = TRUE,         s.weights = NULL,         abs = FALSE,         subset = NULL,         quick = TRUE,         ...)"},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.df.formula.list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Balance Statistics for Longitudinal Datasets — bal.tab.df.formula.list","text":"x either list data frames containing covariates assessed time point list formulas treatment time period left covariates balance displayed right. Covariates assessed multiple points must included entries time point. Data must \"wide\" format, one row per unit. formula list supplied, argument data required unless objects formulas exist environment. treat.list treatment status unit time point. can specified list data frame vectors, contains treatment status individual time point, list vector names variables data contain treatment time point. Required data.frame.list method. stats, int, poly, distance, addl, data, continuous, binary, thresholds, weights, cluster, imp, pairwise, s.weights, abs, subset, quick, ... see bal.tab() details. See special note s.d.denom argument. following argument special note used longitudinal treatments: s.d.denom recommended set argument longitudinal treatments.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.df.formula.list.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Balance Statistics for Longitudinal Datasets — bal.tab.df.formula.list","text":"bal.tab.formula.list() bal.tab.data.frame.list() generate list balance summaries time point based treatments covariates provided. data must \"wide\" format, exactly one row per unit columns representing variables different time points. See WeightIt::weightitMSM() documentation example transform long data wide data using reshape(). Multiple sets weights can supplied simultaneously including entering data frame character vector containing names weight variables found data list thereof. one set weights supplied, output adjusted group simply called \"Adj\", otherwise named corresponding set weights. Specifying multiple sets weights also add components outputs bal.tab().","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.df.formula.list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Balance Statistics for Longitudinal Datasets — bal.tab.df.formula.list","text":"object class bal.tab.msm containing balance summaries time point. balance summary bal.tab object. See bal.tab.msm details. See bal.tab() base methods detailed information value bal.tab objects produced time point.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.df.formula.list.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Balance Statistics for Longitudinal Datasets — bal.tab.df.formula.list","text":"Noah Greifer","code":""},{"path":[]},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.df.formula.list.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Balance Statistics for Longitudinal Datasets — bal.tab.df.formula.list","text":"","code":"if (requireNamespace(\"twang\", quietly = TRUE)) { data(\"iptwExWide\", package = \"twang\") library(\"cobalt\")  ## Estimating longitudinal propensity scores and weights ps1 <- glm(tx1 ~ age + gender + use0,             data = iptwExWide,              family = \"binomial\")$fitted.values w1 <- ifelse(iptwExWide$tx1 == 1, 1/ps1, 1/(1-ps1)) ps2 <- glm(tx2 ~ age + gender + use0 + tx1 + use1,             data = iptwExWide,              family = \"binomial\")$fitted.values w2 <- ifelse(iptwExWide$tx2 == 1, 1/ps2, 1/(1-ps2)) ps3 <- glm(tx3 ~ age + gender + use0 + tx1 + use1 + tx2 + use2,             data = iptwExWide,              family = \"binomial\")$fitted.values w3 <- ifelse(iptwExWide$tx3 == 1, 1/ps3, 1/(1-ps3))                       w <- w1*w2*w3  # Formula interface plus addl: bal.tab(list(tx1 ~ use0 + gender,              tx2 ~ use0 + gender + use1 + tx1,              tx3 ~ use0 + gender + use1 + tx1 + use2 + tx2),         data = iptwExWide,          weights = w,         distance = list(~ps1, ~ps2, ~ps3),         addl = ~age*gender,         un = TRUE)          # data frame interface: bal.tab(list(iptwExWide[c(\"use0\", \"gender\")],              iptwExWide[c(\"use0\", \"gender\", \"use1\", \"tx1\")],              iptwExWide[c(\"use0\", \"gender\", \"use1\", \"tx1\", \"use2\", \"tx2\")]),         treat.list = iptwExWide[c(\"tx1\", \"tx2\", \"tx3\")],          weights = w,         distance = list(~ps1, ~ps2, ~ps3),         un = TRUE) } #> Balance summary across all time points #>          Times     Type Max.Diff.Un Max.Diff.Adj #> ps1          1 Distance      0.7862       0.0251 #> use0   1, 2, 3  Contin.      0.2668       0.0558 #> gender 1, 2, 3   Binary      0.2945       0.0263 #> ps2          2 Distance      0.5288       0.0065 #> use1      2, 3  Contin.      0.1662       0.0316 #> tx1       2, 3   Binary      0.1695       0.0171 #> ps3          3 Distance      0.6565       0.0229 #> use2         3  Contin.      0.1087       0.0315 #> tx2          3   Binary      0.2423       0.0085 #>  #> Effective sample sizes #>  - Time 1 #>            Control Treated #> Unadjusted  294.     706.  #> Adjusted    185.18   573.6 #>  - Time 2 #>            Control Treated #> Unadjusted   492.   508.   #> Adjusted     318.9  264.49 #>  - Time 3 #>            Control Treated #> Unadjusted  415.     585.  #> Adjusted    235.67   366.4"},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.html","id":null,"dir":"Reference","previous_headings":"","what":"Display Balance Statistics in a Table — bal.tab","title":"Display Balance Statistics in a Table — bal.tab","text":"Generates balance statistics covariates relation observed treatment variable. generic function dispatches method corresponding class first argument.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Display Balance Statistics in a Table — bal.tab","text":"","code":"bal.tab(x, ...)  ## # Arguments common across all input types: ## bal.tab(x, ##         stats, ##         int = FALSE, ##         poly = 1, ##         distance = NULL, ##         addl = NULL, ##         data = NULL, ##         continuous, ##         binary, ##         s.d.denom, ##         thresholds = NULL, ##         weights = NULL, ##         cluster = NULL, ##         imp = NULL, ##         pairwise = TRUE, ##         s.weights = NULL, ##         abs = FALSE, ##         subset = NULL, ##         quick = TRUE, ##         ...)"},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Display Balance Statistics in a Table — bal.tab","text":"x input object assess balance. Can output call balancing function another package formula data frame. Input argument determine bal.tab() method used. input type documentation page, linked See Also section . input types require allow additional arguments specified. inputs dedicated method, default method dispatched. See Details . stats character; statistic(s) reported. See stats allowable options. binary multi-category treatments, \"mean.diffs\" (.e., mean differences) default. continuous treatments, \"correlations\" (.e., treatment-covariate Pearson correlations) default. Multiple options allowed. int logical numeric; whether include 2-way interactions covariates included covs addl. numeric, passed poly well. poly numeric; highest polynomial continuous covariate display. example, 2, squares continuous covariate displayed (addition covariate ); 3, squares cubes continuous covariate displayed, etc. 1, default, base covariate displayed. int numeric, poly take value int. distance optional formula data frame containing distance values (e.g., propensity scores) character vector containing names. formula variable names specified, bal.tab() look argument data, specified. longitudinal treatments, can list allowable arguments, one time point. addl optional formula data frame containing additional covariates present balance character vector containing names. formula variable names specified, bal.tab() look arguments input object, covs, data, specified. longitudinal treatments, can list allowable arguments, one time point. data optional data frame containing variables named arguments. input object types, required. continuous whether mean differences continuous variables standardized (\"std\") raw (\"raw\"). Default \"std\". Abbreviations allowed. option can set globally using set.cobalt.options(). binary whether mean differences binary variables (.e., difference proportion) standardized (\"std\") raw (\"raw\"). Default \"raw\". Abbreviations allowed. option can set globally using set.cobalt.options(). s.d.denom character; denominator standardized mean differences calculated, requested. See col_w_smd() allowable options. weights supplied, set weights corresponding entry s.d.denom. Abbreviations allowed. left blank weights, subclasses, matching strata supplied, bal.tab() figure one best based estimand, given (ATT, \"treated\"; ATC, \"control\"; otherwise \"pooled\") clues . thresholds named vector balance thresholds, name corresponds statistic (.e., stats) threshold applies . example, request thresholds mean differences variance ratios, one can set thresholds = c(m = .05, v = 2). Requesting threshold automatically requests display statistic. specified, extra columns inserted Balance table describing whether requested balance statistics exceeded threshold . Summary tables tallying number variables exceeded within threshold displaying variables greatest imbalance balance measure added output. weights vector, list, data.frame containing weights unit, string containing names weights variables data, object get.w() method list thereof. weights can , e.g., inverse probability weights matching weights resulting matching algorithm. cluster either vector containing cluster membership unit string containing name cluster membership variable data input object. See bal.tab.cluster details. imp either vector containing imputation indices unit string containing name imputation index variable data input object. See bal.tab.imp details. necessary data mids object. pairwise whether balance computed pairs treatments treatment groups combined. See bal.tab.multi details. can also used binary treatment assess balance respect full sample. s.weights Optional; either vector containing sampling weights unit string containing name sampling weight variable data. function like regular weights except adjusted unadjusted samples weighted according weights weights used. abs logical; whether displayed balance statistics absolute value . subset logical numeric vector denoting whether observation included observations included. logical, length equal number units. NAs treated FALSE. can used alternative cluster examine balance subsets data. quick logical; TRUE, compute values displayed. Set FALSE computed values displayed used later. ... input types, arguments required allowed. See individual methods pages See Also details. Otherwise, arguments control display output. See display options details.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Display Balance Statistics in a Table — bal.tab","text":"bal.tab() performs various calculations data objects given. page details arguments calculations used across bal.tab() methods.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.html","id":"with-binary-point-treatments","dir":"Reference","previous_headings":"","what":"With Binary Point Treatments","title":"Display Balance Statistics in a Table — bal.tab","text":"Balance statistics can requested stats argument. default balance statistic mean differences continuous variables standardized mean difference, difference means divided measure spread (.e., d-type effect size measure). default puts mean differences scale comparison given threshold. binary variables, default balance statistic raw difference proportion. Although standardized differences proportion can computed, raw differences proportion binary variables already scale, computing standardized difference proportion can obscure true difference proportion dividing difference proportion number function observed proportions. Standardized mean differences calculated using col_w_smd() follows: numerator mean treated group minus mean control group, denominator measure spread calculated accordance argument s.d.denom default specific method used. Common approaches literature include using standard deviation treated group using \"pooled\" standard deviation (.e., square root mean group variances) calculating standardized mean differences. computed spread bal.tab() uses always full, unadjusted sample (.e., matching, weighting, subclassification), recommended Stuart (2010). Prior computation, variables checked variable type, allows users differentiate balance statistic calculations based type using arguments continuous binary. First, given covariate numeric 2 levels, converted binary (0,1) variable. 0 value original variable, retains value value converted 1; otherwise, lower value converted 0 1. Next, covariate numeric logical (.e., character factor variable), split new binary variables, named original variable value, separated underscore. Otherwise, covariate used treated continuous variable. Variance ratios computed within-sample using col_w_vr(), larger two variances numerator abs = TRUE, yielding values greater equal 1. Variance ratios calculated binary variables since function group proportions thus provide information differences proportion. weighting matching used, \"effective sample size\" calculated group using following formula: \\((\\sum w)^2 / \\sum w^2\\). effective sample size \"approximately number observations simple random sample yields estimate sampling variation equal sampling variation obtained weighted comparison observations\" (Ridgeway et al., 2016). calculated number tends underestimate true effective sample size weighted samples. number depends variability weights, sometimes trimming units large weights can actually increase effective sample size, even though units -weighted. matching used, additional \"unweighted\" sample size displayed indicating total number units contributing weighted sample. subclassification used, balance tables subclass stored $Subclass.Balance use values calculated described . aggregate balance table stored $Balance.Across.Subclass, values statistic computed weighted average statistic across subclasses, weighted proportion units subclass. See bal.tab.subclass details.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.html","id":"with-continuous-point-treatments","dir":"Reference","previous_headings":"","what":"With Continuous Point Treatments","title":"Display Balance Statistics in a Table — bal.tab","text":"continuous treatment variables considered, balance statistic calculated Pearson correlation covariate treatment. correlation adjustment computed using col_w_cov() weighted covariance covariate treatment divided product standard deviations unweighted covariate treatment, analogous way weighted standardized mean difference uses unweighted measure spread denominator, purpose avoiding analogous paradox (.e., covariance decreases accompanied change standard deviations, thereby distorting actual resulting balance computed using weighted standard deviations).","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.html","id":"with-multi-category-point-treatments","dir":"Reference","previous_headings":"","what":"With Multi-Category Point Treatments","title":"Display Balance Statistics in a Table — bal.tab","text":"information using bal.tab() multi-category treatments, see bal.tab.multi. Essentially, bal.tab() compares pairs treatment groups standard way.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.html","id":"with-longitudinal-treatments","dir":"Reference","previous_headings":"","what":"With Longitudinal Treatments","title":"Display Balance Statistics in a Table — bal.tab","text":"information using bal.tab() longitudinal treatments, see bal.tab.msm. Essentially, bal.tab() summarizes balance time point summarizes across time points.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.html","id":"with-clustered-or-multiply-imputed-data","dir":"Reference","previous_headings":"","what":"With Clustered or Multiply Imputed Data","title":"Display Balance Statistics in a Table — bal.tab","text":"information using bal.tab() clustered data, see bal.tab.cluster. information using bal.tab() multiply imputed data, see bal.tab.imp.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.html","id":"quick","dir":"Reference","previous_headings":"","what":"Quick","title":"Display Balance Statistics in a Table — bal.tab","text":"Calculations can take time, especially many variables, interactions, clusters. certain values printed, default computed. particular, variance ratios, KS statistics, summary tables computed display requested. can speed overall production output values used later. However, used later, output examined print() used way original call bal.tab(), may useful compute even printed initially. , users can set quick = FALSE, cause bal.tab() calculate values components can. Note love.plot() fully functional even quick = TRUE values requested otherwise computed bal.tab() quick = TRUE.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.html","id":"missing-data","dir":"Reference","previous_headings":"","what":"Missing Data","title":"Display Balance Statistics in a Table — bal.tab","text":"missing data covariates (.e., NAs covariates provided bal.tab()), additional things happen. warning appear mentioning missing values present data set. computed balance summaries variables ignoring missing values. New variables created representing missingness indicators variable, named var:<NA> (var replaced actual name variable). int = TRUE, balance pairwise interactions missingness indicators also computed. variables treated like regular variables created.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Display Balance Statistics in a Table — bal.tab","text":"object class \"bal.tab\". use continuous treatments, subclasses, clusters, /imputations also cause object inherit classes. class \"bal.tab\" print() method (print.bal.tab()), formats output nicely accordance print-related options given call bal.tab(), can called options. scenarios binary point treatments subclasses, imputations, clusters, following elements bal.tab object: Balance data frame containing balance information covariate. Balance contains following columns, additional columns present balance statistics requested: Type: Whether covariate binary, continuous, measure distance (e.g., propensity score). M.0.Un: mean control group prior adjusting. SD.0.Un: standard deviation control group prior adjusting. M.1.Un: mean treated group prior adjusting. SD.1.Un: standard deviation treated group prior adjusting. Diff.Un: (standardized) difference means two groups prior adjusting. See binary continuous arguments bal.tab method pages determine whether standardized raw mean differences reported. default, standardized mean difference displayed continuous variables raw mean difference (difference proportion) displayed binary variables. M.0.Adj: mean control group adjusting. SD.0.Adj: standard deviation control group adjusting. M.1.Adj: mean treated group adjusting. SD.1.Adj: standard deviation treated group adjusting. Diff.Adj: (standardized) difference means two groups adjusting. See binary continuous arguments bal.tab method pages determine whether standardized raw mean differences reported. default, standardized mean difference displayed continuous variables raw mean difference (difference proportion) displayed binary variables. M.Threshold: Whether calculated mean difference adjusting exceeds within threshold given thresholds.  threshold mean differences specified, column NA. Balanced.Means threshold mean differences specified, table tallying number variables exceed within threshold. Max.Imbalance.Means threshold mean differences specified, table displaying variable greatest absolute mean difference. Observations table displaying sample sizes adjusting. Often effective sample size (ESS) displayed. See Details. call original function call, adjustment performed function another package. treatment continuous, instead producing mean differences, bal.tab() produce correlations covariates treatment. corresponding entries output \"Corr.Un\", \"Corr.Adj\", \"R.Threshold\" (accordingly balance tally maximum imbalance tables). multiple weights supplied, \"Adj\" Balance replaced provided names sets weights, extra columns added set weights. Additional columns rows items output created well. bal.tab output subclassification, see bal.tab.subclass.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Display Balance Statistics in a Table — bal.tab","text":"Ridgeway, G., McCaffrey, D., Morral, ., Burgette, L., & Griffin, B. . (2016). Toolkit Weighting Analysis Nonequivalent Groups: tutorial twang package. R vignette. RAND. Stuart, E. . (2010). Matching Methods Causal Inference: Review Look Forward. Statistical Science, 25(1), 1-21. doi:10.1214/09-STS313","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Display Balance Statistics in a Table — bal.tab","text":"Noah Greifer","code":""},{"path":[]},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Display Balance Statistics in a Table — bal.tab","text":"","code":"## See individual pages above for examples with ## different inputs, or see vignette(\"cobalt\")"},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.matchit.html","id":null,"dir":"Reference","previous_headings":"","what":"Balance Statistics for MatchIt Objects — bal.tab.matchit","title":"Balance Statistics for MatchIt Objects — bal.tab.matchit","text":"Generates balance statistics matchit objects MatchIt.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.matchit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Balance Statistics for MatchIt Objects — bal.tab.matchit","text":"","code":"# S3 method for matchit bal.tab(x,          stats,         int = FALSE,         poly = 1,         distance = NULL,         addl = NULL,         data = NULL,         continuous,         binary,         s.d.denom,         thresholds = NULL,         weights = NULL,         cluster = NULL,         imp = NULL,         pairwise = TRUE,         s.weights = NULL,         abs = FALSE,         subset = NULL,         quick = TRUE,         method,         ...)"},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.matchit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Balance Statistics for MatchIt Objects — bal.tab.matchit","text":"x matchit object; output call MatchIt::matchit(). stats, int, poly, addl, data, continuous, binary, thresholds, weights, cluster, imp, pairwise, abs, subset, quick, ... see bal.tab() details. See special notes distance, s.d.denom, s.weights arguments. method character vector containing method adjustment. Ignored unless subclassification used original call matchit(). \"weighting\", subclassification weights used subclasses ignored. \"subclassification\", balance assessed using subclasses (see bal.tab.subclass details). Abbreviations allowed. following arguments special notes used matchit objects: distance distance measure (e.g., propensity score) generated matchit() automatically included named \"distance\". s.d.denom specified, bal.tab() figure one best based estimand matchit object: ATT, \"treated\"; ATC, \"control\", otherwise \"pooled\". s.weights s.weights supplied call matchit(), automatically included need specified (though harm ).","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.matchit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Balance Statistics for MatchIt Objects — bal.tab.matchit","text":"bal.tab.matchit() generates list balance summaries matchit object given, functions similarly MatchIt::summary.matchit(). bal.tab() behaves differently depending whether subclasses used conditioning . used, bal.tab() creates balance statistics subclass sample aggregate; see bal.tab.subclass information.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.matchit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Balance Statistics for MatchIt Objects — bal.tab.matchit","text":"subclassification used method set \"subclassification\", object class \"bal.tab.subclass\" containing balance summaries within across subclasses. See bal.tab.subclass details. matching used clusters specified, object class \"bal.tab\" containing balance summaries matchit object. See bal.tab() details. clusters specified, object class \"bal.tab.cluster\" containing balance summaries within cluster summary balance across clusters. See bal.tab.cluster details.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.matchit.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Balance Statistics for MatchIt Objects — bal.tab.matchit","text":"Noah Greifer","code":""},{"path":[]},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.matchit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Balance Statistics for MatchIt Objects — bal.tab.matchit","text":"","code":"library(MatchIt); data(\"lalonde\", package = \"cobalt\")  ## Nearest Neighbor matching m.out1 <- matchit(treat ~ age + educ + race +                    married + nodegree + re74 + re75,                    data = lalonde, method = \"nearest\")                    bal.tab(m.out1, un = TRUE, m.threshold = .1,          v.threshold = 2) #> Balance Measures #>                 Type Diff.Un V.Ratio.Un Diff.Adj        M.Threshold V.Ratio.Adj #> distance    Distance  1.7941     0.9211   0.9739                         0.7566 #> age          Contin. -0.3094     0.4400   0.0718     Balanced, <0.1      0.4568 #> educ         Contin.  0.0550     0.4959  -0.1290 Not Balanced, >0.1      0.5721 #> race_black    Binary  0.6404          .   0.3730 Not Balanced, >0.1           . #> race_hispan   Binary -0.0827          .  -0.1568 Not Balanced, >0.1           . #> race_white    Binary -0.5577          .  -0.2162 Not Balanced, >0.1           . #> married       Binary -0.3236          .  -0.0216     Balanced, <0.1           . #> nodegree      Binary  0.1114          .   0.0703     Balanced, <0.1           . #> re74         Contin. -0.7211     0.5181  -0.0505     Balanced, <0.1      1.3289 #> re75         Contin. -0.2903     0.9563  -0.0257     Balanced, <0.1      1.4956 #>                  V.Threshold #> distance        Balanced, <2 #> age         Not Balanced, >2 #> educ            Balanced, <2 #> race_black                   #> race_hispan                  #> race_white                   #> married                      #> nodegree                     #> re74            Balanced, <2 #> re75            Balanced, <2 #>  #> Balance tally for mean differences #>                    count #> Balanced, <0.1         5 #> Not Balanced, >0.1     4 #>  #> Variable with the greatest mean difference #>    Variable Diff.Adj        M.Threshold #>  race_black    0.373 Not Balanced, >0.1 #>  #> Balance tally for variance ratios #>                  count #> Balanced, <2         4 #> Not Balanced, >2     1 #>  #> Variable with the greatest variance ratio #>  Variable V.Ratio.Adj      V.Threshold #>       age      0.4568 Not Balanced, >2 #>  #> Sample sizes #>           Control Treated #> All           429     185 #> Matched       185     185 #> Unmatched     244       0  ## Subclassification m.out2 <- matchit(treat ~ age + educ + race +                    married + nodegree + re74 + re75,                    data = lalonde, method = \"subclass\")                    bal.tab(m.out2, disp.subclass = TRUE) #> Balance by subclass #>  - - - Subclass 1 - - -  #>                 Type Diff.Adj #> distance    Distance   0.2785 #> age          Contin.  -0.4024 #> educ         Contin.   0.1142 #> race_black    Binary   0.0823 #> race_hispan   Binary   0.1492 #> race_white    Binary  -0.2315 #> married       Binary  -0.2877 #> nodegree      Binary  -0.0003 #> re74         Contin.  -0.5864 #> re75         Contin.  -0.1729 #>  #>  - - - Subclass 2 - - -  #>                 Type Diff.Adj #> distance    Distance   0.1873 #> age          Contin.  -0.7473 #> educ         Contin.   0.1183 #> race_black    Binary   0.0094 #> race_hispan   Binary  -0.0094 #> race_white    Binary   0.0000 #> married       Binary  -0.2473 #> nodegree      Binary  -0.0121 #> re74         Contin.  -0.0352 #> re75         Contin.  -0.0970 #>  #>  - - - Subclass 3 - - -  #>                 Type Diff.Adj #> distance    Distance  -0.0140 #> age          Contin.   0.0524 #> educ         Contin.   0.1372 #> race_black    Binary   0.0000 #> race_hispan   Binary   0.0000 #> race_white    Binary   0.0000 #> married       Binary   0.3550 #> nodegree      Binary   0.2191 #> re74         Contin.  -0.2669 #> re75         Contin.  -0.0970 #>  #>  - - - Subclass 4 - - -  #>                 Type Diff.Adj #> distance    Distance  -0.0003 #> age          Contin.  -0.0499 #> educ         Contin.  -0.1436 #> race_black    Binary   0.0000 #> race_hispan   Binary   0.0000 #> race_white    Binary   0.0000 #> married       Binary  -0.1116 #> nodegree      Binary  -0.0417 #> re74         Contin.  -0.0073 #> re75         Contin.  -0.0801 #>  #>  - - - Subclass 5 - - -  #>                 Type Diff.Adj #> distance    Distance  -0.0224 #> age          Contin.   0.2640 #> educ         Contin.  -0.2977 #> race_black    Binary   0.0000 #> race_hispan   Binary   0.0000 #> race_white    Binary   0.0000 #> married       Binary   0.0000 #> nodegree      Binary   0.0376 #> re74         Contin.   0.0190 #> re75         Contin.   0.1233 #>  #>  - - - Subclass 6 - - -  #>                 Type Diff.Adj #> distance    Distance   0.0143 #> age          Contin.   0.5245 #> educ         Contin.   0.2781 #> race_black    Binary   0.0000 #> race_hispan   Binary   0.0000 #> race_white    Binary   0.0000 #> married       Binary   0.0000 #> nodegree      Binary  -0.1290 #> re74         Contin.  -0.0152 #> re75         Contin.  -0.2407 #>"},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.mimids.html","id":null,"dir":"Reference","previous_headings":"","what":"Balance Statistics for MatchThem Objects — bal.tab.mimids","title":"Balance Statistics for MatchThem Objects — bal.tab.mimids","text":"Generates balance statistics mimids wimids objects MatchThem.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.mimids.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Balance Statistics for MatchThem Objects — bal.tab.mimids","text":"","code":"# S3 method for mimids bal.tab(x,          stats,         int = FALSE,         poly = 1,         distance = NULL,         addl = NULL,         data = NULL,         continuous,         binary,         s.d.denom,         thresholds = NULL,         weights = NULL,         cluster = NULL,         pairwise = TRUE,         s.weights = NULL,         abs = FALSE,         subset = NULL,         quick = TRUE,         ...)"},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.mimids.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Balance Statistics for MatchThem Objects — bal.tab.mimids","text":"x mimids wimids object; output call MatchThem::matchthem() MatchThem::weightthem(). stats, int, poly, addl, data, continuous, binary, thresholds, weights, cluster, pairwise, s.weights, abs, subset, quick, ... see bal.tab() details. See special notes distance, s.d.denom, imp arguments. Note imp argument ignored imputation identifers already present input object. following arguments special notes used mimids wimids objects: distance distance measure generated matchthem() weightthem() automatically included named \"distance\" \"prop.score\", respectively. s.d.denom defaults depend options specified original function calls; see bal.tab.matchit() bal.tab.weightit() details defaults.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.mimids.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Balance Statistics for MatchThem Objects — bal.tab.mimids","text":"bal.tab.mimids() bal.tab.wimids() generate list balance summaries mimids wimids object given.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.mimids.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Balance Statistics for MatchThem Objects — bal.tab.mimids","text":"clusters specified, object class \"bal.tab.imp\" containing balance summaries imputation summary balance across imputations. See bal.tab.imp details. clusters specified, object class \"bal.tab.imp.cluster\" containing summaries across clusters imputations.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.mimids.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Balance Statistics for MatchThem Objects — bal.tab.mimids","text":"Noah Greifer","code":""},{"path":[]},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.mimids.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Balance Statistics for MatchThem Objects — bal.tab.mimids","text":"","code":"library(mice) #>  #> Attaching package: ‘mice’ #> The following object is masked from ‘package:stats’: #>  #>     filter #> The following objects are masked from ‘package:base’: #>  #>     cbind, rbind library(MatchThem) #>  #> Attaching package: ‘MatchThem’ #> The following objects are masked from ‘package:mice’: #>  #>     cbind, pool #> The following object is masked from ‘package:base’: #>  #>     cbind  data(\"lalonde_mis\", package = \"cobalt\")  #Imputing the missing data imp <- mice(lalonde_mis, m = 5) #>  #>  iter imp variable #>   1   1  married  re74  re75 #>   1   2  married  re74  re75 #>   1   3  married  re74  re75 #>   1   4  married  re74  re75 #>   1   5  married  re74  re75 #>   2   1  married  re74  re75 #>   2   2  married  re74  re75 #>   2   3  married  re74  re75 #>   2   4  married  re74  re75 #>   2   5  married  re74  re75 #>   3   1  married  re74  re75 #>   3   2  married  re74  re75 #>   3   3  married  re74  re75 #>   3   4  married  re74  re75 #>   3   5  married  re74  re75 #>   4   1  married  re74  re75 #>   4   2  married  re74  re75 #>   4   3  married  re74  re75 #>   4   4  married  re74  re75 #>   4   5  married  re74  re75 #>   5   1  married  re74  re75 #>   5   2  married  re74  re75 #>   5   3  married  re74  re75 #>   5   4  married  re74  re75 #>   5   5  married  re74  re75  #Matching using within-imputation propensity scores mt.out1 <- matchthem(treat ~ age + educ + race +                         married + nodegree + re74 + re75,                         data = imp, approach = \"within\") #>  #> Matching Observations  | dataset: #1 #>  #2 #>  #3 #>  #4 #>  #5 #>  bal.tab(mt.out1) #> Balance summary across all imputations #>                 Type Min.Diff.Adj Mean.Diff.Adj Max.Diff.Adj #> distance    Distance       0.9692        0.9735       0.9755 #> age          Contin.      -0.0076        0.0236       0.0514 #> educ         Contin.      -0.1344       -0.0995      -0.0672 #> race_black    Binary       0.3730        0.3730       0.3730 #> race_hispan   Binary      -0.1676       -0.1611      -0.1514 #> race_white    Binary      -0.2216       -0.2119      -0.2054 #> married       Binary      -0.0162       -0.0076       0.0000 #> nodegree      Binary       0.0432        0.0573       0.0757 #> re74         Contin.      -0.0970       -0.0731      -0.0349 #> re75         Contin.      -0.0747       -0.0521      -0.0333 #>  #> Average sample sizes across imputations #>             0   1 #> All       429 185 #> Matched   185 185 #> Unmatched 244   0  #Matching using across-imputation average propensity scores mt.out2 <- matchthem(treat ~ age + educ + race +                         married + nodegree + re74 + re75,                         data = imp, approach = \"across\") #> Estimating distances   | dataset: #1 #>  #2 #>  #3 #>  #4 #>  #5 #>  #> Matching Observations  | dataset: #1 #>  #2 #>  #3 #>  #4 #>  #5 #>                          bal.tab(mt.out2) #> Balance summary across all imputations #>                 Type Min.Diff.Adj Mean.Diff.Adj Max.Diff.Adj #> distance    Distance       0.9769        0.9769       0.9769 #> age          Contin.       0.0249        0.0249       0.0249 #> educ         Contin.      -0.1022       -0.1022      -0.1022 #> race_black    Binary       0.3730        0.3730       0.3730 #> race_hispan   Binary      -0.1622       -0.1622      -0.1622 #> race_white    Binary      -0.2108       -0.2108      -0.2108 #> married       Binary      -0.0054       -0.0022       0.0054 #> nodegree      Binary       0.0703        0.0703       0.0703 #> re74         Contin.      -0.1006       -0.0576      -0.0370 #> re75         Contin.      -0.0569       -0.0311      -0.0088 #>  #> Average sample sizes across imputations #>             0   1 #> All       429 185 #> Matched   185 185 #> Unmatched 244   0  #Weighting using within-imputation propensity scores wt.out <- weightthem(treat ~ age + educ + race +                         married + nodegree + re74 + re75,                         data = imp, approach = \"within\",                        estimand = \"ATT\") #> Estimating weights     | dataset: #1 #>  #2 #>  #3 #>  #4 #>  #5 #>                          bal.tab(wt.out) #> Balance summary across all imputations #>                 Type Min.Diff.Adj Mean.Diff.Adj Max.Diff.Adj #> prop.score  Distance      -0.0316       -0.0223      -0.0150 #> age          Contin.       0.1066        0.1155       0.1304 #> educ         Contin.      -0.0450       -0.0370      -0.0306 #> race_black    Binary      -0.0030       -0.0022      -0.0013 #> race_hispan   Binary      -0.0001        0.0001       0.0004 #> race_white    Binary       0.0013        0.0020       0.0026 #> married       Binary       0.0145        0.0168       0.0201 #> nodegree      Binary       0.0185        0.0197       0.0232 #> re74         Contin.       0.0053        0.0101       0.0201 #> re75         Contin.      -0.0016        0.0050       0.0108 #>  #> Average effective sample sizes across imputations #>                0   1 #> Unadjusted 429.  185 #> Adjusted   100.4 185"},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.ps.html","id":null,"dir":"Reference","previous_headings":"","what":"Balance Statistics for twang Objects — bal.tab.ps","title":"Balance Statistics for twang Objects — bal.tab.ps","text":"Generates balance statistics ps, mnps, iptw objects twang ps.cont objects twangContinuous.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.ps.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Balance Statistics for twang Objects — bal.tab.ps","text":"","code":"# S3 method for ps bal.tab(x,          stop.method,         stats,         int = FALSE,         poly = 1,         distance = NULL,         addl = NULL,         data = NULL,         continuous,         binary,         s.d.denom,         thresholds = NULL,         weights = NULL,         cluster = NULL,         imp = NULL,         pairwise = TRUE,         s.weights = NULL,         abs = FALSE,         subset = NULL,         quick = TRUE,         ...)"},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.ps.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Balance Statistics for twang Objects — bal.tab.ps","text":"x ps, mnps, iptw, ps.cont object; output call twang::ps(), twang::mnps(), twang::iptw() twangContinuous::ps.cont(). stop.method string containing names stopping methods used original call ps(), mnps(), iptw(). Examples include \"es.max\" \"ks.mean\" ps mnps objects. bal.tab assess balance weights created stopping methods. names can abbreviated long abbreviations specific enough. stopping methods provided, bal.tab default displaying balance available stopping methods. Ignored ps.cont objects. stats, int, poly, addl, data, continuous, binary, thresholds, weights, cluster, imp, pairwise, abs, subset, quick, ... see bal.tab() details. See special notes distance, s.d.denom, s.weights arguments. following arguments special notes used input objects: distance propensity scores generated ps() iptw() (mnps() ps.cont()) automatically included named \"prop.score.stop.method\". s.d.denom specified, ps objects, bal.tab() use \"treated\" estimand call ps() ATT \"pooled\" estimand ATE; mnps objects, bal.tab() use \"treated\" treatATT specified original call mnps \"pooled\" otherwise. Use \"\" get values computed bal.table twang. Abbreviations allowed. s.weights sampw supplied call ps(), mnps(), iptw(), ps.cont(), automatically supplied s.weights need specified (though harm ).","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.ps.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Balance Statistics for twang Objects — bal.tab.ps","text":"bal.tab.ps() generates list balance summaries input object given, functions similarly twang::bal.table().","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.ps.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Balance Statistics for twang Objects — bal.tab.ps","text":"binary continuous point treatments, clusters specified, object class \"bal.tab\" containing balance summaries ps object. See bal.tab() details. clusters specified, object class \"bal.tab.cluster\" containing balance summaries within cluster summary balance across clusters. See bal.tab.cluster details. mnps() used multi-category treatments, object class \"bal.tab.multi\" containing balance summaries pairwise treatment comparison summary balance across pairwise comparisons. See bal.tab.multi details.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.ps.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Balance Statistics for twang Objects — bal.tab.ps","text":"function twang::bal.table() twang performs similar function. variances used denominator standardized mean difference weighted computed using survey::svyvar() twang unweighted (except s.weights specified, case col_w_sd used). twang also uses \"\" default s.d.denom estimand ATE; default \"pooled\". reason, results may differ slightly two packages.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.ps.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Balance Statistics for twang Objects — bal.tab.ps","text":"Noah Greifer","code":""},{"path":[]},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.ps.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Balance Statistics for twang Objects — bal.tab.ps","text":"","code":"library(twang); data(\"lalonde\", package = \"cobalt\") #> To reproduce results from prior versions of the twang package, please see the version=\"legacy\" option described in the documentation.  ## Using ps() for generalized boosted modeling ps.out <- ps(treat ~ age + educ + married + race +              nodegree + re74 + re75, data = lalonde,               stop.method = c(\"ks.mean\", \"es.mean\"),               estimand = \"ATT\", verbose = FALSE)               bal.tab(ps.out, stop.method = \"ks.mean\", un = TRUE,          m.threshold = .1, disp.ks = TRUE) #> Balance Measures #>                 Type Diff.Un  KS.Un Diff.Adj        M.Threshold KS.Adj #> prop.score  Distance  2.8072 0.8294   0.5712                    0.2164 #> age          Contin. -0.3094 0.1577   0.0538     Balanced, <0.1 0.0980 #> educ         Contin.  0.0550 0.1114  -0.0810     Balanced, <0.1 0.0678 #> married       Binary -0.3236 0.3236   0.0029     Balanced, <0.1 0.0029 #> race_black    Binary  0.6404 0.6404   0.0176     Balanced, <0.1 0.0176 #> race_hispan   Binary -0.0827 0.0827   0.0014     Balanced, <0.1 0.0014 #> race_white    Binary -0.5577 0.5577  -0.0191     Balanced, <0.1 0.0191 #> nodegree      Binary  0.1114 0.1114   0.0637     Balanced, <0.1 0.0637 #> re74         Contin. -0.7211 0.4470   0.1060 Not Balanced, >0.1 0.0591 #> re75         Contin. -0.2903 0.2876   0.1217 Not Balanced, >0.1 0.0941 #>  #> Balance tally for mean differences #>                    count #> Balanced, <0.1         7 #> Not Balanced, >0.1     2 #>  #> Variable with the greatest mean difference #>  Variable Diff.Adj        M.Threshold #>      re75   0.1217 Not Balanced, >0.1 #>  #> Effective sample sizes #>            Control Treated #> Unadjusted   429.      185 #> Adjusted      25.5     185"},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.sbw.html","id":null,"dir":"Reference","previous_headings":"","what":"Balance Statistics for sbw Objects — bal.tab.sbwcau","title":"Balance Statistics for sbw Objects — bal.tab.sbwcau","text":"Generates balance statistics sbwcau objects sbw.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.sbw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Balance Statistics for sbw Objects — bal.tab.sbwcau","text":"","code":"# S3 method for sbwcau bal.tab(x,          stats,         int = FALSE,         poly = 1,         distance = NULL,         addl = NULL,         data = NULL,         continuous,         binary,         s.d.denom,         thresholds = NULL,         weights = NULL,         cluster = NULL,         imp = NULL,         pairwise = TRUE,         s.weights = NULL,         abs = FALSE,         subset = NULL,         quick = TRUE,         ...)"},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.sbw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Balance Statistics for sbw Objects — bal.tab.sbwcau","text":"x sbwcau object; output call sbw::sbw(). stats, int, poly, distance, addl, data, continuous, binary, thresholds, weights, cluster, imp, pairwise, s.weights, abs, subset, quick, ... see bal.tab() details. See special note s.d.denom argument. following argument special note used sbwcau objects: s.d.denom specified, bal.tab() figure one best based par component sbwcau object: \"att\", \"treated\"; \"atc\", \"control\"; otherwise \"pooled\".","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.sbw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Balance Statistics for sbw Objects — bal.tab.sbwcau","text":"bal.tab.sbwcau() generates list balance summaries sbwcau object given, functions similarly sbw::summarize().","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.sbw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Balance Statistics for sbw Objects — bal.tab.sbwcau","text":"clusters specified, object class \"bal.tab\" containing balance summaries sbwcau object. See bal.tab() details. clusters specified, object class \"bal.tab.cluster\" containing balance summaries within cluster summary balance across clusters. See bal.tab.cluster details.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.sbw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Balance Statistics for sbw Objects — bal.tab.sbwcau","text":"Noah Greifer","code":""},{"path":[]},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.sbw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Balance Statistics for sbw Objects — bal.tab.sbwcau","text":"","code":"library(sbw); data(\"lalonde\", package = \"cobalt\") #> Loading required package: quadprog  ## Stable balancing weights for the ATT sbw.out <- sbw(splitfactor(lalonde, drop.first = \"if2\"),                ind = \"treat\",                bal = list(bal_cov = c(\"age\", \"educ\", \"race_black\",                                        \"race_hispan\", \"race_white\",                                        \"married\", \"nodegree\",                                        \"re74\", \"re75\"),                           bal_alg = FALSE,                            bal_tol = .001),                par = list(par_est = \"att\")) #>   quadprog optimizer is opening...  #>   Finding the optimal weights...  #>   Optimal weights found.                  bal.tab(sbw.out, un = TRUE, poly = 2) #> Balance Measures #>                Type Diff.Un Diff.Adj #> age         Contin. -0.3094   0.0015 #> educ        Contin.  0.0550   0.0014 #> race_black   Binary  0.6404   0.0004 #> race_hispan  Binary -0.0827   0.0001 #> race_white   Binary -0.5577  -0.0005 #> married      Binary -0.3236  -0.0005 #> nodegree     Binary  0.1114   0.0005 #> re74        Contin. -0.7211  -0.0014 #> re75        Contin. -0.2903   0.0010 #> age²        Contin. -0.4276  -0.1698 #> educ²       Contin. -0.0468  -0.0674 #> re74²       Contin. -0.4331   0.0510 #> re75²       Contin. -0.0757   0.0483 #>  #> Effective sample sizes #>            Control Treated #> Unadjusted  429.       185 #> Adjusted    108.99     185"},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.weightit.html","id":null,"dir":"Reference","previous_headings":"","what":"Balance Statistics for WeightIt Objects — bal.tab.weightit","title":"Balance Statistics for WeightIt Objects — bal.tab.weightit","text":"Generates balance statistics weightit weightitMSM objects WeightIt.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.weightit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Balance Statistics for WeightIt Objects — bal.tab.weightit","text":"","code":"# S3 method for weightit bal.tab(x,          stats,         int = FALSE,         poly = 1,         distance = NULL,         addl = NULL,         data = NULL,         continuous,         binary,         s.d.denom,         thresholds = NULL,         weights = NULL,         cluster = NULL,         imp = NULL,         pairwise = TRUE,         s.weights = NULL,         abs = FALSE,         subset = NULL,         quick = TRUE,         ...)"},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.weightit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Balance Statistics for WeightIt Objects — bal.tab.weightit","text":"x weightit weightitMSM object; output call WeightIt::weightit() WeightIt::weightitMSM(). stats, int, poly, addl, data, continuous, binary, thresholds, weights, cluster, imp, pairwise, abs, subset, quick, ... see bal.tab() details. See special notes distance, s.d.denom, s.weights arguments. following arguments special notes used weightit weightitMSM objects: distance propensity scores generated weightit() weightitMSM() automatically included named \"prop.score\". s.d.denom specified, bal.tab() figure one best based estimand weightit object: ATT, \"treated\"; ATC, \"control\"; otherwise \"pooled\". Abbreviations allowed. s.weights s.weights supplied call weightit() weightitMSM(), automatically included need specified (though harm ).","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.weightit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Balance Statistics for WeightIt Objects — bal.tab.weightit","text":"bal.tab.weightit() generates list balance summaries weightit object given.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.weightit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Balance Statistics for WeightIt Objects — bal.tab.weightit","text":"point treatments, clusters imputations specified, object class \"bal.tab\" containing balance summaries weightit object. See bal.tab() details. imputations specified, object class \"bal.tab.imp\" containing balance summaries imputation summary balance across imputations. See bal.tab.imp details. weightit() used multi-category treatments, object class \"bal.tab.multi\" containing balance summaries pairwise treatment comparison. See bal.tab.multi details. weightitMSM() used longitudinal treatments, object class \"bal.tab.msm\" containing balance summaries time period. See bal.tab.msm details. clusters specified, object class \"bal.tab.cluster\" containing balance summaries within cluster summary balance across clusters. See bal.tab.cluster details.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.weightit.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Balance Statistics for WeightIt Objects — bal.tab.weightit","text":"Noah Greifer","code":""},{"path":[]},{"path":"https://ngreifer.github.io/cobalt/reference/bal.tab.weightit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Balance Statistics for WeightIt Objects — bal.tab.weightit","text":"","code":"library(WeightIt) data(\"lalonde\", package = \"cobalt\")  ## Basic propensity score weighting w.out1 <- weightit(treat ~ age + educ + race +                       married + nodegree + re74 + re75,                     data = lalonde, method = \"ps\") bal.tab(w.out1, un = TRUE, m.threshold = .1,          v.threshold = 2) #> Balance Measures #>                 Type Diff.Un V.Ratio.Un Diff.Adj        M.Threshold V.Ratio.Adj #> prop.score  Distance  1.7569     0.9211   0.1360                         0.9758 #> age          Contin. -0.2419     0.4400  -0.1676 Not Balanced, >0.1      0.3689 #> educ         Contin.  0.0448     0.4959   0.1296 Not Balanced, >0.1      0.5657 #> race_black    Binary  0.6404          .   0.0499     Balanced, <0.1           . #> race_hispan   Binary -0.0827          .   0.0047     Balanced, <0.1           . #> race_white    Binary -0.5577          .  -0.0546     Balanced, <0.1           . #> married       Binary -0.3236          .  -0.0944     Balanced, <0.1           . #> nodegree      Binary  0.1114          .  -0.0547     Balanced, <0.1           . #> re74         Contin. -0.5958     0.5181  -0.2740 Not Balanced, >0.1      0.8208 #> re75         Contin. -0.2870     0.9563  -0.1579 Not Balanced, >0.1      0.9562 #>                  V.Threshold #> prop.score      Balanced, <2 #> age         Not Balanced, >2 #> educ            Balanced, <2 #> race_black                   #> race_hispan                  #> race_white                   #> married                      #> nodegree                     #> re74            Balanced, <2 #> re75            Balanced, <2 #>  #> Balance tally for mean differences #>                    count #> Balanced, <0.1         5 #> Not Balanced, >0.1     4 #>  #> Variable with the greatest mean difference #>  Variable Diff.Adj        M.Threshold #>      re74   -0.274 Not Balanced, >0.1 #>  #> Balance tally for variance ratios #>                  count #> Balanced, <2         4 #> Not Balanced, >2     1 #>  #> Variable with the greatest variance ratio #>  Variable V.Ratio.Adj      V.Threshold #>       age      0.3689 Not Balanced, >2 #>  #> Effective sample sizes #>            Control Treated #> Unadjusted  429.    185.   #> Adjusted    329.01   58.33  ## Weighting with a multi-category treatment w.out2 <- weightit(race ~ age + educ + married +                       nodegree + re74 + re75,                     data = lalonde, method = \"ps\",                    estimand = \"ATE\", use.mlogit = FALSE) bal.tab(w.out2, un = TRUE) #> Balance summary across all treatment pairs #>             Type Max.Diff.Un Max.Diff.Adj #> age      Contin.      0.3065       0.0504 #> educ     Contin.      0.5861       0.1046 #> married   Binary      0.3430       0.0355 #> nodegree  Binary      0.2187       0.0438 #> re74     Contin.      0.6196       0.1445 #> re75     Contin.      0.3442       0.1462 #>  #> Effective sample sizes #>            black hispan  white #> Unadjusted 243.   72.   299.   #> Adjusted   140.5  54.32 259.28 bal.tab(w.out2, un = TRUE, pairwise = FALSE) #> Balance summary across all treatment pairs #>             Type Max.Diff.Un Max.Diff.Adj #> age      Contin.      0.1532       0.0777 #> educ     Contin.      0.4641       0.0847 #> married   Binary      0.1931       0.0372 #> nodegree  Binary      0.1336       0.0305 #> re74     Contin.      0.3390       0.1466 #> re75     Contin.      0.1744       0.1434 #>  #> Effective sample sizes #>            black hispan  white #> Unadjusted 243.   72.   299.   #> Adjusted   140.5  54.32 259.28  ## IPW for longitudinal treatments data(\"iptwExWide\", package = \"twang\") wmsm.out <- weightitMSM(list(tx1 ~ use0 + gender,                              tx2 ~ use0 + gender + use1 + tx1,                              tx3 ~ use0 + gender + use1 + tx1 + use2 + tx2),                         data = iptwExWide,                         stabilize = TRUE) bal.tab(wmsm.out) #> Balance summary across all time points #>              Times     Type Max.Diff.Adj #> prop.score 1, 2, 3 Distance       0.3978 #> use0       1, 2, 3  Contin.       0.0672 #> gender     1, 2, 3   Binary       0.0102 #> use1          2, 3  Contin.       0.0286 #> tx1           2, 3   Binary       0.1602 #> use2             3  Contin.       0.0709 #> tx2              3   Binary       0.2345 #>  #> Effective sample sizes #>  - Time 1 #>            Control Treated #> Unadjusted  294.    706.   #> Adjusted    223.43  644.59 #>  - Time 2 #>            Control Treated #> Unadjusted  492.    508.   #> Adjusted    417.01  446.82 #>  - Time 3 #>            Control Treated #> Unadjusted  415.    585.   #> Adjusted    350.64  513.25"},{"path":"https://ngreifer.github.io/cobalt/reference/balance.stats.html","id":null,"dir":"Reference","previous_headings":"","what":"Balance Statistics in bal.tab and love.plot — Balance Statistics","title":"Balance Statistics in bal.tab and love.plot — Balance Statistics","text":"bal.tab() love.plot() display balance statistics included covariates. stats argument functions controls balance statistics displayed. argument stats character vector names desired balance statistics. page describes available balance statistics request . Abbreviations allowed, can use first letters balance statistics request instead typing whole name. convention used throughout documentation. example, request mean differences variance ratios bal.tab() love.plot(), include stats = c(\"m\", \"v\"). addition, thresholds argument uses naming conventions can used request balance thresholds statistic. example, request balance threshold .1 mean differences, include thresholds = c(m = .1). , allowable entry stats thresholds described, along details option accompany . statistic requested thresholds, automatically placed stats. example, bal.tab(..., stats = \"m\", thresholds = c(v = 2)) display mean differences variance ratios, variance ratios balance threshold set 2.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/balance.stats.html","id":"binary-multi-category-treatments","dir":"Reference","previous_headings":"","what":"Binary/Multi-Category Treatments","title":"Balance Statistics in bal.tab and love.plot — Balance Statistics","text":"\"mean.diffs\" Mean differences computed col_w_smd(). Can abbreviated \"m\". Setting arguments continuous binary either \"std\" \"raw\" determine whether standardized mean differences raw mean differences calculated continuous categorical variables, respectively. standardized mean differences requested, s.d.denom argument controls standardization occurs. abs = TRUE, negative values become positive. Mean differences requested default entry stats provided. \"variance.ratios\" Variance ratios computed col_w_vr(). Can abbreviated \"v\". computed binary variables. abs = TRUE, values less 1 inverse taken. used love.plot, x-axis scaled logged , e.g., .5 far away 1 2 . \"ks.statistics\" Kolmogorov-Smirnov (KS) statistics computed col_w_ks(). \"ovl.coefficients\" Overlapping (OVL) statistics computed col_w_ovl(). Can abbreviated \"ovl\". Additional arguments passed col_w_ovl(), integrate bw, can supplied bal.tab() love.plot().","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/balance.stats.html","id":"continuous-treatments","dir":"Reference","previous_headings":"","what":"Continuous Treatments","title":"Balance Statistics in bal.tab and love.plot — Balance Statistics","text":"\"correlations\" Pearson correlations computed col_w_cov(). Can abbreviated \"cor\". Setting arguments continuous binary either \"std\" \"raw\" determine whether correlations covariances calculated continuous categorical variables, respectively (\"std\" default). correlations requested, s.d.denom argument controls standardization occurs. abs = TRUE, negative values become positive. Pearson correlations requested default entry stats provided. \"spearman.correlations\" Spearman correlations computed col_w_cov(). Can abbreviated \"sp\". arguments \"correlations\". abs = TRUE, negative values become positive. \"mean.diffs.target\" Mean differences computed weighted unweighted sample ensure weighted sample representative original population. Can abbreviated \"m\". Setting arguments continuous binary either \"std\" \"raw\" determine whether standardized mean differences raw mean differences calculated continuous categorical variables, respectively. standardization factor computed unweighted sample. abs = TRUE, negative values become positive. statistic computed adjusted samples. \"ks.statistics.target\" KS-statistics computed weighted unweighted sample ensure weighted sample representative original population. Can abbreviated \"ks\". statistic computed adjusted samples.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/balance.stats.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Balance Statistics in bal.tab and love.plot — Balance Statistics","text":"","code":"data(lalonde)  #Binary treatments bal.tab(treat ~ age + educ + married + re74, data = lalonde,         stats = c(\"m\", \"v\", \"ks\")) #> Error: The given response variable, \"treat\", is not a variable in 'data' or the global environment. love.plot(treat ~ age + educ + married + re74, data = lalonde,           stats = c(\"m\", \"v\", \"ks\"), binary = \"std\",           thresholds = c(m = .1, v = 2)) #> Error: The given response variable, \"treat\", is not a variable in 'data' or the global environment.  #Continuous treatments bal.tab(re75 ~ age + educ + married + re74, data = lalonde,         stats = c(\"cor\", \"sp\")) #> Error: object 'educ' not found love.plot(re75 ~ age + educ + married + re74, data = lalonde,           thresholds = c(cor = .1, sp = .1)) #> Error: object 'educ' not found"},{"path":"https://ngreifer.github.io/cobalt/reference/balance.summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Balance Statistics for Covariates — Balance Summary","title":"Compute Balance Statistics for Covariates — Balance Summary","text":"functions quickly compute balance statistics given covariates. functions used bal.tab(), available use programming without call bal.tab() get . col_w_mean computes (weighted) means set covariates weights essentially weighted version colMeans. col_w_sd computes (weighted) standard deviations set covariates weights. col_w_smd computes (weighted) (absolute) (standardized) difference means set covariates, binary treatment, weights. col_w_vr computes (weighted) variance ratio set covariates, binary treatment, weights. col_w_ks computes (weighted) Kolmogorov-Smirnov (KS) statistic set covariates, binary treatment, weights. col_w_ovl computes complement (weighted) overlapping coefficient set covariates, binary treatment, weights (based Franklin et al, 2014). col_w_cov col_w_corr compute (weighted) (absolute) treatment-covariate covariance correlation set covariates, continuous treatment, weights.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/balance.summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Balance Statistics for Covariates — Balance Summary","text":"","code":"col_w_mean(mat, weights = NULL, s.weights = NULL,             subset = NULL, na.rm = TRUE, ...)             col_w_sd(mat, weights = NULL, s.weights = NULL,           bin.vars, subset = NULL, na.rm = TRUE, ...)           col_w_smd(mat, treat, weights = NULL, std = TRUE,            s.d.denom = \"pooled\", abs = FALSE,            s.weights = NULL, bin.vars,            subset = NULL, weighted.weights = weights,            na.rm = TRUE, ...)            col_w_vr(mat, treat, weights = NULL, abs = FALSE,           s.weights = NULL, bin.vars,           subset = NULL, na.rm = TRUE, ...)           col_w_ks(mat, treat, weights = NULL,           s.weights = NULL, bin.vars,           subset = NULL, na.rm = TRUE, ...)           col_w_ovl(mat, treat, weights = NULL,           s.weights = NULL, bin.vars,           integrate = FALSE, subset = NULL,           na.rm = TRUE, ...)           col_w_cov(mat, treat, weights = NULL, type = \"pearson\",           std = FALSE, s.d.denom = \"all\", abs = FALSE,            s.weights = NULL, bin.vars,            subset = NULL, weighted.weights = weights,            na.rm = TRUE, ...)             col_w_corr(mat, treat, weights = NULL, type = \"pearson\",            s.d.denom = \"all\", abs = FALSE,             s.weights = NULL, bin.vars,             subset = NULL, weighted.weights = weights,             na.rm = TRUE, ...)"},{"path":"https://ngreifer.github.io/cobalt/reference/balance.summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Balance Statistics for Covariates — Balance Summary","text":"mat numeric matrix data frame containing covariates statistic computed. data frame, splitfactor drop.first = \"if2\" called character factor variables present. can slow function, generally best supply numeric matrix. numeric vector supplied, converted 1-column matrix first. weights numeric; optional set weights used compute weighted statistics. sampling weights supplied s.weights, weights incorporate weights, weights s.weights multiplied together prior computing weighted statistics. s.weights numeric; optional set sampling weights used compute weighted statistics. weights supplied weights, weights s.weights multiplied together prior computing weighted statistics. functions use s.weights particular way; others, supplying weights s.weights equivalent supplying product either weights s.weights. See Details. subset logical vector length equal number rows mat used subset data. See Details notes use col_w_smd, col_w_cov, col_w_corr. na.rm logical; whether NAs ignored . FALSE, variable NAs corresponding statistic returned NA. TRUE, variable NAs corresponding statistic computed missing value . treat vector treatment status individual. col_w_smd, col_w_vr, col_w_ks, col_w_ovl, treat exactly two unique values. col_w_cov col_w_corr, treat many-valued numeric vector. std logical; col_w_smd, whether computed mean differences variable standardized; col_w_cov, whether treatment-covariate correlations computed (TRUE) rather covariances (FALSE). Can either length 1, whereby variables standardized , length equal number columns mat, whereby variables value TRUE standardized. See Details. s.d.denom col_w_smd col_w_cov std TRUE variables, col_w_corr, standardization factor computed. col_w_smd (.e., computing standardized mean differences), allowable options include \"treated\" - uses standard deviation variable treated group \"control\" - uses standard deviation variable control group \"pooled\" - uses square root average variances variable treated control groups \"\" - uses standard deviation variable full sample \"weighted\" - uses standard deviation variable full sample weighted weighted.weights \"hedges\" - uses small-sample corrected version Hedge's G described WWC Procedures Handbook (see References) name one treatment values - uses standard deviation variable treatment group. col_w_cov col_w_corr, \"\" \"weighted\" allowed. Abbreviations allowed. can also supplied numeric vector standard deviations length equal number columns mat; values used standardization factors. abs logical; col_w_smd, col_w_cov, col_w_corr, whether returned statistics absolute value (TRUE) . col_w_vr, whether ratio always include larger variance numerator, ratio always greater equal 1. Default FALSE. bin.vars vector used denote whether variable binary . Can logical vector length equal number columns mat vector numeric indices character names binary variables. missing (default), function figure covariates binary , can increase computation time. NULL, assumed variables binary. functions col_w_mean treat binary variables different continuous variables. factor character variable mat, dummies created automatically marked binary, still receive entry bin.vars supplied logical. weighted.weights col_w_smd, col_w_cov, col_w_corr, std = TRUE s.d.denom = \"weighted\", vector weights applied computation denominator standard deviation. specified, use argument weights. s.d.denom \"weighted\", ignored. main purpose allow weights NULL weighting denominator standard deviations assessing balance unweighted sample using standard deviations weighted sample. type col_w_cov col_w_corr, type covariance/correlation computed. Allowable options include \"pearson\" \"spearman\". \"spearman\" requested, covariates treatment first turned ranks using rank na.last = \"keep\". integrate logical; col_w_ovl, whether use integrate calculate area overlap. FALSE, midpoint Riemann sum 1000 partitions used instead. Riemann sum little slower slightly imprecise (unnoticibly contexts), integral can fail sometimes thus less stable. default use Riemann sum. ... functions, additional arguments supplied splitfactor mat data.frame. data, var.name, drop.first, drop.level ignored; drop.first automatically set \"if2\". col_w_ovl, arguments passed density besides x weights. Note default value bw unspecified \"nrd\" rather default density, \"nrd0\".","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/balance.summary.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute Balance Statistics for Covariates — Balance Summary","text":"col_w_mean computes column weighted means matrix variables. similar colMeans (optionally) incorporates weights. weights s.weights multiplied together prior used, distinction . used compute weighted means covariate general population examine degree weighting method left weighted samples resembling original population. col_w_sd computes column weighted standard deviations matrix variables. weights s.weights multiplied together prior used, distinction . variance binary variables computed \\(p(1-p)\\), \\(p\\) (weighted) proportion 1s, variance continuous variables computed using standard formula; standard deviation square root variance. col_w_smd computes mean difference covariate treatment groups defined treat. mean differences can optionally weighted, standardized, /absolute value. standardization factor computed using unweighted standard deviation variance s.weights absent, computed using s.weights-weighted standard deviation variance s.weights present, except s.d.denom = \"weighted\", case product weighted.weights s.weights (present) used weight standardization factor. standardization factor computed using whole sample even subset used. Note unlike bal.tab(), col_w_smd requires user specify whether individual variable standardized using std rather relying continuous binary. weighted mean difference computed using product weights s.weights, specified. variance binary variables computed \\(p(1-p)\\), \\(p\\) (weighted) proportion 1s, variance continuous variables computed using standard formula. col_w_vr computes variance ratio covariate treatment groups defined treat. abs = TRUE, pmax(, 1/) applied output ratio always greater equal 1. binary variables, variance computed \\(p(1-p)\\), \\(p\\) (weighted) proportion 1s, variance continuous variables computed using standard formula. Note bal.tab(), variance ratios computed binary variables, , (likely interpreted). weights s.weights multiplied together prior used, distinction . weighted variance computed, exactly balanced groups may variance ratios differ slightly 1. col_w_ks computes KS statistic covariate using method implemented twang. KS statistics can optionally weighted. binary variables, KS statistic just difference proportions. weights s.weights multiplied together prior used, distinction . col_w_ovl computes complement overlapping coefficient described Franklin et al. (2014). computing density covariate treated control groups, finding area density overlap, subtracting number 1, yielding value 0 1 1 indicates complete imbalance, 0 indicates perfect balance. density used model density group. bandwidth covariate smaller treatment group used groups. area overlap can computed using integrate, quickly accurately computes integral, using midpoint Riemann sum 1000 partitions, approximates area slowly. reason prefer Riemann sum integrate can fail unknown reasons, though Riemann sums fail extreme distributions. either method fails, resulting value NA. binary variables, complement overlapping coefficient just difference proportions. weights s.weights multiplied together prior used, distinction . weights used compute weighted density supplying weights argument density. col_w_cov computes covariance continuous treatment covariates assess balance continuous treatments recommended Austin (2019). covariance can optionally weighted absolute value can requested correlations (.e., standardized covariances). correlations computed covariance treatment covariate divided standardization factor, equal square root product variance treatment variance covariate. standardization factor computed using unweighted variances s.weights absent, computed using sampling weighted variances s.weights present, except s.d.denom = \"weighted\", case product weighted.weights s.weights (present) used weight standardization factor. reason, computed correlation can greater 1 less -1. standardization factor always computed using whole sample even subset used. covariance computed using product weights s.weights, specified. variance binary variables computed \\(p(1-p)\\), \\(p\\) (weighted) proportion 1s, variance continuous variables computed using standard formula. col_w_corr wrapper col_w_cov std set TRUE.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/balance.summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Balance Statistics for Covariates — Balance Summary","text":"vector balance statistics, one variable mat. mat column names, output named well.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/balance.summary.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute Balance Statistics for Covariates — Balance Summary","text":"Franklin, J. M., Rassen, J. ., Ackermann, D., Bartels, D. B., & Schneeweiss, S. (2014). Metrics covariate balance cohort studies causal effects. Statistics Medicine, 33(10), 1685–1699. doi:10.1002/sim.6058 Austin, P. C. (2019). Assessing covariate balance using generalized propensity score quantitative continuous exposures. Statistical Methods Medical Research, 28(5), 1365–1377. doi:10.1177/0962280218756159 Works Clearinghouse. (2020). WWC Procedures Handbook (Version 4.1). Retrieved https://ies.ed.gov/ncee/wwc/Handbooks","code":""},{"path":[]},{"path":"https://ngreifer.github.io/cobalt/reference/balance.summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute Balance Statistics for Covariates — Balance Summary","text":"","code":"library(WeightIt); data(\"lalonde\", package = \"cobalt\")  treat <- lalonde$treat covs <- subset(lalonde, select = -c(treat, re78)) covs <- splitfactor(covs, drop.first = \"if2\") bin.vars <- c(FALSE, FALSE, TRUE, TRUE, TRUE,               TRUE, TRUE, FALSE, FALSE) W <- weightit(treat ~ covs, method = \"ps\",                estimand = \"ATE\") weights <- W$weights  round(data.frame(     m0 = col_w_mean(covs, weights = weights, subset = treat == 0),     sd0 = col_w_sd(covs, weights = weights,                    bin.vars = bin.vars, subset = treat == 0),     m1 = col_w_mean(covs, weights = weights, subset = treat == 1),     sd1 = col_w_sd(covs, weights = weights,                    bin.vars = bin.vars, subset = treat == 1),     smd = col_w_smd(covs, treat = treat, weights = weights,                      std = TRUE, bin.vars = bin.vars),     vr = col_w_vr(covs, treat = treat, weights = weights,                   bin.vars = bin.vars),     ks = col_w_ks(covs, treat = treat, weights = weights,                   bin.vars = bin.vars),     row.names = colnames(covs) ), 4) #>                    m0       sd0        m1       sd1     smd     vr     ks #> age           27.1000   10.8071   25.5663    6.5640 -0.1676 0.3689 0.1912 #> educ          10.2863    2.7430   10.6064    2.0631  0.1296 0.5657 0.0768 #> race_black     0.3979    0.4895    0.4478    0.4973  0.1302 1.0322 0.0499 #> race_hispan    0.1170    0.3215    0.1217    0.3269  0.0156 1.0344 0.0047 #> race_white     0.4851    0.4998    0.4305    0.4951 -0.1378 0.9815 0.0546 #> married        0.4089    0.4916    0.3146    0.4643 -0.2102 0.8920 0.0944 #> nodegree       0.6250    0.4841    0.5702    0.4950 -0.1157 1.0456 0.0547 #> re74        4552.7364 6339.3397 2932.1845 5743.4197 -0.2740 0.8208 0.3121 #> re75        2172.0386 3161.2645 1658.0651 3091.1829 -0.1579 0.9562 0.1526  # Compare to bal.tab(): bal.tab(covs, treat, weights = weights, disp = c(\"m\", \"sd\"),          stats = c(\"m\", \"v\", \"ks\"), estimand = \"ATE\",          method = \"weighting\", binary = \"std\") #> Balance Measures #>                Type   M.0.Adj  SD.0.Adj   M.1.Adj  SD.1.Adj Diff.Adj #> age         Contin.   27.1000   10.8071   25.5663    6.5640  -0.1676 #> educ        Contin.   10.2863    2.7430   10.6064    2.0631   0.1296 #> race_black   Binary    0.3979    0.4895    0.4478    0.4973   0.1302 #> race_hispan  Binary    0.1170    0.3215    0.1217    0.3269   0.0156 #> race_white   Binary    0.4851    0.4998    0.4305    0.4951  -0.1378 #> married      Binary    0.4089    0.4916    0.3146    0.4643  -0.2102 #> nodegree     Binary    0.6250    0.4841    0.5702    0.4950  -0.1157 #> re74        Contin. 4552.7364 6339.3397 2932.1845 5743.4197  -0.2740 #> re75        Contin. 2172.0386 3161.2645 1658.0651 3091.1829  -0.1579 #>             V.Ratio.Adj KS.Adj #> age              0.3689 0.1912 #> educ             0.5657 0.0768 #> race_black            . 0.0499 #> race_hispan           . 0.0047 #> race_white            . 0.0546 #> married               . 0.0944 #> nodegree              . 0.0547 #> re74             0.8208 0.3121 #> re75             0.9562 0.1526 #>  #> Effective sample sizes #>            Control Treated #> Unadjusted  429.    185.   #> Adjusted    329.01   58.33"},{"path":"https://ngreifer.github.io/cobalt/reference/class-bal.tab.cluster.html","id":null,"dir":"Reference","previous_headings":"","what":"Using bal.tab() with Clustered Data — class-bal.tab.cluster","title":"Using bal.tab() with Clustered Data — class-bal.tab.cluster","text":"using bal.tab() clustered data, output different case single-level data, options common across bal.tab() methods. page outlines outputs options case. two main components output bal.tab() clustered data: within-cluster balance summaries across-cluster balance summary. within-cluster balance summaries display balance units within cluster separately. across-cluster balance summary pools information across within-cluster balance summaries simplify balance assessment. provides combination (e.g., mean maximum) balance statistic covariate across clusters. allows see bad worst imbalance balance looks like average. balance summary computed longitudinal treatments, multi-category treatments, multiply imputed data used.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/class-bal.tab.cluster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Using bal.tab() with Clustered Data — class-bal.tab.cluster","text":"four arguments bal.tab() method can handle clustered data: cluster, .cluster, cluster.summary, cluster.fun. cluster vector cluster membership. can factor, character, numeric vector. argument required let bal.tab() know data clustered. data argument specified, can also name variable data contains cluster membership. .cluster display option affect computation. .(default), clusters cluster displayed. .none, clusters displayed. Otherwise, can vector cluster names numerical indices display balance. Indices correspond alphabetical order cluster names (order cluster levels factor). cluster.summary display option affect computation. TRUE, balance summary across clusters displayed. default TRUE, .cluster .none, automatically set TRUE. cluster.fun display option affect computation. Can \"min\", \"mean\", \"max\" corresponds function used across-cluster summary combine results across clusters. example, cluster.fun = \"mean\" mean balance statistic across clusters displayed. default abs = FALSE bal.tab() call display three. default abs = FALSE bal.tab() call display just mean max balance statistic.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/class-bal.tab.cluster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Using bal.tab() with Clustered Data — class-bal.tab.cluster","text":"output bal.tab.cluster object, inherits bal.tab. following elements: Cluster.Balance cluster, regular bal.tab object containing balance table, sample size summary, balance assessment tools, depending options specified. Cluster.Summary balance summary across clusters. include combination balance statistic covariate across clusters according value cluster.fun. Observations table sample sizes effective sample sizes cluster adjustment. methods, multiple weights can specified, values weights appear tables.","code":""},{"path":[]},{"path":"https://ngreifer.github.io/cobalt/reference/class-bal.tab.imp.html","id":null,"dir":"Reference","previous_headings":"","what":"Using bal.tab() with Multiply Imputed Data — class-bal.tab.imp","title":"Using bal.tab() with Multiply Imputed Data — class-bal.tab.imp","text":"using bal.tab() multiply imputed data, output different case single data set. Multiply imputed data can used bal.tab() methods, mimids wimids methods MatchThem objects automatically incorporate multiply imputed data. page outlines outputs options available multiply imputed data. two main components output bal.tab() multiply imputed data: within-imputation balance summaries across-imputation balance summary. within-imputation balance summaries display balance units within imputed data set separately. general, useful interest rarely lies qualities individual imputed data set. across-imputation balance summary pools information across within-imputation balance summaries simplify balance assessment. provides average, smallest, largest balance statistic covariate across imputations. allows see bad worst imbalance balance looks like average across imputations. summary behaves differently depending whether abs specified TRUE FALSE. abs = TRUE, across-imputation balance summary display mean absolute balance statistics maximum absolute balance statistics. abs = FALSE, across-imputation balance summary display minimum, mean, maximum balance statistic original form.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/class-bal.tab.imp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Using bal.tab() with Multiply Imputed Data — class-bal.tab.imp","text":"four arguments bal.tab() method can handle multiply imputed data: imp, .imp, imp.summary, imp.fun. imp vector imputation membership. can factor, character, numeric vector. argument required let bal.tab() know data multiply imputed unless MatchThem objects used. data argument specified, can also name variable data contains imputation membership. data argument mids object, output call mice(), imp need specified automatically extracted mids object. .imp display option affect computation. ., imputations imp displayed. .none (default), imputations displayed. Otherwise, can vector imputation indices display balance. imp.summary display option affect computation. TRUE, balance summary across imputations displayed. default TRUE, .imp .none, automatically set TRUE. imp.fun display option affect computation. Can \"min\", \"mean\", \"max\" corresponds function used across-imputation summary combine results across imputations. example, imp.fun = \"mean\" mean balance statistic across imputations displayed. default abs = FALSE bal.tab() call display three. default abs = FALSE bal.tab() call display just mean max balance statistic.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/class-bal.tab.imp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Using bal.tab() with Multiply Imputed Data — class-bal.tab.imp","text":"output bal.tab.imp object, inherits bal.tab. following elements: Imputation.Balance imputation, regular bal.tab object containing balance table, sample size summary, balance assessment tools, depending options specified. Balance.Across.Imputations balance summary across imputations. include combination balance statistic covariate across imputations according value imp.fun. Observations table sample sizes effective sample sizes averaged across imputations adjustment. methods, multiple weights can specified, values weights appear tables.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/class-bal.tab.imp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Using bal.tab() with Multiply Imputed Data — class-bal.tab.imp","text":"Noah Greifer","code":""},{"path":[]},{"path":"https://ngreifer.github.io/cobalt/reference/class-bal.tab.msm.html","id":null,"dir":"Reference","previous_headings":"","what":"Using bal.tab() with Longitudinal Treatments — class-bal.tab.msm","title":"Using bal.tab() with Longitudinal Treatments — class-bal.tab.msm","text":"using bal.tab() longitudinal treatments, output different case point treatments, options common across bal.tab() methods dealing longitudinal data. page outlines outputs options case. two main components output bal.tab() longitudinal treatments: time-point-specific balance summary across-time-points balance summary. time-point-specific balance summaries standard point treatment balance summaries time point. across-time-points balance summary , variable, greatest imbalance across time-point-specific balance summaries. greatest observed imbalance tolerable, imbalances variable tolerable , focusing reducing greatest imbalance sufficient reducing imbalance overall. balance summary computed multi-category treatments multiply imputed data used.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/class-bal.tab.msm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Using bal.tab() with Longitudinal Treatments — class-bal.tab.msm","text":"two additional arguments bal.tab() method can handle longitudinal treatments: .time msm.summary. .time display option affect computation. .(default), time points displayed. .none, time points displayed. Otherwise, can vector treatment names indices display balance. msm.summary display option affect computation. TRUE, balance summary across time points displayed. default TRUE, .time .none, automatically set TRUE.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/class-bal.tab.msm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Using bal.tab() with Longitudinal Treatments — class-bal.tab.msm","text":"output bal.tab.msm object, inherits bal.tab. following elements: Time.Balance time point, regular bal.tab object containing balance table, sample size summary, balance assessment tools, depending options specified. Balance.Across.Times balance summary across time points. include maximum balance statistic(s) covariate across time points. Observations table sample sizes effective sample sizes time point adjustment. methods, multiple weights can specified, values weights appear tables.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/class-bal.tab.msm.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Using bal.tab() with Longitudinal Treatments — class-bal.tab.msm","text":"Noah Greifer","code":""},{"path":[]},{"path":"https://ngreifer.github.io/cobalt/reference/class-bal.tab.multi.html","id":null,"dir":"Reference","previous_headings":"","what":"Using bal.tab() with Multi-Category Treatments — class-bal.tab.multi","title":"Using bal.tab() with Multi-Category Treatments — class-bal.tab.multi","text":"using bal.tab() multi-category treatments, output different case binary continuous treatments, options common across bal.tab() methods. page outlines outputs options case. two main components output bal.tab() multi-category treatments: two-group treatment comparisons balance summary. two-group treatment comparisons standard binary treatment comparison either pairs groups (e.g., treatments , B, C, \"vs. B\", \"vs. C\", \"B vs. C\") group groups (.e., entire sample). balance summary , variable, greatest imbalance across two-group comparisons. , variable X1, \"vs. B\" standardized mean difference 0.52, \"vs. C\" standardized mean difference .17,  \"B vs. C\" standardized mean difference .35, balance summary 0.52 value standardized mean difference X1. goes variables measures balance. greatest observed imbalance tolerable, imbalances variable tolerable , focusing reducing greatest imbalance sufficient reducing imbalance overall. (Note s.d.denom = \"pooled\", .e., estimand ATE, pooled standard deviation denominator average standard deviations across treatment groups, just used pairwise comparison.) balance summary computed multiply imputed data used.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/class-bal.tab.multi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Using bal.tab() with Multi-Category Treatments — class-bal.tab.multi","text":"four arguments bal.tab() method can handle multi-category treatments: pairwise, focal, .treat, multi.summary. pairwise Whether compute two-group comparisons pairwise . TRUE, bal.tab() compute comparisons pair treatments. can valuable treatments compared one another (often case). FALSE, bal.tab() compute balance treatment group full unadjusted sample. makes sense ATE desired. focal specified, pairwise automatically set TRUE. focal one group compared multiple control groups ATT analysis, group considered \"treated\" focal group. comparisons groups focal group interest. specifying name index treatment condition considered focal, bal.tab() compute display pairwise balance treatment comparisons include focal group. example, \"\" compared \"B\" \"C\", \"\" considered focal, comparison groups \"B\" \"C\" computed. general good idea specify focal ATT sought. .treat display option affect computation. displaying bal.tab output, treatments displayed? vector length 1 entered, comparisons involving treatment group displayed. vector length 2 entered, comparisons involving treatments appear input displayed. example, inputting \"\" display \"vs. B\" \"vs. C\", entering c(\"\", \"B\") display \"vs. B\". .none indicates treatment comparisons displayed, .indicates treatment comparisons displayed. .none default. multi.summary TRUE, balance summary across comparisons computed displayed. includes one row covariate maximum balance statistic across pairwise comparisons. Note , variance ratios KS statistics requested addition mean differences, displayed values may come pairwise comparisons; , greatest standardized mean difference greatest variance ratio may come comparison. default TRUE, .treat .none, automatically set TRUE.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/class-bal.tab.multi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Using bal.tab() with Multi-Category Treatments — class-bal.tab.multi","text":"output bal.tab.multi object, inherits bal.tab. following elements: Pair.Balance pair treatment groups, regular bal.tab object containing balance table, sample size summary, balance assessment tools, depending options specified. focal specified, comparisons involving focal group computed. pairwise FALSE, comparisons group groups combined (labeled \"\"). Balance.Across.Pairs balance summary across two-group comparisons. include greatest (.e., maximum) absolute balance statistics(s) covariate across comparisons computed. Thresholds can requested balance measure binary treatments. Observations table sample sizes effective sample sizes treatment group adjustment. methods, multiple weights can specified, values weights appear tables.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/class-bal.tab.multi.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Using bal.tab() with Multi-Category Treatments — class-bal.tab.multi","text":"versions 4.3.1 earlier, setting pairwise = FALSE comapre group full adjusted sample. Now, group compared full unadjusted sample (unadjusted except s.weights, supplied).","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/class-bal.tab.multi.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Using bal.tab() with Multi-Category Treatments — class-bal.tab.multi","text":"Noah Greifer","code":""},{"path":[]},{"path":"https://ngreifer.github.io/cobalt/reference/class-bal.tab.subclass.html","id":null,"dir":"Reference","previous_headings":"","what":"Using bal.tab() with Subclassified Data — class-bal.tab.subclass","title":"Using bal.tab() with Subclassified Data — class-bal.tab.subclass","text":"using bal.tab() subclassified data, .e., data split subclasses balance may hold, output different standard, non-subclassified case, additional option controlling display. page outlines outputs options case. two main components output bal.tab() subclassified data: balance within subclasses balance summary across subclasses. within-subclass balance displays essentially standard balance displays subclass, except \"adjusted\" values available, subclassification adjustment. balance summary , variable, like weighted average balance statistics across subclasses. computed internally assigning individual weight based subclass treatment group membership computing weighted balance statistics usual weights. summary one get subclasses supplied match.strata argument rather subclass. means mean differences additive, computed values weighted averages subclass-specific values, statistics, computed values .","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/class-bal.tab.subclass.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Using bal.tab() with Subclassified Data — class-bal.tab.subclass","text":"three arguments bal.tab() relate subclasses: subclass, .subclass, subclass.summary. subclass data.frame formula methods bal.tab(), vector subclass membership name variable data containing subclass membership. using subclassification function compatible cobalt, matchit() MatchIt, argument can omitted subclass output object. .subclass display option affect computation. ., subclasses subclass displayed. .none (default), subclasses displayed. Otherwise, can vector subclass indices display balance. subclass.summary display option affect computation. TRUE, balance summary across subclasses displayed. default TRUE, .subclass .none, automatically set TRUE.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/class-bal.tab.subclass.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Using bal.tab() with Subclassified Data — class-bal.tab.subclass","text":"output bal.tab.subclass object, inherits bal.tab. following elements: Subclass.Balance list data frames containing balance information covariate subclass. Balance.Across.Subclass data frame containing balance statistics covariate aggregated across subclasses original sample (.e., unadjusted). See bal.tab() details includes.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/class-bal.tab.subclass.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Using bal.tab() with Subclassified Data — class-bal.tab.subclass","text":"Noah Greifer","code":""},{"path":[]},{"path":"https://ngreifer.github.io/cobalt/reference/cobalt-package.html","id":null,"dir":"Reference","previous_headings":"","what":"cobalt: Covariate Balance Tables and Plots — cobalt-package","title":"cobalt: Covariate Balance Tables and Plots — cobalt-package","text":"set tools assessing covariate balance observational studies numerically graphically. functions provide integration major R packages used balancing covariates, including MatchIt, WeightIt, twang, CBPS, many others, support objects made using packages. support binary, multi-category continuous treatments, point longitudinal treatments, clustered multiply imputed data. main functions cobalt following: bal.tab() - generate tables balance statstics matching, weighting, subclassification bal.plot() - generate plots assess balance visually one covariate time love.plot() - generate plots summarize report balance statistics functions include get.w() extracting weights objects produced packages, col_w_smd() (friends documentated page) computing (weighted) balance statistics outside bal.tab(), splitfactor() splitting factor variables dataset dummy variables. cobalt several vignettes, can accessed using vignette(package = \"cobalt\") visiting website https://ngreifer.github.io/cobalt/.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/cobalt-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"cobalt: Covariate Balance Tables and Plots — cobalt-package","text":"Noah Greifer (ORCID) contact cobalt, please use GitHub issues page.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/display_options.html","id":null,"dir":"Reference","previous_headings":"","what":"Options for Displaying bal.tab() Output — Display Options","title":"Options for Displaying bal.tab() Output — Display Options","text":"Several additional arguments can passed bal.tab() control display output; arguments documented . arguments applicable uses bal.tab(); example, .subclass, controls subclasses displayed subclassification used, anything subclassification used. Note quick = TRUE set call bal.tab() (default), setting arguments FALSE can prevent values computed, can unintended effects.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/display_options.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Options for Displaying bal.tab() Output — Display Options","text":"disp.bal.tab logical; whether display table balance statistics. Default TRUE, balance table displayed. imbalanced.logical; whether display covariates failed meet least one balance thresholds. Default FALSE, covariates displayed. un logical; whether print statistics unadjusted sample well adjusted sample. Default FALSE, statistics adjusted sample displayed. disp character; distribution summary statistic(s) reported. Allowable options include \"means\" \"sds\". Multiple options allowed. Abbreviations allowed. stats character; statistic(s) reported. See stats see options available. Multiple options allowed. Abbreviations allowed. binary multi-category treatments, default \"mean.diffs\" (.e., [standardized] mean differences), continuous treatments, default \"correlations\" (.e., treatment-covariate Pearson correlations). factor_sep character; string used separate factor variables levels variable names printed. Default \"_\". int_sep character; string used separate two variables involved interaction variable names printed. Default \" * \". Older versions cobalt used \"_\". disp.call logical; whether display function call original input object, present. Default FALSE, function call displayed. subclassification used .subclass subclasses () displayed. ., subclasses displayed. .none (default), subclasses displayed. Otherwise, can vector subclass indices display balance. subclass.summary logical; whether display balance summary across subclasses. TRUE, balance summary across subclasses displayed. default TRUE, .subclass .none, automatically set TRUE. treatment multi-category .treat treatments treatment combinations balance tables displayed. vector length 1 entered, comparisons involving treatment group displayed. vector length 2 entered, comparisons involving treatments appear input displayed. example, setting  .treat = \"\" display \"vs. B\" \"vs. C\", setting .treat = c(\"\", \"B\") display \"vs. B\". .none indicates treatment comparisons displayed, .indicates treatment comparisons displayed. Default .none. See bal.tab.multi. multi.summary logical; whether display balance summary across treatment pairs. includes one row covariate maximum balance statistic across pairwise comparisons. Note , variance ratios KS statistics requested, displayed values may come pairwise comparisons; , greatest standardized mean difference greatest variance ratio may come comparison. Default TRUE .treat .none FALSE otherwise. See bal.tab.multi. clusters present .cluster clusters balance tables displayed. ., clusters cluster displayed. .none, clusters displayed. Otherwise, can vector cluster names numerical indices display balance. Indices correspond alphabetical order cluster names (order cluster levels factor). Default .. See bal.tab.cluster. cluster.summary logical; whether display balance summary across clusters. Default TRUE .cluster .none FALSE otherwise (note default .cluster .). See bal.tab.cluster. cluster.fun function used across-cluster summary combine results across clusters. Can \"min\", \"mean\", \"max\". example, cluster.fun = \"mean\" mean balance statistic across clusters displayed. default abs = FALSE bal.tab() call display three. default abs = FALSE bal.tab() call display just mean max balance statistic. See bal.tab.cluster. multiple imputations present .imp imputations balance tables displayed. ., imputations imp displayed. .none, imputations displayed. Otherwise, can vector imputation indices display balance. Default .none. See bal.tab.imp. imp.summary logical; whether display balance summary across imputations. Default TRUE .imp .none FALSE otherwise. See bal.tab.imp. imp.fun function used across-imputation summary combine results across imputations. Can \"min\", \"mean\", \"max\". example, imp.fun = \"mean\" mean balance statistic across imputations displayed. default abs = FALSE bal.tab() call display three. default abs = FALSE bal.tab() call display just mean max balance statistic. See bal.tab.imp. treatment longitudinal .time time points balance tables displayed. ., time points displayed. .none, time points displayed. Otherwise, can vector treatment names indices display balance. Default .none. See bal.tab.msm. msm.summary logical; whether display balance summary across time points. Default TRUE .time .none FALSE otherwise. See bal.tab.msm. Deprecated arguments following arguments deprecated still work. disp.means logical; whether print group means balance output. Default FALSE, means displayed. Deprecated; use disp instead. disp.sds logical; whether print group standard deviations balance output. Default FALSE, standard deviations displayed. Deprecated; use disp instead. disp.diff logical; whether display (standardized) mean differences balance output binary multi-category treatments. Default TRUE, mean differences displayed. Deprecated; use stats instead. disp.v.ratio logical; whether display variance ratios balance output binary multi-category treatments. Default FALSE, variance ratios displayed. Deprecated; use stats instead. disp.ks logical; whether display Kolmogorov-Smirnov (KS) statistics balance output binary multi-category treatments. Default FALSE, KS statistics displayed. Deprecated; use stats instead. disp.ovl logical; whether display overlapping (OVL) coefficients balance output binary multi-category treatments. Default FALSE, OVL coefficients displayed. Deprecated; use stats instead.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/display_options.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Options for Displaying bal.tab() Output — Display Options","text":"addition able specified arguments, find frequently set display option something default, can set global option (present R session) using set.cobalt.options() retrieve using get.cobalt.options(). Note global options set .subclass, .cluster, .imp, .treat, .time.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/display_options.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Options for Displaying bal.tab() Output — Display Options","text":"calling bal.tab() using .call(), using ..none inputs arguments, need use alist() rather list() group arguments. example, .call(bal.tab, list(., .cluster = .none)) produce error, .call(bal.tab, alist(., .cluster = .none)) work correctly.","code":""},{"path":[]},{"path":"https://ngreifer.github.io/cobalt/reference/f.build.html","id":null,"dir":"Reference","previous_headings":"","what":"Convenient Formula Generation — f.build","title":"Convenient Formula Generation — f.build","text":"f.build() returns formula form y ~ x1 + x2 + ... data frame input. can much quicker use f.build() hand-write precise formula, may contain errors. can used place formula , example, glm(), matchit(), bal.tab(). provides similar functionality reformulate().","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/f.build.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convenient Formula Generation — f.build","text":"","code":"f.build(y, rhs)"},{"path":"https://ngreifer.github.io/cobalt/reference/f.build.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convenient Formula Generation — f.build","text":"y quoted name response (left hand side) variable formula. one variable supported. missing, NULL, empty string (\"\"), formula response variable. rhs supplied, y replace rhs y set \"\". rhs data frame whose variable names terms right hand side formula, character vector whose values terms right hand side formula. missing, argument y replace rhs y set \"\"; essence, f.build(\"x\") f.build(\"\", \"x\"), producing ~ x.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/f.build.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convenient Formula Generation — f.build","text":"formula object.","code":""},{"path":[]},{"path":"https://ngreifer.github.io/cobalt/reference/f.build.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convenient Formula Generation — f.build","text":"","code":"data(lalonde) covs <- subset(lalonde, select = -c(treat, re78)) #> Error in eval(substitute(select), nl, parent.frame()): object 'treat' not found lm(f.build(\"treat\", covs), data = lalonde) #> Error: object 'covs' not found"},{"path":"https://ngreifer.github.io/cobalt/reference/get.w.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Weights from Preprocessing Objects — get.w","title":"Extract Weights from Preprocessing Objects — get.w","text":"Extracts weights outputs preprocessing functions.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/get.w.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Weights from Preprocessing Objects — get.w","text":"","code":"get.w(x, ...)  # S3 method for matchit get.w(x, ...)  # S3 method for ps get.w(x, stop.method = NULL, estimand, s.weights = FALSE, ...)  # S3 method for mnps get.w(x, stop.method = NULL, s.weights = FALSE, ...)  # S3 method for iptw get.w(x, stop.method = NULL, s.weights = FALSE, ...)  # S3 method for ps.cont get.w(x, s.weights = FALSE, ...)  # S3 method for Match get.w(x, ...)  # S3 method for CBPS get.w(x, estimand, ...)  # S3 method for ebalance get.w(x, treat, ...)  # S3 method for optmatch get.w(x, estimand, ...)  # S3 method for cem.match get.w(x, estimand, ...)  # S3 method for weightit get.w(x, s.weights = FALSE, ...)  # S3 method for mimids get.w(x, ...)  # S3 method for wimids get.w(x, ...)  # S3 method for designmatch get.w(x, treat, estimand, ...)  # S3 method for sbwcau get.w(x, ...)"},{"path":"https://ngreifer.github.io/cobalt/reference/get.w.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Weights from Preprocessing Objects — get.w","text":"x output corresponding preprocessing packages. stop.method name stop method used original call ps() mnps() twang, e.g., \"es.mean\". empty, return weights stop method available data.frame. Abbreviations allowed. estimand weights computed using propensity score (.e., ps CBPS methods), estimand use compute weights. \"ATE\", weights computed 1/ps treated group 1/(1-ps) control group. \"ATT\", weights computed 1 treated group ps/(1-ps) control group. specified, get.w() try figure estimand desired based object. weights computed using subclasses/matching strata (.e., cem designmatch methods), estimand use compute weights. First, subclass propensity score computed proportion treated units subclass, one formulas used based estimand requested. specified, \"ATT\" assumed. treat vector treatment status unit. required methods include treat argument. treatment variable used original preprocessing function call used. s.weights whether sampling weights included original call fitting function included weights. TRUE, returned weights product balancing weights estimated fitting function sampling weights. FALSE, balancing weights returned. ... arguments passed methods.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/get.w.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract Weights from Preprocessing Objects — get.w","text":"output get.w() can used calls formula data frame methods bal.tab() (see example ). way, output multiple preprocessing packages can viewed simultaneously compared. weights can also used weights statements regression methods compute weighted effects. twang function called get.weights() performs function ps objects offers slightly finer control. Note weights generated get.w() ps objects include sampling weights default. sampling weights used CBPS() CBPS, returned weights already sampling weights incorporated. retrieve balancing weights , divide returned weights original sampling weights. packages, balancing weights returned separately unless s.weights = TRUE, means must multiplied sampling weights effect estimation. Match() Matching used CommonSupport = TRUE, returned weights incorrect. option recommended package authors.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/get.w.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Weights from Preprocessing Objects — get.w","text":"vector data frame weights unit. may matching weights balancing weights.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/get.w.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract Weights from Preprocessing Objects — get.w","text":"Noah Greifer","code":""},{"path":[]},{"path":"https://ngreifer.github.io/cobalt/reference/get.w.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Weights from Preprocessing Objects — get.w","text":"","code":"data(\"lalonde\", package = \"cobalt\") library(\"MatchIt\"); library(\"WeightIt\")  m.out <- matchit(treat ~ age + educ + race, data = lalonde)   w.out <- weightit(treat ~ age + educ + race, data = lalonde,                   estimand = \"ATT\")  bal.tab(treat ~ age + educ + race, data = lalonde,         weights = data.frame(matched = get.w(m.out),                              weighted = get.w(w.out)),         method = c(\"matching\", \"weighting\"),          estimand = \"ATT\") #> Balance Measures #>                Type Diff.matched Diff.weighted #> age         Contin.      -0.0280        0.1078 #> educ        Contin.       0.0161       -0.0633 #> race_black   Binary       0.3730       -0.0020 #> race_hispan  Binary      -0.2703        0.0009 #> race_white   Binary      -0.1027        0.0011 #>  #> Effective sample sizes #>          Control Treated #> All       429.       185 #> matched   185.       185 #> weighted  116.94     185"},{"path":"https://ngreifer.github.io/cobalt/reference/lalonde.html","id":null,"dir":"Reference","previous_headings":"","what":"Lalonde's National Supported Work Demonstration Data — lalonde","title":"Lalonde's National Supported Work Demonstration Data — lalonde","text":"One datasets used Dehejia Wahba paper \"Causal Effects Non-Experimental Studies: Reevaluating Evaluation Training Programs.\" Versions data set used example data set MatchIt, twang, Matching, CBPS. data set lalonde_mis values missing (set NA).","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/lalonde.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lalonde's National Supported Work Demonstration Data — lalonde","text":"","code":"data(\"lalonde\") data(\"lalonde_mis\")"},{"path":"https://ngreifer.github.io/cobalt/reference/lalonde.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Lalonde's National Supported Work Demonstration Data — lalonde","text":"data frame 614 observations following 9 variables. treat 1 treated National Supported Work Demonstration,                         0 Current Population Survey age age educ years education race factor; black, Hispanic (hispan), white married 1 married, 0 otherwise nodegree 1 degree, 0 otherwise re74 earnings 1974 (pretreatment) re75 earnings 1975 (pretreatment) re78 earnings 1978 (outcome)","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/lalonde.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Lalonde's National Supported Work Demonstration Data — lalonde","text":"https://users.nber.org/~rdehejia/data/.nswdata2.html","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/lalonde.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Lalonde's National Supported Work Demonstration Data — lalonde","text":"Lalonde, R. (1986). Evaluating econometric evaluations training programs experimental data. American Economic Review 76: 604-620. Dehejia, R.H. Wahba, S. (1999). Causal Effects Nonexperimental Studies:  Re-Evaluating Evaluation Training Programs. Journal American  Statistical Association 94: 1053-1062.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/love.plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Display Balance Statistics in a Love Plot — love.plot","title":"Display Balance Statistics in a Love Plot — love.plot","text":"Generates \"Love\" plot graphically displaying covariate balance adjusting. Options available producing publication-ready plots.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/love.plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Display Balance Statistics in a Love Plot — love.plot","text":"","code":"love.plot(x,            stats,            abs,            agg.fun = NULL,            var.order = NULL,            drop.missing = TRUE,            drop.distance = FALSE,            thresholds = NULL,            line = FALSE,            stars = \"none\",            grid = FALSE,            limits = NULL,            colors = NULL,            shapes = NULL,            alpha = 1,            size = 3,            wrap = 30,            var.names = NULL,            title,            sample.names,            labels = FALSE,           position = \"right\",            themes = NULL,           ...)"},{"path":"https://ngreifer.github.io/cobalt/reference/love.plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Display Balance Statistics in a Love Plot — love.plot","text":"x valid input call bal.tab() (e.g., output preprocessing function). arguments supplied bal.tab() can entered .... Can also bal.tab object, .e., output call bal.tab(). See Examples. x bal.tab object, love.plot() calls bal.tab() arguments supplied. stats character; statistic(s) reported. See stats allowable options. binary multi-category treatments, \"mean.diffs\" (.e., mean differences) default. continuous treatments, \"correlations\" (.e., treatment-covariate Pearson correlations) default. Multiple options allowed. abs logical; whether present statistic absolute value . variance ratios, force ratios greater equal 1. x bal.tab object, love.plot() might ignore abs depending original bal.tab() call. unspecified, uses whatever used call bal.tab(). agg.fun balance displayed across clusters imputations rather within single cluster imputation, summarizing function (\"mean\", \"max\", \"range\") balance statistics used. \"range\" entered, love.plot() display line min max point mean covariate. Abbreviations allowed; \"range\" default. Remember set .<ARG> = .none (<ARG> grouping argument, cluster imp) use agg.fun. See Details. var.order character love.plot object; order variables plot. See Details. drop.missing logical; whether drop rows variables statistic value NA, example, variance ratios binary variables. FALSE, rows variables points representing value. Default TRUE, variables missing balance statistics absent. multiple stats requested, variables NAs stats dropped drop.missing = TRUE. argument used called .missing, name still works (deprecated). drop.distance logical; whether ignore distance measure () plotting. thresholds numeric; optional value used threshold marker plot. named vector name corresponds statistic threshold applied. See example stats. x bal.tab object threshold set (e.g., thresholds), threshold used unless overridden using threshold argument love.plot. line logical; whether display line connecting points sample. stars mean differences displayed, variable names star (.e., asterisk) next . Allowable values \"none\", \"std\" (variables mean differences standardized), \"raw\" (variables mean differences standardized). \"raw\", x-axis title \"Standardized Mean Differences\". Otherwise, \"Mean Differences\". Ignored mean difference displayed. See Details explanation purpose option. grid logical; whether gridlines shown plot. Default FALSE. limits numeric; bounds x-axis plot. Must (named) list vectors length 2 ascending order, one value stats limits; e.g., list(m = c(-.2, .2)). values exceed limits, plotted edge. colors colors points plot. See 'Color Specification' graphics::par() ggplot2 aesthetic specifications page. first value corresponds color unadjusted sample, second color adjusted sample. one specified, apply . Defaults default ggplot2 colors. shapes shapes points plot. Must one two numbers 1 25 name valid shape. See ggplot2 aesthetic specifications page valid options. Values 15 25 recommended. first value corresponds shape unadjusted sample, second color adjusted sample. one specified, apply . Defaults 19 (\"circle filled\"). alpha numeric; transparency points. See ggplot2::scale_alpha(). size numeric; size points plot. Defaults 3. previous versions, size scaled factor 3. Now size corresponds directly size aesthetic ggplot2::geom_point(). wrap numeric; number characters wrap axis labels next line. Defaults 30. Decrease axis labels excessively long. var.names optional object providing alternate names variables plot, otherwise variable names stored. may useful variables ugly names. See Details specify var.names. var.names() can useful tool extracting editing names bal.tab object. title character; title plot. sample.names character; new names given samples (.e., place \"Unadjusted\" \"Adjusted\"). example, matching used, may useful enter c(\"Unmatched\", \"Matched\"). labels logical character; labels give plots multiple stats requested. TRUE, labels capital letters. Otherwise, must string length stats. can useful plots used article. position position legend. stats length 1, can value appropriate argument legend.position ggplot2::theme(). stat length greater 1, can one \"none\", \"left\", \"right\", \"bottom\", \"top\". themes optional list theme objects append individual plot. entry output call ggplot2::theme() ggplot2. way customize individual plots multiple stats requested since final output manipulable ggplot object. can used length-1 stats, probably makes sense just add theme() call love.plot(). ... additional arguments passed bal.tab() options display plot. following related arguments currently accepted: use.grid whether use gridExtra::arrangeGrob() gridExtra make plot stats length 1. See section Value. disp.subclass whether display individual subclasses subclassification used. Overrides disp.subclass option original bal.tab() call x bal.tab object. star_char character; stars used, character \"star\" next starred variables. default \"*\". \"†\" \"\\u2020\" (.e., dagger) might appealing well. Additionally, . arguments used clustered multiply imputed data longitudinal multi-category treatments can specified display balance selected groupings. Set .none aggregate across groups (agg.fun comes effect) set .view groups. See display_options options, see vignette \"Appendix 2: Using cobalt Clustered, Multiply Imputed, Segmented Data\" details examples.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/love.plot.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Display Balance Statistics in a Love Plot — love.plot","text":"love.plot can used clusters, imputations, multi-category longitudinal treatments addition standard case. Setting corresponding . argument .none aggregate across dimension. aggregating, argument specified agg.fun referring whether mean, minimum (\"min\"), maximum (\"max\") balance statistic range (\"range\", default) balance statistics covariate presented plot. See vignette \"Appendix 2: Using cobalt Clustered, Multiply Imputed, Segmented Data\" examples. subclasses, balance displayed unadjusted sample aggregated subclassified sample. disp.subclass TRUE, subclass displayed additionally number plot. Variable order using var.order order variables presented depends argument var.order. NULL, default, displayed order call bal.tab(), order underlying data set. \"alphabetical\", displayed alphabetical order. \"unadjusted\", ordered balance statistic unadjusted sample. order values adjusted sample, \"adjusted\" can supplied one set weights (subclasses) specified; otherwise, name set weights specified. multiple stats requested, order determined first entry stats (e.g., \"mean.diffs\" \"ks.statistics\" requested, var.order = \"unadjusted\", variables displayed order unadjusted mean differences plots). multiple plots produced simultaneously (.e., individual clusters imputations), var.order can NULL \"alphabetical\". love.plot object supplied, plot drawn use variable order supplied love.plot object. can useful making one plot variable order across plots. Variable names using var.names default love.plot present variables named output call bal.tab, important know output specifying alternate variable names using var.names, displayed variable names may differ original data. several ways specify alternate names presentation displayed plot using var.names argument specifying list old new variable names, pairing old name new name. can three ways: 1) use vector list new variable names, names values old variable names; 2) use data frame exactly one column containing new variable names row names containing old variable names; 3) use data frame two columns, first (one named \"old\") containing old variable names second (one named \"new\") containing new variable names. variable output bal.tab() provided list old variable names, love.plot() use original old variable name. love.plot() can replace old variables names new ones based exact matching name strings matching using variable name components. example, factor variable \"X\" levels \"\", \"b\", \"c\" displayed love.plot(), variables \"X_a\", \"X_b\", \"X_c\" displayed. can enter replacement names three variables individually var.names, can simply specify replacement name \"X\", \"X\" replaced given name instances appears, including just factor expansions, also polynomials interactions int = TRUE original bal.tab() call. interaction another variable, say \"Y\", several ways replace name interaction term \"X_a * Y\". entire string (\"X_a * Y\") included var.names, entire string replaced. \"X_a\" included var.names, replaced (replaced everywhere else appears). \"X\" included var.names, replaced (replaced everywhere else appears). See example var.names(). Stars x-axis label mean differences mean differences displayed, love.plot() attempts figure appropriate label x-axis. mean differences standardized, x-axis label \"Standardized Mean Differences\". mean differences raw (.e., unstandardized), x-axis label \"Mean Differences\". Otherwise, love.plot() turns stars argument. \"raw\", x-axis label \"Standardized Mean Differences\" (.e., un-starred variables standardized mean differences displayed). \"std\", x-axis label \"Mean Differences\" (.e., un-starred variables raw mean differences displayed). \"none\", x-axis label \"Mean Differences\" warning issued recommending use stars. default display standardized mean differences continuous variables, raw mean differences binary variables, stars, warning issued default uses love.plot(). purpose correct behavior previous versions cobalt default x-axis label \"Mean Differences\", even standardized mean differences displayed, yielding potentially misleading plot. warning requires user think values displayed. idea using stars user can, caption plot, explain variables asterisk standardized (raw) mean differences display, contrast un-starred variables.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/love.plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Display Balance Statistics in a Love Plot — love.plot","text":"one type balance statistic requested, returned object standard ggplot object can manipulated using ggplot2 syntax. facilitates changing fonts, background colors, features legend outside love.plot() provides automatically. one type balance statistic requested, plot constructed using gridExtra::arrangeGrob() gridExtra, arranges multiple plots shared legend one plot. output arrangeGrob gtable object, features manipulated standard way. Use themes argument change theme elements component plots. original plots stored \"plots\" attribute output object.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/love.plot.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Display Balance Statistics in a Love Plot — love.plot","text":"love.plot can also called using plot() autoplot() bal.tab object. used way, messages may appear twice. recommended just use love.plot() instead.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/love.plot.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Display Balance Statistics in a Love Plot — love.plot","text":"Noah Greifer","code":""},{"path":[]},{"path":"https://ngreifer.github.io/cobalt/reference/love.plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Display Balance Statistics in a Love Plot — love.plot","text":"","code":"library(WeightIt); data(\"lalonde\", package = \"cobalt\")  ## Propensity score weighting w.out1 <- weightit(treat ~ age + educ + race +                    married + nodegree + re74 + re75,                    data = lalonde)  love.plot(w.out1, thresholds = c(m = .1), var.order = \"unadjusted\") #> Warning: Standardized mean differences and raw mean differences are present in the same plot.  #> Use the 'stars' argument to distinguish between them and appropriately label the x-axis.   ## Using alternate variable names v <- data.frame(old = c(\"age\", \"educ\", \"race_black\", \"race_hispan\",                          \"race_white\", \"married\", \"nodegree\", \"re74\",                          \"re75\", \"distance\"),                 new = c(\"Age\", \"Years of Education\", \"Black\",                          \"Hispanic\", \"White\", \"Married\", \"No Degree\",                          \"Earnings 1974\", \"Earnings 1975\",                          \"Propensity Score\"))                  love.plot(w.out1, stats = \"m\", threshold = .1,            var.order = \"unadjusted\", var.names = v) #> Warning: Standardized mean differences and raw mean differences are present in the same plot.  #> Use the 'stars' argument to distinguish between them and appropriately label the x-axis.             #Using multiple stats love.plot(w.out1, stats = c(\"m\", \"ks\"),            thresholds = c(m = .1, ks = .05),            var.order = \"unadjusted\", var.names = v, stars = \"raw\",           position = \"bottom\", wrap = 20)             #Changing visual elements love.plot(w.out1, thresholds = c(m = .1),            var.order = \"unadjusted\", var.names = v, abs = TRUE,           shapes = c(\"triangle filled\", \"circle\"),            colors = c(\"red\", \"blue\"), line = TRUE,           grid = FALSE, sample.names = c(\"Original\", \"Weighted\"),           stars = \"raw\", position = \"top\")"},{"path":"https://ngreifer.github.io/cobalt/reference/print.bal.tab.html","id":null,"dir":"Reference","previous_headings":"","what":"Print Results of a Call to bal.tab() — print.bal.tab","title":"Print Results of a Call to bal.tab() — print.bal.tab","text":"Prints bal.tab() output clean way. Provides options printing.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/print.bal.tab.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print Results of a Call to bal.tab() — print.bal.tab","text":"","code":"# S3 method for bal.tab print(x,        imbalanced.only,        un,       disp.bal.tab,       disp.call,       stats,       disp.thresholds,       disp,       which.subclass,       subclass.summary,       which.imp,       imp.summary,       imp.fun,       which.treat,       multi.summary,       which.time,       msm.summary,       which.cluster,       cluster.summary,       cluster.fun,       digits = max(3, getOption(\"digits\") - 3),       ...)"},{"path":"https://ngreifer.github.io/cobalt/reference/print.bal.tab.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print Results of a Call to bal.tab() — print.bal.tab","text":"x bal.tab object; output call bal.tab(). imbalanced.logical; whether display covariates failed meet least one balance thresholds. Depends whether threshold initial set call bal.tab() arguments print() (except disp.bal.tab). un logical; whether display balance values unadjusted sample. Ignored (set TRUE) conditioning performed. disp.bal.tab logical; whether display table balance statistics. FALSE, values (e.g., call, sample sizes, balance tallies, maximum imbalances) presented. disp.call logical; whether display function call input object, . stats character; statistic(s) reported. binary multi-category treatments, options \"mean.diffs\" mean differences (standardized according selected bal.tab() options), \"variance.ratios\" variance ratios, \"ks.statistics\" Kolmogorov-Smirnov statistics. \"mean.diffs\" default. continuous treatments, option \"correlations\" treatment-covariate correlations. Multiple options allowed. Abbreviations allowed. Statistics requested original call bal.tab() requested print() unless quick = FALSE original call. disp.thresholds logical; whether display thresholds statistic thresholds originally requested call bal.tab(). named logical vector names corresponding thresholds. example, thresholds mean differences requested bal.tab(), set disp.thresholds = c(m = FALSE) prevent printed. statistic prevented displayed another argument print(), thresholds displayed. disp character; distribution summary statistics display. Allowable options include \"means\" \"sds\". Statistics requested original call bal.tab() requested print() unless quick = FALSE original call. .subclass used subclassification, subclass(es) display. NULL, subclasses displayed. NA, subclasses displayed. Otherwise, can vector subclass indices display balance. display subclasses requested original call bal.tab(), omit argument. See bal.tab.subclass details. subclass.summary logical; used subclassification, whether display subclass balance summary table. .subclass NA, subclass.summary set TRUE. See bal.tab.subclass details. .imp used multiply imputed data, imputation(s) display. NULL, imputations displayed. NA, imputations displayed. Otherwise, can vector imputations numbers display balance. display imputations requested original call bal.tab(), omit argument. See bal.tab.imp details. imp.summary logical; used multiply imputed data, whether display imputation summary table. .imp NA, imp.summary set TRUE. See bal.tab.imp details. imp.fun character; used multiply imputed data, character vector functions balance statistics display displaying balance across imputations. Can \"mean\", \"min\", \"max\". one allowed. See bal.tab.imp details. .treat used multi-category treatments, treatments display. See bal.tab.multi details. multi.summary logical; used multi-category treatments, whether display balance summary table across pairwise comparisons. See bal.tab.multi details. .time used longitudinal treatments, time periods display longitudinal treatments used. See bal.tab.msm details. msm.summary logical; used longitudinal treatments, whether display balance summary table across time periods. See bal.tab.msm details. .cluster used clustered data, cluster(s) display. NULL, clusters displayed. NA, clusters displayed. Otherwise, can vector cluster names numerical indices display balance. Indices correspond alphabetical order cluster names. display clusters requested original call bal.tab(), omit argument. See bal.tab.cluster details. cluster.summary logical; used clustered data, whether display cluster summary table. .cluster NA, cluster.summary set TRUE. See bal.tab.cluster details. cluster.fun character; used clustered data, character vector functions balance statistics display displaying balance across clusters. Can \"mean\", \"min\", \"max\". one allowed. See bal.tab.cluster details. digits number digits display. ... arguments passed methods.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/print.bal.tab.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print Results of a Call to bal.tab() — print.bal.tab","text":"Simply calling bal.tab() print results, can useful store results object print later, possibly different print options specified. print() function automatically dispatches correct method bal.tab object given. parameter used bal.tab() calculations, int, addl, distance, used print(); parameters listed , solely determine printing options, can used. change computation options, new call bal.tab() must performed. Prior versions print() separate methods bal.tab class. Now dispatched internally.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/print.bal.tab.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Print Results of a Call to bal.tab() — print.bal.tab","text":"Unless quick = FALSE original call bal.tab() (default), values may calculated, case using print() display values even requested. example, stats = \"m\" quick = TRUE original call bal.tab() (default ), setting stats = \"ks\" print() print KS statistics calculated.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/print.bal.tab.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print Results of a Call to bal.tab() — print.bal.tab","text":"Noah Greifer","code":""},{"path":[]},{"path":"https://ngreifer.github.io/cobalt/reference/print.bal.tab.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print Results of a Call to bal.tab() — print.bal.tab","text":"","code":"library(WeightIt); data(\"lalonde\", package = \"cobalt\")  w.out <- weightit(treat ~ age + educ + married + race + re74 + re75,                    data = lalonde)                    b <- bal.tab(w.out, stats = c(\"m\", \"v\", \"ks\"),               un = TRUE, v.threshold = 2)               print(b, un = FALSE, stats = c(\"m\", \"v\"),       disp.thresholds = c(v = FALSE)) #> Balance Measures #>                 Type Diff.Adj V.Ratio.Adj #> prop.score  Distance   0.1660      0.9426 #> age          Contin.  -0.1885      0.3730 #> educ         Contin.   0.0861      0.5164 #> married       Binary  -0.1043           . #> race_black    Binary   0.0612           . #> race_hispan   Binary   0.0104           . #> race_white    Binary  -0.0715           . #> re74         Contin.  -0.2825      0.8392 #> re75         Contin.  -0.1614      0.9440 #>  #> Effective sample sizes #>            Control Treated #> Unadjusted  429.    185.   #> Adjusted    330.88   65.26"},{"path":"https://ngreifer.github.io/cobalt/reference/set.cobalt.options.html","id":null,"dir":"Reference","previous_headings":"","what":"Set and Get Options in cobalt — set.cobalt.options","title":"Set and Get Options in cobalt — set.cobalt.options","text":"Makes easier set cobalt options. set.cobalt.options() essentially wrapper options() performs several checks, get.cobalt.options() essentially wrapper getOption().","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/set.cobalt.options.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set and Get Options in cobalt — set.cobalt.options","text":"","code":"set.cobalt.options(..., default = FALSE)  get.cobalt.options(...)"},{"path":"https://ngreifer.github.io/cobalt/reference/set.cobalt.options.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set and Get Options in cobalt — set.cobalt.options","text":"... set.cobalt.options(), bal.tab() parameters values take. name parameter bal.tab() without \"cobalt_\" preceding . See examples. values NULL, corresponding options set back defaults. get.cobalt.options(), one strings containing name parameter option retrieved. See examples. empty, available options values returned. default TRUE, sets cobalt options named ... default values.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/set.cobalt.options.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Set and Get Options in cobalt — set.cobalt.options","text":"option set NULL, set default value. defaults displayed listed help pages appear. options correspond display options, can accessed . others (e.g., continous binary) described bal.tab() help page.","code":""},{"path":[]},{"path":"https://ngreifer.github.io/cobalt/reference/set.cobalt.options.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set and Get Options in cobalt — set.cobalt.options","text":"","code":"# Set un to be TRUE to always display unadjusted  # balance measures and set binary to \"std\" to  # produce standardized mean differences for  # binary variables.  set.cobalt.options(un = TRUE, binary = \"std\")  # Note: the above is equivalent to: # options(cobalt_un = TRUE, cobalt_binary = \"std\") # but performs some additional checks  get.cobalt.options(\"un\", \"binary\") #> $un #> [1] TRUE #>  #> $binary #> [1] \"std\" #>   # Note: the above is equivalent to: # getOption(\"cobalt_un\") # getOption(\"cobalt_binary\")  # Return all cobalt options to their defaults  set.cobalt.options(default = TRUE)  # View all available options get.cobalt.options() #> $stats #> NULL #>  #> $un #> NULL #>  #> $continuous #> NULL #>  #> $binary #> NULL #>  #> $imbalanced.only #> NULL #>  #> $disp #> NULL #>  #> $disp.means #> NULL #>  #> $disp.sds #> NULL #>  #> $disp.v.ratio #> NULL #>  #> $disp.ks #> NULL #>  #> $disp.subclass #> NULL #>  #> $disp.bal.tab #> NULL #>  #> $cluster.summary #> NULL #>  #> $cluster.fun #> NULL #>  #> $imp.summary #> NULL #>  #> $imp.fun #> NULL #>  #> $multi.summary #> NULL #>  #> $msm.summary #> NULL #>  #> $target.summary #> NULL #>  #> $subclass.summary #> NULL #>  #> $int_sep #> NULL #>  #> $factor_sep #> NULL #>  #> $center #> NULL #>  #> $remove_perfect_col #> NULL #>  #> $disp.call #> NULL #>"},{"path":"https://ngreifer.github.io/cobalt/reference/splitfactor.html","id":null,"dir":"Reference","previous_headings":"","what":"Split and Unsplit Factors into Dummy Variables — splitfactor","title":"Split and Unsplit Factors into Dummy Variables — splitfactor","text":"splitfactor() splits factor variables dummy (0/1) variables. can useful functions process factor variables well require numeric matrices operate. unsplitfactor() combines dummy variables factor variables, undoing operation splitfactor().","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/splitfactor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Split and Unsplit Factors into Dummy Variables — splitfactor","text":"","code":"splitfactor(data, var.name, drop.level = NULL,              drop.first = TRUE, drop.singleton = FALSE,              drop.na = TRUE, sep = \"_\", replace = TRUE,              split.with = NULL, check = TRUE)  unsplitfactor(data, var.name, dropped.level = NULL,                dropped.na = TRUE, sep = \"_\",                replace = TRUE)"},{"path":"https://ngreifer.github.io/cobalt/reference/splitfactor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Split and Unsplit Factors into Dummy Variables — splitfactor","text":"data data.frame containing variables split unsplit. splitfactor(), can factor variable split. var.name splitfactor(), names factor variables split. specified, split factor variables data. data factor, stem new variables created. unsplitfactor(), name previously split factor. specified data output call splitfactor(), previously split variables unsplit. drop.level name level var.name drop dummy variable. works one variable split. drop.first Whether drop first dummy created factor. \"if2\", drop first category factor exactly two levels. default always drop first dummy (TRUE). drop.singleton Whether drop factor variable one level. drop.na NAs present variable, handle . TRUE, new dummy created NA values, created dummies NA original variable NA. FALSE, NA treated like factor level, given column, dummies value 0 original variable NA. sep character separating stem value variable dummy. example, \"race_black\", sep = \"_\". replace Whether replace original variable(s) new variable(s) (TRUE) append newly created variable(s) end data set (FALSE). split.list vectors factors lengths equal number columns data split way data . See Details. check Whether make sure variables specified var.name actually factor (character) variables. splitting non-factor (non-character) variables dummies, set check = FALSE. check = FALSE data data.frame, argument var.name must specified. dropped.level value original factor variable whose dummy dropped variable split. left empty dummy dropped, resulting factor value NA instead dropped value. one entry per variable unsplit. dummy dropped variable, entry still required, ignored. dropped.na TRUE, assume NAs variables unsplit correspond NA unsplit factor (.e., drop.na = TRUE specified split.factor()). FALSE, assume dummy called \"var.name_stem_NA\" (e.g., \"x_NA\") contains 1s unsplit factor NA (.e., drop.na = FALSE specified split.factor(). NAs stored different column stem, e.g., \"x_miss\", name (e.g., \"miss\") can entered instead.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/splitfactor.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Split and Unsplit Factors into Dummy Variables — splitfactor","text":"NAs variable split, new variables created splitfactor() NA original variable NA. using unsplitfactor() data.frame generated splitfactor(), arguments dropped.na, sep unnecessary. split.supplied, elements split way data . example, data contained 4-level factor split, entries split.index factor duplicated resulting entries length number columns data split. resulting values stored \"split.\" attribute output object. See Examples.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/splitfactor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Split and Unsplit Factors into Dummy Variables — splitfactor","text":"splitfactor(), data.frame containing original data set newly created dummies. unsplitfactor(). data.frame containing original data set newly created factor variables.","code":""},{"path":[]},{"path":"https://ngreifer.github.io/cobalt/reference/splitfactor.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Split and Unsplit Factors into Dummy Variables — splitfactor","text":"","code":"data(\"lalonde\", package = \"cobalt\")  lalonde.split <- splitfactor(lalonde, \"race\",                             replace = TRUE,                             drop.first = TRUE) # A data set with \"race_hispan\" and \"race_white\" instead # of \"race\".  lalonde.unsplit <- unsplitfactor(lalonde.split, \"race\",                          replace = TRUE,                         dropped.level = \"black\")  all.equal(lalonde, lalonde.unsplit) #TRUE #> [1] TRUE  # Demonstrating the use of split.with: to.split <- list(letters[1:ncol(lalonde)],                  1:ncol(lalonde))                   lalonde.split <- splitfactor(lalonde, split.with = to.split,                              drop.first = FALSE) attr(lalonde.split, \"split.with\") #> [[1]] #>       treat         age        educ  race_black race_hispan  race_white  #>         \"a\"         \"b\"         \"c\"         \"d\"         \"d\"         \"d\"  #>     married    nodegree        re74        re75        re78  #>         \"e\"         \"f\"         \"g\"         \"h\"         \"i\"  #>  #> [[2]] #>       treat         age        educ  race_black race_hispan  race_white  #>           1           2           3           4           4           4  #>     married    nodegree        re74        re75        re78  #>           5           6           7           8           9  #>"},{"path":"https://ngreifer.github.io/cobalt/reference/var.names.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Variable Names from bal.tab Objects — var.names","title":"Extract Variable Names from bal.tab Objects — var.names","text":"function extracts variable names bal.tab object use specifying alternate variable names love.plot(). Optionally, file can written easy editing names.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/var.names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Variable Names from bal.tab Objects — var.names","text":"","code":"var.names(b,            type,            file = NULL,            minimal = FALSE)"},{"path":"https://ngreifer.github.io/cobalt/reference/var.names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Variable Names from bal.tab Objects — var.names","text":"b bal.tab object; output call bal.tab(). type type output desired. Can either \"df\" data.frame \"vec\" named vector. See \"Value\". default \"vec\" unless file NULL. file optional; file name save output type = \"df\". See write.csv(), var.name calls. Must end .csv. minimal whether output contain variable names (.e., rows appear output bal.tab()) just unique base variables. See \"Details\".","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/var.names.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Variable Names from bal.tab Objects — var.names","text":"type = \"vec\", character vector variable names names entries. type = \"df\", data.frame two columns called \"old\" \"new\", variables entries. file NULL, output returned invisibly.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/var.names.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract Variable Names from bal.tab Objects — var.names","text":"goal function make supplying new variable names var.names argument love.plot() easier. Rather manually creating vector data.frame variable names one desires change, one can use var.names() extract variable names bak.tab object edit output. Importantly, output can saved CSV file, can easily edited read back R use love.plot(), demonstrated Example. minimal = TRUE, minimal set variables output. example, variables analyzed bal.tab() age, race, married, int = TRUE bal.tab(), many variables appear output, including expansions factor variables, polynomial terms, interactions. Rather renaming variables individually, one can rename just three base variables, variables arise accordingly renamed. Setting minimal = TRUE requests base variables.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/var.names.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Extract Variable Names from bal.tab Objects — var.names","text":"programs can properly read Unicode characters polynomial terms requested. may appear strange , e.g., Excel, R process characters correctly.","code":""},{"path":"https://ngreifer.github.io/cobalt/reference/var.names.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Variable Names from bal.tab Objects — var.names","text":"","code":"data(lalonde, package = \"cobalt\")  b1 <- bal.tab(treat ~ age + race + married, data = lalonde,              int = TRUE) #> Note: 's.d.denom' not specified; assuming pooled. v1 <- var.names(b1, type = \"vec\", minimal = TRUE) v1[\"age\"] <- \"Age (Years)\" v1[\"race\"] <- \"Race/Eth\" v1[\"married\"] <- \"Married\" love.plot(b1, var.names = v1) #> Warning: Standardized mean differences and raw mean differences are present in the same plot.  #> Use the 'stars' argument to distinguish between them and appropriately label the x-axis.   if (FALSE) { b2 <- bal.tab(treat ~ age + race + married + educ + nodegree +               re74 + re75 + I(re74==0) + I(re75==0),                data = lalonde) var.names(b2, file = \"varnames.csv\")  ##Manually edit the CSV (e.g., in Excel), then save it. v2 <- read.csv(\"varnames.csv\") love.plot(b2, var.names = v2) }"},{"path":"https://ngreifer.github.io/cobalt/news/index.html","id":"cobalt-441","dir":"Changelog","previous_headings":"","what":"cobalt 4.4.1","title":"cobalt 4.4.1","text":"CRAN release: 2022-11-03 Fixed bug covariates nonstandard names extracted model objects (#63). Thanks @markdanese. Fixed bug “0” “1” names two treatment levels multinomial treatment. Fixed bug default method bal.tab() ignoring components supplied object. Fixed bug bal.plot() ignore s.weights. now included correctly. call original balancing function now hidden default. request displayed, set disp.call = TRUE call bal.tab() print.bal.tab() use set.cobalt.options(disp.call = TRUE) display session.","code":""},{"path":"https://ngreifer.github.io/cobalt/news/index.html","id":"cobalt-440","dir":"Changelog","previous_headings":"","what":"cobalt 4.4.0","title":"cobalt 4.4.0","text":"CRAN release: 2022-08-15 Added support bal.plot() negative weights type = \"density\". Added support ps.cont() objects twangContinuous package. ps.cont objects WeightIt longer supported. Major documentation overhaul. arguments explained help(\"bal.tab\") new package help page can found help(\"cobalt-package\"). function call longer included bal.tab() results objects twang. Fixed bug predictors binary clusters continuous others. Variables now stable type across partitions. Fixed bug binary variables correctly processed using formula interface. using poly, orthogonal polynomials can requested setting orth = TRUE. Improved appearance conditional examples pkgdown site. Removed mlogit Suggests. Returned sbw Suggests. Updated logo, thanks Ben Stillerman.","code":""},{"path":"https://ngreifer.github.io/cobalt/news/index.html","id":"cobalt-432","dir":"Changelog","previous_headings":"","what":"cobalt 4.3.2","title":"cobalt 4.3.2","text":"CRAN release: 2022-01-19 pairwise = FALSE binary multi-category treatments, balance statistics now refer difference group original full sample, unadjusted except possibly s.weights. Previously, referred difference group combined adjusted sample. subclassification used units discarded, bal.tab() now reports number discarded units along number units subclass sample sizes table.(#59) Fixed several bugs using love.plot() subclassification caused last update. Thanks Mario Lawes pointing . Fixed bug get.w() computed weights Match objects resulting Matching::Match() estimand = \"ATE\". Results now agree Matching::MatchBalance(). Fixed bug occur using cobalt functions without attaching package (e.g., cobalt::bal.tab()). (#53) Fixed bug occur ordinal treatments. Added better support negative weights. Fixed typos (#54, many identified fixed @jessecambon).","code":""},{"path":"https://ngreifer.github.io/cobalt/news/index.html","id":"cobalt-431","dir":"Changelog","previous_headings":"","what":"cobalt 4.3.1","title":"cobalt 4.3.1","text":"CRAN release: 2021-03-30 Added support objects new version MatchThem. Fixed bug improved speed using match.strata.","code":""},{"path":"https://ngreifer.github.io/cobalt/news/index.html","id":"cobalt-430","dir":"Changelog","previous_headings":"","what":"cobalt 4.3.0","title":"cobalt 4.3.0","text":"CRAN release: 2021-02-20 Returned cem Suggests. Added ability display threshold summaries multiply imputed datasets, clustered datasets, multi-category treatments, longitudinal treatments. Added pairwise argument binary treatments. set FALSE, bal.tab() display balance treatment group full sample (.e., target population). functionality already existed multi-category treatments; indeed, binary treatments, works treating treatment multi-category. Added two new stats options bal.tab() love.plot() continuous treatments: \"mean.diffs.target\" (abbreviated \"m\") \"ks.statistics.target\" (abbreviated \"ks\"). compute (standardized) mean differences KS statistics weighted unweighted samples ensure weighted sample representative original population. statistics computed adjusted sample (.e., appear absence adjustment). subclassification methods, arguments .subclass subclass.summary added display balance individual subclasses control output balance across subclasses summary. arguments replace disp.subclass argument, can still used. using bal.plot() clustered multiply imputed data, .cluster .imp arguments can set .none display balance ignoring cluster membership combining across imputations. Changed processing print() method. Now one print() method (print.bal.tab()) bal.tab objects. Processing little smoother printing bugs fixed. \".\" can longer supplied keep print setting -; simply omit corresponding argument use options specified call bal.tab(). additional argument, disp.call, can supplied bal.tab() print.bal.tab() control printing call component input object, contains original function call. Set FALSE hide call. option documented ?display_options can also set using set.cobalt.options(). balance table component bal.tab objects smaller extraneous columns longer produced. particular, threshold requested, threshold columns produced. affect display, makes easier extract balance statistics bal.tab objects (e.g., exporting table). mean previously saved bal.tab objects produced earlier versions cobalt able printed correctly. Fixed bug bal.plot() incorrectly process 2-level factor variables (#48). Fixed bug love.plot() display variables correct order using aggregation setting var.order = NULL. Thanks Florian Kaiser. Fixed bug love.plot() color points incorrect. Fixed bug love.plot() samples always displayed right order. Now displayed order bal.tab(). Fixed bug love.plot() weight names spaces . Added error message clusters contain treatment levels. Thanks Rachel Visontay. Fixed bug supplying weights argument list supported objects (e.g., weightit objects) unnamed. Samples conveniently named. Fixed bug col_w_mean(), col_w_smd(), friends occurred nonzero weights present. Now informative error thrown. Updates documentation.","code":""},{"path":"https://ngreifer.github.io/cobalt/news/index.html","id":"cobalt-424","dir":"Changelog","previous_headings":"","what":"cobalt 4.2.4","title":"cobalt 4.2.4","text":"CRAN release: 2020-11-05 Sampling weights now function correctly subclassification. Fixed bug print.bal.tab() units unmatched discarded. Fixed issue version number gridExtra DESCRIPTION. (#47) cem removed Suggests removed CRAN. Updated support MatchIt 4.0.0, includes sampling weights improved processing covariates.","code":""},{"path":"https://ngreifer.github.io/cobalt/news/index.html","id":"cobalt-423","dir":"Changelog","previous_headings":"","what":"cobalt 4.2.3","title":"cobalt 4.2.3","text":"CRAN release: 2020-08-31 Fixed bugs processing functions formulas, including rms functions poly(). (#40) Fixed bug KS statistics computed col_w_ks(). Results now agree MatchIt twang. Fixed bugs processing small partially empty subclasses. functions compute weights matching strata (e.g., get.w() types objects), estimand argument can supplied choose formula used compute weights. Subclass propensity scores computed number treated units subclass, stabilized weights computed propensity scores using standard formulas. Effective sample sizes now print two digits (believe , don’t need three) print cleanly whole numbers.","code":""},{"path":"https://ngreifer.github.io/cobalt/news/index.html","id":"cobalt-422","dir":"Changelog","previous_headings":"","what":"cobalt 4.2.2","title":"cobalt 4.2.2","text":"CRAN release: 2020-06-26 Fixed bug due new version sbw. Minor improvements error messages documentation.","code":""},{"path":"https://ngreifer.github.io/cobalt/news/index.html","id":"cobalt-421","dir":"Changelog","previous_headings":"","what":"cobalt 4.2.1","title":"cobalt 4.2.1","text":"CRAN release: 2020-06-20 Fixed bug int poly ignored binary continuous treatments. Fixed bug subclass balance statistics incorrectly computed. Thanks Mario Lawes. Improved processing inappropriately given S4 objects. Removed bal.tab methods atomic vectors (undocumented). errors provide inappropriately supplied unhelpful. Fixed bug backports 1.1.7 running correctly. Fixed bug str2expression R versions 3.6.0. Thanks @kthohr @jimmyg909. data segmented (.e., multi-category longitudinal treatment clusters multiple imputations specified), balance summary across segments computed displayed individual segment balance requested. See ?display_options see defaults different segment types, changed. Updated warnings.","code":""},{"path":"https://ngreifer.github.io/cobalt/news/index.html","id":"cobalt-420","dir":"Changelog","previous_headings":"","what":"cobalt 4.2.0","title":"cobalt 4.2.0","text":"CRAN release: 2020-06-04 Added support Matchby objects resulting call Matchby() Matching package. function identically Match objects. using formula inputs, interaction terms (e.g., X1 * X2) now correctly resolved displayed interaction term. makes easier check balance specific interactions rather set int = TRUE create separate interaction variable data. Interaction terms specified way ignored int poly used. using var.names love.plot(), changing names base components interaction also change name interaction term, consistent int behavior. formula supplied input object bal.tab() functions, terms formula now also included balance reports. Arguments addl can now specified one-sided formula (e.g., ~ X1 + X2 * X3). makes easy take advantage changes formula interface add additional interaction terms. formula look available datasets conditioning object supplied bal.tab() global environment. supplying single variable exists global environment, makes sense supply formula (e.g., addl = ~ X1) rather just variable (e.g., addl = X1). former retain name variable. can done distance. variables addl perfectly correlated name supplied covariates, variables removed addl. one argument provided f.build() (e.g., f.build(\"x\")), treated right-hand-side formula left-hand-side (e.g., evaluate ~ x). Fixed bug caused match.strata input ignored. Improved processing error reporting using default bal.tab() method. Speed improvements due changes formulas processed (now using model.matrix() directly rather splitfactor() process factors) small fixes. enables changes formula capabilities. Improved documentation weightitMSM objects WeightIt CBMSM objects CBPS. Fixed bug printing bal.tab objects continuous treatments. Fixed bug using multi-category treatments numbers level names. Fixed bug using mnps objects twang multiple stop methods. Fixed bug requesting means standard deviations segmented data. Fixed bug x-axis love.plot always “Standardized Mean Differences” even wasn’t supposed stats = \"mean.diffs\". rlang now IMPORTS. General speed stability improvements.","code":""},{"path":"https://ngreifer.github.io/cobalt/news/index.html","id":"cobalt-410","dir":"Changelog","previous_headings":"","what":"cobalt 4.1.0","title":"cobalt 4.1.0","text":"CRAN release: 2020-04-11 Added support sbwcau objects sbw. See Appendix 1 ?bal.tab.sbw example. Added support cem.match objects cem. See Appendix 1 ?bal.tab.cem.match example. Added stats argument bal.tab() print() replace disp.v.ratio disp.ks. argument functions similarly love.plot(); example, request mean differences variance ratios, one can enter stats = c(\"m\", \"v\"). One consequence possible request statistics don’t include mean differences. See ?display_options details. old arguments still work (probably always ) use stats instead. goal unify syntax across bal.tab(), print(), love.plot(). new help page specifically stats argument can viewed ?balance.stats. Added thresholds argument bal.tab() replace m.threshold, v.threshold, etc. argument functions similarly love.plot(); example, request thresholds mean differences variance ratios, one can enter thresholds = c(m = .1, v = 2). old arguments still work (probably always ) use thresholds instead. goal unify syntax across bal.tab(), print(), love.plot(). Added disp.means option bal.plot display mean covariate line density plots histograms. Added \"hedges\" option s.d.denom. compute standardized mean difference using formula small sample-corrected Hedge’s G described Works Clearinghouse Procedures Handbook. multi-category treatments pairwise = FALSE, rather computing balance treatment group treatment groups, balance now computed treatment group entire sample. print(), arguments disp.m.threshold, disp.v.threshold, disp.ks.threshold, disp.r.threshold, set FALSE prevent corresponding balance thresholds summaries printed, replaced disp.thresholds. Named entries can set FALSE. goal unify syntax across bal.tab() print(). new balance statistic, overlapping coefficient (OVL), allowed binary multi-category treatments. described Belitser et al. (2011) Franklin et al. (2014) assessing balance. Generally, covariate, overlapping coefficient area probability density functions sample overlap. follow Franklin et al. (2014) report 1 - (OVL) values close zero indicate good balance (.e., completely overlapping distributions) values close 1 indicate poor balance (.e., completely non-overlapping distributions). estimate display OVL, set include \"ovl\" stats argument call bal.tab() love.plot() (can use old syntax setting disp.ovl = TRUE). balance threshold can requested including \"ovl\" thresholds argument (can use old syntax using ovl.threshold argument). Spearman correlations can requested continuous treatments adding \"sp\" stats argument. argument weights can now supplied bal.tab() call request balance additional weights beyond weights object bal.tab() called. argument takes named list, element vector weights, name variable containing weights available dataset, object get.w() method (e.g., output another preprocessing function). make easier compare balancing methods without specify covariates treatment using formula data.frame methods. ggplot2 version 3.3.0 required, removes warnings makes ggstance doesn’t need imported. 900 variables compute balance statistics bal.tab (can happen quickly int = TRUE categorical variables many categories), avoid major slowdowns, checks redundancy variables forgone. dramatically increase speed bal.tab scenarios. option can changed cobalt option \"remove_perfect_col\" can set TRUE FALSE. Set FALSE improve speed expense possibly redundant variables appear. Fixed bug using default bal.tab method objects containing longitudinal treatments. Fixed bug using bal.tab continuous treatments clusters. Fixed bug love.plot() using subclassification. Fixed bug using bal.tab longitudinal treatments multiple sets weights. Fixed bug using col_w_ovl(). OVL values now accurate. Speedups small fixes.","code":""},{"path":"https://ngreifer.github.io/cobalt/news/index.html","id":"cobalt-400","dir":"Changelog","previous_headings":"","what":"cobalt 4.0.0","title":"cobalt 4.0.0","text":"CRAN release: 2020-01-08 Major Updates Added support mimids wimids objects MatchThem. Major restructuring clusters, longitudinal treatments, multi-category treatments, multiply imputed data can used . layers following order: clusters, time points, treatment categories, imputations. Summaries across layers handled slightly differently used ; importantly, summaries nested, lowest layer present can summary. example, multiply imputed data used multi-category treatments, summary across imputations (lowest layer) across treatment pairs. love.plot allows multiple forms faceting aggregating extremely flexible regard. Major changes appearance bal.plot() line love.plot(), including new grid position options control presence grid position legend. Formula interfaces now accept poly(x, .) matrix-generating functions variables, including rms-class-generating functions rms package (e.g., pol(), rcs(), etc.) (rms package must loaded use latter ones) basis-class-generating functions splines package (.e., bs() ns()). bug early version found @ahinton-mmc. Minor Updates Bug Fixes s.d.denom estimand s.d.denom can now use name treatment rather just \"treated\" \"control\". addition, s.d.denom can \"weighted\" use weighted sample’s standardization factors, option available continuous treatments, . Improved guessing estimand provided. Estimands besides ATT can now used subclasses. estimand can inferred provided subclasses. Works match.strata well, function like subclasses. addition, always assumed MatchIt objects targeting ATT, example, subclassification calipers. bal.plot Added sample.names argument bal.plot response post Cross Validated. Added functionality argument bal.plot, allowing specificity multiple sets weights used. Added type = \"ecdf\" option bal.plot categorical treatments continuous covariates display empirical cumulative density plots alternative density plots. using bal.plot continuous treatments continuous covariates, points shaded based weights; behavior controlled new alpha.weight argument, replaces functionality size.weight (kind ugly informative) TRUE default. Now ’s apparent points influential weighted sample. addition, line illustrating unweighted covariate mean present. default grid argument now FALSE bal.plot() love.plot(). Previously TRUE. make plots cleaner outset. improvements Added new function col_w_cov() compute treatment-covariate covariances (.e., unstandardized correlations) continuous treatments. continuous binary can set \"raw\" bal.tab() std can set FALSE col_w_cov() request treatment-covariate covariances instead correlations. col_w_corr() now wrapper col_w_cov() std = TRUE. get functionality std argument (e.g., standardize covariances covariates others), use col_w_cov(). Balance summary functions (e.g., col_w_sd(), col_w_smd(), etc.) process binary variables slightly differently. bin.vars missing, function figure variables binary. NULL, assumed variables binary. Entering values bin.vars can done flexibly. factor variable supplied part mat split internally splitfactor(), extra values automatically added bin.vars newly created dummies considered binary variables. Bug fixes binary factor treatments used, thanks Moaath Mustafa Ali. bal.tab() longer tells whether assumes matching weighting certain non-package-related methods used. Improvements assessment subclass balance. binary treatments, balance statistics mean differences can now requested. across-subclass balance summary uses subclassification weights (processed way match.strata ) instead simply taking weighted average across subclasses (valid non-additive statistics like variance ratios KS statistics). continuous treatments, balance summary across subclasses can now produced. uses weighted average subclass-specific balance statistics. default love.plot() abs now whatever (implicit) call bal.tab(), usually FALSE. Previously abs aligned love.plot() bal.tab(). s.weights can now manually supplied methods usually come sampling weights, twang WeightIt. Speedup splitfactor(). splitfactor() now split.option split one vectors concert data set split. splitfactor() unsplitfactor() little smarter sync. functions work better inside functions like lapply() purrr::map(), thanks @-Zian. Updates vignettes; Appendix 2 particularly different. bug fixes performance improvements .","code":""},{"path":"https://ngreifer.github.io/cobalt/news/index.html","id":"cobalt-390","dir":"Changelog","previous_headings":"","what":"cobalt 3.9.0","title":"cobalt 3.9.0","text":"CRAN release: 2019-10-06 Added vignette use love.plot. Changed grid version requirement. Updated README. Fixed bugs occur using love.plot() various combinations var.order, multiple stats, agg.fun = \"range\". Fixed bugs occur using bal.tab() objects Matching package. Calculated statistics now generated using Matching::MatchBalance. Changes based updates get.w.Match(). Added balance summary functions col_w_mean, col_w_sd, col_w_smd, col_w_vr, col_w_ks, col_w_ovl, col_w_corr. make easier get quick, simple summaries balance without calling bal.tab, example, use programming functions. now used inside bal.tab increase speed simplify internal syntax. small bug fixes.","code":""},{"path":"https://ngreifer.github.io/cobalt/news/index.html","id":"cobalt-380","dir":"Changelog","previous_headings":"","what":"cobalt 3.8.0","title":"cobalt 3.8.0","text":"CRAN release: 2019-09-12 Added ability display balance multiple measures (e.g., mean differences, variance ratios, KS statistics) time love.plot(). Bug fixes make bal.tab() love.plot() usable within functions especially called .call(). Made easier get proper bal.tab output using matchit() argument distance (call matchit()). Include original dataset data argument bal.tab() get variables display correctly. Changed default shape love.plot() \"circle\", solid circle. found prettier alternative open circle, especially Windows. get back open circles set shapes = \"circle filled\" (yes, bit confusing). Added ability hide gridlines easily love.plot(). Changed calculation standard deviations (standardized differences proportion) binary variables line recommendations, noted @mbloechl05. Note make values different MatchIt::summary small amount. KS statistic now computed binary variables. simply difference proportion. Allowed methods accept mids objects (output call mice::mice()) data argument supply multiply imputed data. essentially replaces data = complete(imp., \"long\"), imp = \".imp\" data = imp.put, assuming imp.mids object. bug fixes improvements.","code":""},{"path":"https://ngreifer.github.io/cobalt/news/index.html","id":"cobalt-370","dir":"Changelog","previous_headings":"","what":"cobalt 3.7.0","title":"cobalt 3.7.0","text":"CRAN release: 2019-05-01 Changes bal.tab defaults: quick now set TRUE default. Adjusted unadjusted means, standard deviations, mean differences always computed, regardless quick. Variance ratios KS statistics computed quick = FALSE disp.v.ratio disp.ks, respectively, TRUE. Variance ratios now respond abs. abs = FALSE, default bal.tab, variance ratio variance treated (1) divided variance control (0). abs = TRUE, numerator variance ratio larger variance denominator smaller variance, old behavior. v.threshold still responds abs set TRUE, just like mean differences. time variance ratios aggregated (e.g., across imputations clusters), “mean” variance ratio geometric mean account asymmetry ratios. love.plot several changes make much user-friendly. First, rather supplying bal.tab object love.plot, can simply supply arguments gone bal.tab() call straight love.plot(). Second, quick = TRUE (new default) first argument love.plot() call bal.tab() (arguments provided bal.tab()) stat set \"variance.ratios\" \"ks.statistics\", bal.tab() re-called corresponding disp argument set TRUE love.plot() display statistics regardless quick. work argument supplied love.plot() bal.tab object. Third, unadjusted mean differences computed regardless quick, never circumstance adjusted values displayed. quick = TRUE, un = FALSE, stat \"variance.ratios\" \"ks.statistics\", un automatically set TRUE bal.tab() re-call. using . arguments (e.g., .cluster, .imp, etc.), instead supplying NULL NA, can supply ..none (quotes). make easier use. Note new inputs variables; keywords evaluated using nonstandard evaluation. actually objects names, ignored. Bugs scoping related formula interface solved, particularly making bal.tab() usable within functions. Fixed bug occurring using matchit objects set discard something NULL reestimate = TRUE call matchit(). Thank Weiyi Xie finding bug. Fixed bug occurring using balance thresholds subclassification. Fixed bug occurring printing bal.tab output continuous treatments clusters. Fixed bug occurring using bal.tab() mnps objects multiple stop methods.","code":""},{"path":"https://ngreifer.github.io/cobalt/news/index.html","id":"cobalt-361","dir":"Changelog","previous_headings":"","what":"cobalt 3.6.1","title":"cobalt 3.6.1","text":"CRAN release: 2019-01-16 Fixed bug installed version R earlier 3.5.0.","code":""},{"path":"https://ngreifer.github.io/cobalt/news/index.html","id":"cobalt-360","dir":"Changelog","previous_headings":"","what":"cobalt 3.6.0","title":"cobalt 3.6.0","text":"CRAN release: 2018-11-25 Added poly argument bal.tab() display polynomials continuous covariates (e.g., squares, cubes, etc.). used available int argument, also displayed interactions. Now, polynomials can requested separately. int = TRUE, squares covariates longer displayed; replicate old behavior, set int = 2, equivalent int = TRUE, poly = 2. Fixed bug using subset produce error. Fixed bug using multiply imputed data binary treatments factors characters. Updated bal.tab documentation make easier navigate right page. Small documentation syntax updates. Added hidden undocumented argument center bal.tab, , set TRUE, centers covariates mean entire unadjusted sample prior computing interactions polynomials. Added set.cobalt.options function easily set global options can used defaults arguments. example, set.global.options(binary = \"std\") makes standardized mean difference always displayed binary covariates (present R session). options can retrieved get.cobalt.options.","code":""},{"path":"https://ngreifer.github.io/cobalt/news/index.html","id":"cobalt-350","dir":"Changelog","previous_headings":"","what":"cobalt 3.5.0","title":"cobalt 3.5.0","text":"CRAN release: 2018-10-25 Several changes bal.tab() display options (.e., imbalanced., un, disp.means, disp.v.ratio, disp.ks, disp.bal.tab, disp.subclass, parameters related display balance tables multinomial treatments, clusters, multiple imputations, longitudinal treatments). First, named arguments removed method-specific functions order clean make easier add new functions, still available specified. Second, help page devoted just functions created, can accessed ?options-display. Third, global options arguments can set options() don’t need typed time. example, wanted un = TRUE time, set options(cobalt_un = TRUE) include call bal.tab(). Added disp.sds option display standard deviations group bal.tab(). works places disp.means . Added cluster.fun imp.fun options request certain functions (e.g., mean maximum) balance statistics displayed summary across clusters/imputations. Previously option available call print(). parameters part display options described , documented ?options-display bal.tab help files. Added factor_sep int_sep options change separators variable names factor variables interactions displayed. functionality available since version 3.4.0 documented. now documented new display_options help page. bal.tab(), continuous binary can specified global options \"cobalt_continuous\" \"cobalt_binary\", respectively, global setting (e.g., set binary = \"std\" view standardized mean difference rather raw differences proportion binary variables) can used instead specifying argument time call bal.tab(). Minor updates f.build() process inputs flexibly. left hand side can now empty, variables right hand side can now contain spaces. Fixed bug logical treatments used. Thanks @victorn1. Fixed bug occur variable one value. Thanks @victorn1. Made names 0/1 logical variables printed \"_1\" appended . Thanks @victorn1 suggestion. Major updates organization code help files. Certain functions simplified syntax, relying ..., help pages shorted consolidated methods. particular, code help documents Matching, optmatch, ebal, designmatch methods bal.tab() consolidated since rely exactly syntax.","code":""},{"path":"https://ngreifer.github.io/cobalt/news/index.html","id":"cobalt-341","dir":"Changelog","previous_headings":"","what":"cobalt 3.4.1","title":"cobalt 3.4.1","text":"CRAN release: 2018-09-15 Fixed bug occur imabalanced.= TRUE bal.tab() variables balanced. Fixed bug mean binary variable displayed 1 minus mean. Fixed bug occur missingness patterns multiple variables. Fixed bug occur distance measure assessed bal.tab() missing values covariates (thanks Laura Helmkamp). Fixed bug occur estimand supplied user using default method bal.tab(). Fixed bug non-standard variable names (like \"(age^2)\") cause error. Fixed bug treatment levels different numbers characters yield error. Added disp.means option bal.tab continuous treatments.","code":""},{"path":"https://ngreifer.github.io/cobalt/news/index.html","id":"cobalt-340","dir":"Changelog","previous_headings":"","what":"cobalt 3.4.0","title":"cobalt 3.4.0","text":"CRAN release: 2018-08-14 Added default method bal.tab can used specially formatted output packages (e.g., optweight). bal.plot work outputs . , course, never completely bug-free infinite inputs possible processed perfectly. Don’t try break function :) Fixed bugs occurring standardized mean differences finite, thanks Noémie Kiefer. Speed improvements bal.plot, especially multiple facets, bal.tab. Added new options bal.plot, including ability display histograms rather densities mirrored rather overlapping plots. makes possible make popular mirrored histogram plot propensity scores. addition, ’s now easier change colors components plots. Made behavior around binary variables interactions like documentation, interactions levels variable present (thanks @victorn1). Also, replaced _ * delimiter variable names interactions. old behavior, use int_sep = \"_\" bal.tab. Expanded flexibility var.names love.plot replacing name variable replace everywhere appears, including interactions. Thanks @victorn1 suggestion. Added var.names function extract save variable names bal.tab objects. makes lot easier create replacement names use love.plot. Thanks @victorn1 suggestion. weighted correlations computed continuous treatments, denominator correlation now uses unweighted standard deviations. See ?bal.tab rationale.","code":""},{"path":"https://ngreifer.github.io/cobalt/news/index.html","id":"cobalt-330","dir":"Changelog","previous_headings":"","what":"cobalt 3.3.0","title":"cobalt 3.3.0","text":"CRAN release: 2018-06-24 Added methods objects designmatch package. Added methods ps.cont objects WeightIt package. Fixed bugs resulting form changes formula inputs handled. Cleaned internal functions, also fixing related bugs Added subset option bal.tab() methods (consequently bal.plot()) allows users specify subset data assess balance (.e., instead whole data set). provides workaround methods cluster option isn’t allowed (e.g., longitudinal treatments) balance desired subsets data. However, cases, cluster .cluster specified makes sense. Updated help files, particular, clearly documenting methods iptw objects twang CBMSM objects CBPS. Added pretty printing crayon, inspired Jacob Long’s jtools package Added abs option bal.tab display absolute values statistics, can especially helpful aggregated output. also affects love.plot() handles aggregated balance statistics.","code":""},{"path":"https://ngreifer.github.io/cobalt/news/index.html","id":"cobalt-323","dir":"Changelog","previous_headings":"","what":"cobalt 3.2.3","title":"cobalt 3.2.3","text":"CRAN release: 2018-05-04 Added support data missing covariates. bal.tab() produce balance statistics non-missing values automatically create new variable indicating whether variable missing produce balance statistics variable well. Fixed bug displaying maximum imbalances subclassification. Fixed bug unadjusted statistics displayed using love.plot() subclasses. (Thanks Megha Joshi.) Add ability display individual subclass balance using love.plot() subclasses. --hood changes weightit objects handled. Objects environment now handled better bal.tab() formula interface. data argument now optional variables formula exist environment.","code":""},{"path":"https://ngreifer.github.io/cobalt/news/index.html","id":"cobalt-322","dir":"Changelog","previous_headings":"","what":"cobalt 3.2.2","title":"cobalt 3.2.2","text":"CRAN release: 2018-03-13 Fixed bug using get.w() (bal.tab()) mnps objects twang one stop method. Fixed bug using bal.tab() twang objects contained missing covariate values. Fixed bug using int = TRUE bal.tab() covariates. Fixed bug variable names special characters. Added ability check higher order polynomials setting int number. Changed behavior bal.tab() multinomial treatments s.d.denom = \"pooled\" use pooled standard deviation entire sample, just paired treatments. Restored vignettes required WeightIt.","code":""},{"path":"https://ngreifer.github.io/cobalt/news/index.html","id":"cobalt-321","dir":"Changelog","previous_headings":"","what":"cobalt 3.2.1","title":"cobalt 3.2.1","text":"CRAN release: 2018-02-20 Edits vignettes help files respond missing packages. vignette items may display packages (temporarily) unavailable. Fixed issue sampling weights CBPS objects. (Thanks @kkranker Github.) Added support sampling weights get.w() help files.","code":""},{"path":"https://ngreifer.github.io/cobalt/news/index.html","id":"cobalt-320","dir":"Changelog","previous_headings":"","what":"cobalt 3.2.0","title":"cobalt 3.2.0","text":"CRAN release: 2018-01-17 Added support longitudinal treatments bal.tab(), bal.plot(), love.plot(), including output iptw() twang, CBMSM() CBPS, weightitMSM() WeightIt. Added vignette explain use longitudinal treatments. Edits help files. Added ability change density options bal.plot(). Added support imp bal.tab() weightit objects. Fixed bugs limited variables present. (One found fixed @sumtxt Github.) Fixed bug multiple methods weights entered list.","code":""},{"path":"https://ngreifer.github.io/cobalt/news/index.html","id":"cobalt-310","dir":"Changelog","previous_headings":"","what":"cobalt 3.1.0","title":"cobalt 3.1.0","text":"CRAN release: 2017-11-12 Added full support tibbles. Examples weightit methods documentation vignette now work. Improved speed performance. Added pairwise option bal.tab() multinomial treatments. Increased flexibility displaying balance using love.plot() clustered multiply imputed data. Added imbalanced.disp.bal.tab options bal.tab(). Fixes vignettes. Also, creation new vignette simplify main one.","code":""},{"path":"https://ngreifer.github.io/cobalt/news/index.html","id":"cobalt-300","dir":"Changelog","previous_headings":"","what":"cobalt 3.0.0","title":"cobalt 3.0.0","text":"CRAN release: 2017-10-16 Added support multinomial treatments bal.tab(), including output CBPS twang. Added support weightit objects WeightIt, including multinomial treatments. Added support ebalance.trim objects ebal. Fixes vignette. Fixes splitfactor() handle tibbles better. Fixed bug using bal.tab() multiply imputed data without adjustment. Fixed bug using s.weights formula method bal.tab().","code":""},{"path":"https://ngreifer.github.io/cobalt/news/index.html","id":"cobalt-220","dir":"Changelog","previous_headings":"","what":"cobalt 2.2.0","title":"cobalt 2.2.0","text":"CRAN release: 2017-09-05 Added disp.ks ks.threshold options bal.tab() display Kolmogorov-Smirnov statistics preprocessing. Added support sampling weights, applied control treated units, using option s.weights bal.tab(). Sampling weights also now compatible sampling weights ps objects twang; default apply sampling weights adjustment, mimicking behavior bal.table() twang. Changed behavior bal.tab() ps objects allow displaying balance one stop method time, default displaying balance available stop methods. full.stop.method argument bal.tab() renamed stop.method, full.stop.method still works. get.w() ps objects also gone changes like twang’s get.weights(). Added support bal.tab() bal.plot() subclassification continuous treatments. Added support splitfactor() unsplitfactor() NA values Fixed bug love.plot() caused var.order specified sample present.","code":""},{"path":"https://ngreifer.github.io/cobalt/news/index.html","id":"cobalt-210","dir":"Changelog","previous_headings":"","what":"cobalt 2.1.0","title":"cobalt 2.1.0","text":"CRAN release: 2017-05-31 Added support bal.tab(), bal.plot(), love.plot() examining balance multiple weight specifications time Added new utilities splitfactor(), unsplitfactor(), get.w() Added option bal.plot() display points sized weights treatment covariate continuous Added = \"\" option bal.plot() simultaneously display plots adjusted unadjusted samples; changed argument syntax accommodate Allowed bal.plot() display balance multiple clusters imputations simultaneously Allowed bal.plot() display balance multiple subclasses simultaneously .sub Fixes love.plot() ensure adjusted points front unadjusted points; changed colors shape defaults allowable values Fixed bug s.d.denom estimand functioning correctly bal.tab() distance, addl, weights can now specified lists usual arguments","code":""},{"path":"https://ngreifer.github.io/cobalt/news/index.html","id":"cobalt-200","dir":"Changelog","previous_headings":"","what":"cobalt 2.0.0","title":"cobalt 2.0.0","text":"CRAN release: 2017-05-14 Added support matching using optmatch package specifying matching strata. Added full support (bal.tab(), love.plot(), bal.plot()) multiply imputed data, including clustered data sets. Added support multiple distance measures, including special treatment love.plot() Adjusted specifications love.plot() color shape points, added option generate line connecting points. Adjusted love.plot() display perform better Windows. Added capabilities love.plot() bal.plot() display plots multiple groups time Added flexibility f.build(). Updated bal.plot(), giving capability view multiple plots subclassified clustered data. Multinomial treatments also supported. Created new vignette clustered multiply imputed data Speed improvements Fixed bug causing mislabelling categorical variables Changed calculation weighted variance line recommendations; CBPS can now used standardized weights","code":""},{"path":"https://ngreifer.github.io/cobalt/news/index.html","id":"cobalt-131","dir":"Changelog","previous_headings":"","what":"cobalt 1.3.1","title":"cobalt 1.3.1","text":"CRAN release: 2016-12-18 Added support entropy balancing ebal package. Changed default color scheme love.plot() black white added options color, shape, size points. Added sample size calculations continuous treatments. Edits vignette.","code":""},{"path":"https://ngreifer.github.io/cobalt/news/index.html","id":"cobalt-130","dir":"Changelog","previous_headings":"","what":"cobalt 1.3.0","title":"cobalt 1.3.0","text":"CRAN release: 2016-10-23 Increased capabilities cluster balance bal.tab() love.plot() Increased information decreased redundancy assessing balance interactions Added quick option bal.tab() increase speed Added options print() Bug fixes Speed improvements Edits vignette","code":""},{"path":"https://ngreifer.github.io/cobalt/news/index.html","id":"cobalt-120","dir":"Changelog","previous_headings":"","what":"cobalt 1.2.0","title":"cobalt 1.2.0","text":"CRAN release: 2016-09-01 Added support continuous treatment variables bal.tab(), bal.plot(), love.plot() Added balance assessment within across clusters small performance changes minimize errors intuitive Major revisions adjustments vignette","code":""},{"path":"https://ngreifer.github.io/cobalt/news/index.html","id":"cobalt-110","dir":"Changelog","previous_headings":"","what":"cobalt 1.1.0","title":"cobalt 1.1.0","text":"CRAN release: 2016-07-23 Added vignette. Fixed error bal.tab.Match() caused wrong values warning messages used. Added new capabilities bal.plot(), including ability view unadjusted sample distributions, categorical variables , distance measure. Also updated documentation reflect changes make .sub focal. Allowed subclasses different simply 1:S treating like factors input numerical Changed column names Balance table output fit compactly, updated documentation reflect changes. small performance changes minimize errors intuitive.","code":""}]
